{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import inkml2img\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expressmatch', 'extension', 'HAMEX', 'KAIST', 'MathBrush', 'MfrDB']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"for t in arr[i]:\\n    if ('.lg' not in t):\\n        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\\n        print(t)\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert .inkml files to .jpg images\n",
    "PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\"\n",
    "dataSets = os.listdir(PATH)\n",
    "arr = [[] for _ in range(len(dataSets))]\n",
    "print(dataSets)\n",
    "for i in range(len(dataSets)):\n",
    "    arr[i] = os.listdir(PATH+'\\\\'+dataSets[i])\n",
    "\n",
    "'''for t in arr[i]:\n",
    "    if ('.lg' not in t):\n",
    "        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\n",
    "        print(t)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latex expressions of each .inkml file\n",
    "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "LABELS_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\"\n",
    "# Dictionary where each .inkml file info will be store\n",
    "items = {}\n",
    "index = 0\n",
    "count = 0\n",
    "\n",
    "for t in arr:\n",
    "    for i in t:\n",
    "        if (\".lg\" not in i):\n",
    "            imgPath = DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i\n",
    "            tree = ET.parse(imgPath)\n",
    "            root = tree.getroot()\n",
    "            count =0\n",
    "            for item in root:\n",
    "                if item.text:\n",
    "                    if \"$\" in item.text:\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
    "                        break\n",
    "                    if \"\\\\\" in item.text and dataSets[index] == \"MathBrush\":\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
    "                        break\n",
    "                    if (count ==1 and dataSets[index]==\"KAIST\" and len(item.text)>2):\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current\n",
    "                        break\n",
    "                count +=1\n",
    "        else:\n",
    "            print(i)\n",
    "    index +=1 \n",
    "\n",
    "for key in items:\n",
    "    if ('l o g' in items[key]):\n",
    "        items[key] = items[key].replace('l o g', '\\\\log')\n",
    "\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'w') as f:\n",
    "    json.dump(items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no correr, cambios a manita\n",
    "delete = ['\\\\Bigg','\\\\left','\\\\right','\\\\Big','\\\\mathrm']\n",
    "replace = {'\\\\to':'\\\\rightarrow', '\\\\gt':'>', '\\\\lt':'<'}\n",
    "add = ['_','{','}','=','(',')','-','+','^','[',']', ',']\n",
    "count = 0\n",
    "for key in items:\n",
    "    for dele in delete:\n",
    "        if dele in items[key]:\n",
    "            items[key] = items[key].replace(dele, \"\")\n",
    "    for rep in replace:\n",
    "        if (rep in items[key]):\n",
    "            items[key] = items[key].replace(rep, replace[rep])\n",
    "    for it in add:\n",
    "        if (it in items[key]):\n",
    "            items[key] = items[key].replace(it, \" \"+it+\" \")\n",
    "    if ('\\\\' in items[key]):\n",
    "        items[key] = items[key].replace('\\\\', \" \\\\\")\n",
    "    items[key] = re.split(r'\\s+', items[key])\n",
    "    count = 0\n",
    "    for a in items[key]:\n",
    "        if ('\\\\' not in a and len(a)>1):\n",
    "            uno = items[key][:count]\n",
    "            dos = re.split('', a)[1:-1]\n",
    "            tres = items[key][count+1:]\n",
    "            count+= len(dos)-1\n",
    "            uno.extend(dos)\n",
    "            uno.extend(tres)\n",
    "            items[key] = uno\n",
    "        count+=1\n",
    "    if (items[key][-1]==\"\"):\n",
    "        items[key] = items[key][:-1]\n",
    "    if (items[key][0]==\"\"):\n",
    "        items[key] = items[key][1:]\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'w') as f:\n",
    "    json.dump(items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> S = ( \\sum _ { i = 1 } ^ { n } \\theta _ i - ( n - 2 ) \\pi ) r ^ 2 <end>\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "num_words = 1000\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "items = {}\n",
    "# antes hay que correr la celda anterior\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'r') as f:\n",
    "    items = json.load(f)\n",
    "tokens = {}\n",
    "count = 0\n",
    "for key in items:\n",
    "    items[key] = ' '.join(map(str, items[key]))\n",
    "    items[key] = '<start> '+items[key] + ' <end>'\n",
    "    items[key] = re.sub(r\"\\s+\", \" \", items[key])\n",
    "keys = list(items.keys())\n",
    "data = [ items[key] for key in keys ]\n",
    "print(data[0])\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token, filters='', lower=False)\n",
    "tokenizer.fit_on_texts(data)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\tokens.json\", 'w') as f:\n",
    "    json.dump(word_index, f, indent=4)\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "files_imgs = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\tokens.json\", 'r') as f:\n",
    "    tokens = json.load(f)\n",
    "tokensPerFile = {}\n",
    "items = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'r') as f:\n",
    "    items = json.load(f)\n",
    "for key in items:\n",
    "    newKey = LABELS_PATH +'\\\\images'+ key[len(LABELS_PATH)+11:][:-6]+'.jpg'\n",
    "    tokensPerFile[newKey] = []\n",
    "    files_imgs[newKey] = key\n",
    "    for command in items[key]:\n",
    "        tokensPerFile[newKey].append(tokens[command])\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labelsPerFile.json\", 'w') as f:\n",
    "    json.dump(tokensPerFile, f, indent=4)\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\files_img.json\", 'w') as f:\n",
    "    json.dump(files_imgs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 1024, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 510, 1022, 32 320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 510, 1022, 32 128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 510, 1022, 32 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 508, 1020, 32 9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 508, 1020, 32 128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 508, 1020, 32 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 506, 1018, 32 9248        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 506, 1018, 32 128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 506, 1018, 32 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 504, 1016, 32 9248        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 504, 1016, 32 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 504, 1016, 32 128         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 504, 1016, 32 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 252, 508, 32) 0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 250, 506, 64) 18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 250, 506, 64) 256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 250, 506, 64) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 248, 504, 64) 36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 248, 504, 64) 256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 248, 504, 64) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 246, 502, 64) 36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 246, 502, 64) 256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 246, 502, 64) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 244, 500, 64) 36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 244, 500, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 244, 500, 64) 256         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 244, 500, 64) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 122, 250, 64) 0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 120, 248, 64) 36928       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 120, 248, 64) 256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 120, 248, 64) 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 118, 246, 64) 36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 118, 246, 64) 256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 118, 246, 64) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 116, 244, 64) 36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 116, 244, 64) 256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 116, 244, 64) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 114, 242, 64) 36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 114, 242, 64) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 114, 242, 64) 256         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 114, 242, 64) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 57, 121, 64)  0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 28, 60, 128)  73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 28, 60, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 28, 60, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 29, 128)  147584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 13, 29, 128)  512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 13, 29, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 14, 128)   147584      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            multiple             0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 14, 128)   512         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 14, 128)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 2, 6, 128)    147584      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 2, 6, 128)    512         dropout_11[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 6, 128)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 1, 3, 128)    0           activation_47[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 826,272\n",
      "Trainable params: 823,968\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#FCN + GRU (attention) \n",
    "# checar que onda con los filtros\n",
    "# vector de cuatro en output\n",
    "class FCN_encoder(tf.keras.Model):\n",
    "    def __init__(self, dropout_rate = 0.2):\n",
    "        super(FCN_encoder, self).__init__()\n",
    "        \n",
    "        # bloque de convolucion 1, 32 filtros\n",
    "        self.conv_1_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_3 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_4 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.drop_1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_1_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_4 = tf.keras.layers.Activation('relu')\n",
    "        \n",
    "        # maxpooling para reducir el tamaño\n",
    "        self.maxPool_1 = tf.keras.layers.MaxPooling2D()\n",
    "        \n",
    "        # bloque convolucional 2, 64 filtros\n",
    "        self.conv_2_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.drop_2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_2_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_2 = tf.keras.layers.MaxPooling2D()\n",
    "\n",
    "        self.conv_3_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.drop_3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_3_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_3 = tf.keras.layers.MaxPooling2D()\n",
    "\n",
    "        self.conv_4_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.drop_4 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_4_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_4 = tf.keras.layers.MaxPooling2D()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.conv_1_1(inputs)\n",
    "        x = self.batch_1_1(x)\n",
    "        x = self.act_1_1(x)\n",
    "        x = self.conv_1_2(x)\n",
    "        x = self.batch_1_2(x)\n",
    "        x = self.act_1_2(x)\n",
    "        x = self.conv_1_3(x)\n",
    "        x = self.batch_1_3(x)\n",
    "        x = self.act_1_3(x)\n",
    "        x = self.conv_1_4(x)\n",
    "        x = self.drop_1(x)\n",
    "        x = self.batch_1_4(x)\n",
    "        x = self.act_1_4(x)\n",
    "        x = self.maxPool_1(x)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.batch_2_1(x)\n",
    "        x = self.act_2_1(x)\n",
    "        x = self.conv_2_2(x)\n",
    "        x = self.batch_2_2(x)\n",
    "        x = self.act_2_2(x)\n",
    "        x = self.conv_2_3(x)\n",
    "        x = self.batch_2_3(x)\n",
    "        x = self.act_2_3(x)\n",
    "        x = self.conv_2_4(x)\n",
    "        x = self.drop_2(x)\n",
    "        x = self.batch_2_4(x)\n",
    "        x = self.act_2_4(x)\n",
    "        x = self.maxPool_2(x)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.batch_3_1(x)\n",
    "        x = self.act_3_1(x)\n",
    "        x = self.conv_3_2(x)\n",
    "        x = self.batch_3_2(x)\n",
    "        x = self.act_3_2(x)\n",
    "        x = self.conv_3_3(x)\n",
    "        x = self.batch_3_3(x)\n",
    "        x = self.act_3_3(x)\n",
    "        x = self.conv_3_4(x)\n",
    "        x = self.drop_3(x)\n",
    "        x = self.batch_3_4(x)\n",
    "        x = self.act_3_4(x)\n",
    "        x = self.maxPool_3(x)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.batch_4_1(x)\n",
    "        x = self.act_4_1(x)\n",
    "        x = self.conv_4_2(x)\n",
    "        x = self.batch_4_2(x)\n",
    "        x = self.act_4_2(x)\n",
    "        x = self.conv_4_3(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = self.batch_4_3(x)\n",
    "        x = self.act_4_3(x)\n",
    "        x = self.conv_4_4(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = self.batch_4_4(x)\n",
    "        x = self.act_4_4(x)\n",
    "        x = self.maxPool_4(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def model(self):\n",
    "        input = tf.keras.layers.Input(shape=(512, 1024, 1))\n",
    "        return tf.keras.Model(inputs = input, outputs = self.call(input) )\n",
    "print(FCN_encoder().model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attender(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Attender, self).__init__()\n",
    "        self.W_1 = tf.keras.layers.Dense(128)\n",
    "        self.U_a = tf.keras.layers.Dense(128)\n",
    "        self.V_a = tf.keras.layers.Dense(1)\n",
    "        self.F = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2)\n",
    "    \n",
    "    def call(self, a, h):\n",
    "        h_t = tf.expand_dims(h, 1)\n",
    "        e_ti = self.V_a( (tf.nn.tanh( self.W_1(a) + self.U_a(h))))\n",
    "        a_ti = tf.nn.softmax(e_ti, axis=1)\n",
    "        context = a_ti * a\n",
    "        context = tf.reduce_sum(context, axis =1)\n",
    "        return context, a_ti       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_decoder(tf.keras.Model):\n",
    "    def __init__(self, dimension, units, label_len):\n",
    "        super(GRU_decoder, self).__init__()\n",
    "        self.units = units\n",
    "        self.embedding = tf.keras.layers.Embedding(label_len, dimension)\n",
    "        self.gru = tf.keras.layers.GRU( self.units, return_sequences=True, return_state = True, recurrent_initializer='glorot_uniform')\n",
    "        self.fc1 = tf.keras.layers.Dense(self.units)\n",
    "        self.fc2 = tf.keras.layers.Dense(label_len)\n",
    "        self.attention = Attender()\n",
    "    def call(self, x, a, h):\n",
    "        #print(a.shape, h.shape)\n",
    "        context_v, attention_pro = self.attention(a,h)\n",
    "        x = self.embedding(x)\n",
    "        context_v = tf.expand_dims(context_v,1)\n",
    "        print(context_v.shape, x.shape)\n",
    "        x = tf.concat([context_v,x], axis =-1)\n",
    "        out, state = self.gru(x)\n",
    "        x = self.fc1(out)\n",
    "        x = tf.reshape(x, (-1, x.shape[2]))\n",
    "        x = self.fc2(x)\n",
    "        return x, state, attention_pro\n",
    "    \n",
    "    def reset(self, batch):\n",
    "        return tf.zeros((batch,1,3, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = FCN_encoder()\n",
    "decoder = GRU_decoder(256,128,len(list(word_index.keys())))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "LABELS_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\"\n",
    "with open(LABELS_PATH+'\\\\labelsPerFile.json',  'r') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (512, 1024, 1)\n",
      "Label:  [ 4  2 64 11  2 19 17 31 31 67 59  9  2 52  3  3  2  2 55  3 11  2 19  3\n",
      "  3  3  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "#train padded\n",
    "files_img = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\files_img.json\", 'r') as f:\n",
    "    files_img = json.load(f)\n",
    "    f.close()\n",
    "keys = list(files_img.keys())\n",
    "import pathlib\n",
    "list_ds = tf.data.Dataset.list_files(list(data.keys()))\n",
    "def getProcessedImages(f):\n",
    "    index = keys.index(f)\n",
    "    image = tf.io.read_file(f)\n",
    "    image = tf.image.decode_jpeg(image, channels = 1)                       \n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [512, 1024] ) \n",
    "    return image, train_padded[index] #[data[str(tf.constant(f).numpy())[2:-1].replace('\\\\\\\\', '\\\\') ]]\n",
    "    \n",
    "labeledDataset = list_ds.map(lambda x: tf.py_function(getProcessedImages, [x], [tf.float32, tf.int32]) ,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "for image, label in labeledDataset.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for image, label in labeledDataset.batch(64).take( 1 ):\\n    print(\"Image shape: \", image.numpy().shape)\\n    print(\"Label: \", label.numpy())'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeledDataset = labeledDataset.batch(16)\n",
    "labeledDataset = labeledDataset.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "\n",
    "'''for image, label in labeledDataset.batch(64).take( 1 ):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def train(image, groundTruth):\n",
    "    loss = 0\n",
    "    hidden = decoder.reset(groundTruth.shape[0])\n",
    "    input_decoder = tf.expand_dims([word_index['<start>']] * groundTruth.shape[0], 1)\n",
    "    print(input_decoder.shape)\n",
    "    with tf.GradientTape() as tape:\n",
    "        feature_map = encoder(image)\n",
    "        for i in range(1, groundTruth.shape[1]):\n",
    "            print(i)\n",
    "            pred, hidden, _ = decoder(input_decoder, feature_map, hidden)\n",
    "            loss += loss_function(target[:, i], predictions)\n",
    "            dec_input = tf.expand_dims(target[:, i], 1)\n",
    "\n",
    "    total_loss = (loss / int(target.shape[1]))\n",
    "\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainData(dataset, EPOCHS = 1):\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "      \n",
    "        for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "            batch_loss, t_loss = train(img_tensor, target)\n",
    "            total_loss += t_loss\n",
    "          \n",
    "            if batch % 100 == 0:\n",
    "                average_batch_loss = batch_loss.numpy()/int(target.shape[1])\n",
    "        print('Epoch {0:d}/{1:d}'.format(epoch+1, EPOCHS), \": {0:.3f}sec\".format((end_time - start_time)))\n",
    "        print('===============>  train-loss=%.3f' % (total_loss/num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1)\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,248,504,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Relu]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23188/1256061772.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeledDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23188/749176885.py\u001b[0m in \u001b[0;36mtrainData\u001b[1;34m(dataset, EPOCHS)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23188/2122353946.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(image, groundTruth)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mfeature_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroundTruth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23188/1143928528.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_2_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_2_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact_2_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_2_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_2_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\activations.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[0;32m    310\u001b[0m       \u001b[0mTensor\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m   \"\"\"\n\u001b[1;32m--> 312\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(x, alpha, max_value, threshold)\u001b[0m\n\u001b[0;32m   4733\u001b[0m     \u001b[0mclip_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4734\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4735\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4737\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mclip_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(features, name)\u001b[0m\n\u001b[0;32m  10478\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10479\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m> 10480\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  10481\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10482\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6895\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6896\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6897\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6898\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,248,504,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu [Op:Relu]"
     ]
    }
   ],
   "source": [
    "trainData(labeledDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef preTraining(dataSet, cache=True, shuffle_buffer_size=1000):\\n    dataSet = dataSet.shuffle( buffer_size=shuffle_buffer_size )\\n    #dataSet = dataSet.repeat()\\n    dataSet = dataSet.batch(16) #batch size =32\\n    #dataSet = dataSet.prefetch(buffer_size = tf.data.AUTOTUNE)\\n    return dataSet\\ntrainDS = preTraining(labeledDataset)\\n#image_batch, label_batch = next(iter(trainDS))\\n#show_batch(image_batch.numpy(), label_batch.numpy())'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def preTraining(dataSet, cache=True, shuffle_buffer_size=1000):\n",
    "    dataSet = dataSet.shuffle( buffer_size=shuffle_buffer_size )\n",
    "    #dataSet = dataSet.repeat()\n",
    "    dataSet = dataSet.batch(16) #batch size =32\n",
    "    #dataSet = dataSet.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "    return dataSet\n",
    "trainDS = preTraining(labeledDataset)\n",
    "#image_batch, label_batch = next(iter(trainDS))\n",
    "#show_batch(image_batch.numpy(), label_batch.numpy())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Dimensions :  (512, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert to grayscale\n",
    "PATH = r\"G:\\\\Documents\\\\CROHME\\\\CROHME\\\\CROHME2013_data\\\\TrainINKML\\\\images\\\\expressmatch\\\\101_alfonso.jpg\"\n",
    "image = cv.imread(PATH)\n",
    "resized = cv.resize(image, (1024,512), interpolation = cv.INTER_AREA)\n",
    " \n",
    "print('Resized Dimensions : ',resized.shape)\n",
    " \n",
    "cv.imshow(\"Resized image\", resized)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "#grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\"\n",
    "path2 = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "for i in dirs:\n",
    "    images = os.listdir(path+'\\\\'+i)\n",
    "    files = os.listdir(path2+'\\\\'+i)\n",
    "    images = set(map( lambda x: x[:-4], images ))\n",
    "    files = set(map( lambda x: x[:-6], files ))\n",
    "    print(images.difference(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\\expressmatch\\65_alfonso.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros((16,1,3, 128))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
