{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "#import inkml2img\n",
    "import re\n",
    "import json\n",
    "#import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expressmatch', 'extension', 'HAMEX', 'KAIST', 'MathBrush', 'MfrDB']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"    for t in arr[i]:\\n    # si la extension no es .lg\\n    if ('.lg' not in t):\\n        # se llama a la funcion inkml2img del modulo hominimo, especificando la ruta del inkml y la ruta a guardar la imagen\\n        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\\n        print(t)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En esta celda se convierten los archivos inkml a .jpg con ayuda del modulo inkml2img\n",
    "# PATH indica la ubicacion de los archivos .inkml\n",
    "PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "# DIR_PATH indica el directorio donde se guardarán las imagenes\n",
    "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\"\n",
    "# se obtiene el nombre de las carpetas que contienen los archivos .inkml\n",
    "dataSets = os.listdir(PATH)\n",
    "# se genera una lista con listas vacias (la cantidad de carpetas en dataSets)\n",
    "arr = [[] for _ in range(len(dataSets))]\n",
    "print(dataSets)\n",
    "# se itera por cada carpeta de archivos .inkml\n",
    "for i in range(len(dataSets)):\n",
    "    # se agrega a la lista los archivos en determinada carpeta (la de la iteracion actual)\n",
    "    arr[i] = os.listdir(PATH+'\\\\'+dataSets[i])\n",
    "    # se itera por los archivos .inkml de la carpeta\n",
    "    for t in arr[i]:\n",
    "    # si la extension no es .lg\n",
    "    if ('.lg' not in t):\n",
    "        # se llama a la funcion inkml2img del modulo hominimo, especificando la ruta del inkml y la ruta a guardar la imagen\n",
    "        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en esta celda se obtienen los labels (el ground truth en latex) asociado a cada archivo .inkml\n",
    "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "LABELS_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\"\n",
    "# diccionario donde el ground truth se guardara para cada archivo\n",
    "items = {}\n",
    "index = 0\n",
    "count = 0\n",
    "# se itera por la cantidad de carpetas que contienen archivos .inkml\n",
    "for t in arr:\n",
    "    # se itera por cada archivo inkml\n",
    "    for i in t:\n",
    "        if (\".lg\" not in i):\n",
    "            # se obtiene el path del archivo concatenando DIR_PATH con el nombre de la carpeta y del archivo\n",
    "            imgPath = DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i\n",
    "            # dado que .inkml es un tipo de XML, tiene una estructura de arbol, por lo que se utiliza \n",
    "            # la funcion ET.parse para hacer uso de esta estructura\n",
    "            tree = ET.parse(imgPath)\n",
    "            # se otbiene la raiz del archivo (primera etiqueta en el .inkml)\n",
    "            root = tree.getroot()\n",
    "            count =0\n",
    "            # se itera por cada hijo de la raiz\n",
    "            for item in root:\n",
    "                # si el hijo posee texto entonces es posible que contenga el ground truth (label) deseado\n",
    "                if item.text:\n",
    "                    # existen tres posibilidades debido a la forma en que fueron codificados los archivos en distintas carpetas\n",
    "                    # el primero es que el groud truth en latex se encuetre entre simbolos de dolar $\n",
    "                    if \"$\" in item.text:\n",
    "                        current = item.text\n",
    "                        # se añade como key del diccionario el nombre del archivo y se le asocia el ground truth en latex\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
    "                        break\n",
    "                    if \"\\\\\" in item.text and dataSets[index] == \"MathBrush\":\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
    "                        break\n",
    "                    # para la carpeta KAIST el latex se encuentra sin elementos externos, por lo que se agrega sin mas\n",
    "                    if (count ==1 and dataSets[index]==\"KAIST\" and len(item.text)>2):\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current\n",
    "                        break\n",
    "                count +=1\n",
    "        else:\n",
    "            print(i)\n",
    "    index +=1 \n",
    "# se verifica que el comando log no se encuentre como una secuencia de letras separadas\n",
    "for key in items:\n",
    "    if ('l o g' in items[key]):\n",
    "        # si se encuentra se reemplaza por su respectivo comando en latex correcto\n",
    "        items[key] = items[key].replace('l o g', '\\\\log')\n",
    "# se guarda el diccionario en formato json\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\label.json\", 'w') as f:\n",
    "    json.dump(items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se realiza un filtrado de los groud truth para separar cada comando, letra y numero presente en el dataset\n",
    "# establece los comandos a borrar, ya que no proporcionan informacion relevante para la ecuacion\n",
    "delete = ['\\\\Bigg','\\\\left','\\\\right','\\\\Big','\\\\mathrm']\n",
    "# comandos a reemplazar por el comando latex correcto\n",
    "replace = {'\\\\to':'\\\\rightarrow', '\\\\gt':'>', '\\\\lt':'<'}\n",
    "# simbolos a los que se les añade espacios en blanco antes y despues para un mejor tratamiento\n",
    "add = ['_','{','}','=','(',')','-','+','^','[',']', ',']\n",
    "count = 0\n",
    "# se iteran los archivos .inkml, items representa el mismo diccionario guardado en labels.json\n",
    "for key in items:\n",
    "    # si existe alguno de los comandos descritos en las listas y diccionario anteriores se realizan la soperaciones\n",
    "    # correspondientes\n",
    "    for dele in delete:\n",
    "        if dele in items[key]:\n",
    "            items[key] = items[key].replace(dele, \"\")\n",
    "    for rep in replace:\n",
    "        if (rep in items[key]):\n",
    "            items[key] = items[key].replace(rep, replace[rep])\n",
    "    for it in add:\n",
    "        if (it in items[key]):\n",
    "            items[key] = items[key].replace(it, \" \"+it+\" \")\n",
    "    # se agrega un espacio en blanco antes de \\\\ para que pueda diferenciarse a los comandos del resto de letras o numeros\n",
    "    if ('\\\\' in items[key]):\n",
    "        items[key] = items[key].replace('\\\\', \" \\\\\")\n",
    "    # se separa el ground truth, siendo la condicion para separa el que existan uno o mas espacios en blanco entre caracteres\n",
    "    items[key] = re.split(r'\\s+', items[key])\n",
    "    count = 0\n",
    "    # se itera sobre la lista generada de letras, numeros, simbolos y comandos para cada archivo inkml\n",
    "    # separando los caracteres que se encuentren juntos y no sean parte de un comando, \n",
    "    # por ejemplo 'abc' se separa en 'a', 'b', 'c'\n",
    "    for a in items[key]:\n",
    "        if ('\\\\' not in a and len(a)>1):\n",
    "            uno = items[key][:count]\n",
    "            dos = re.split('', a)[1:-1]\n",
    "            tres = items[key][count+1:]\n",
    "            count+= len(dos)-1\n",
    "            uno.extend(dos)\n",
    "            uno.extend(tres)\n",
    "            items[key] = uno\n",
    "        count+=1\n",
    "    if (items[key][-1]==\"\"):\n",
    "        items[key] = items[key][:-1]\n",
    "    if (items[key][0]==\"\"):\n",
    "        items[key] = items[key][1:]\n",
    "# se guarda en labels.json\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\label.json\", 'w') as f:\n",
    "    json.dump(items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> S = ( \\sum _ { i = 1 } ^ { n } \\theta _ i - ( n - 2 ) \\pi ) r ^ 2 <end>\n"
     ]
    }
   ],
   "source": [
    "# se instancia la llamada a la funcion Tokenizer de tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# se define el numero maximo de palabras a tokenizar\n",
    "num_words = 1000\n",
    "# token para labels desconocidas\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "items = {}\n",
    "# se obtienen las listas de labels (numeros, comandos latex, simbolos y letras) para cada archivo inkml\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'r') as f:\n",
    "    items = json.load(f)\n",
    "tokens = {}\n",
    "count = 0\n",
    "# se itera para cada archivo\n",
    "for key in items:\n",
    "    # se convierte a string\n",
    "    items[key] = ' '.join(map(str, items[key]))\n",
    "    # se anade al inicio y final los labels start y end para indicar inicio y final del ground truth\n",
    "    items[key] = '<start> '+items[key] + ' <end>'\n",
    "    # se vuelven a separar\n",
    "    items[key] = re.sub(r\"\\s+\", \" \", items[key])\n",
    "# se obtiene la cantidad de archvios inkml a tratar\n",
    "keys = list(items.keys())\n",
    "# se anade el groud truth de cada archivo a una lista\n",
    "data = [ items[key] for key in keys ]\n",
    "print(data[0])\n",
    "# se instancia la funcion tokenizer con los parametros establecidos en un principio\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token, filters='', lower=False)\n",
    "# se obtienen los tokens para el conjunto de datos, es decir, a cada comando de latex, letra, numero o simbolo\n",
    "# utilizado se le asigna un numero entero en base a su frecuencia de aparicion\n",
    "tokenizer.fit_on_texts(data)\n",
    "# se define la cantidad de palabras o tokens\n",
    "word_index = tokenizer.word_index\n",
    "# se guardan los tokens en tokens.json\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\tokens.json\", 'w') as f:\n",
    "    json.dump(word_index, f, indent=4)\n",
    "# se convierten los labels a tokens para cada archivo inkml\n",
    "# por ejemplo ['a','b','c'] se convierte a [1,2,3] asumiendo que estos son sus tokens\n",
    "train_sequences = tokenizer.texts_to_sequences(data)\n",
    "# se obtiene la longitud del label mas grande\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "# se asocian los tokens a cada archivo haciendo un pad hacia la maxima longitud\n",
    "# tal que todos los archivos tenga por label una lista de la misma longitud, rellenando con ceros\n",
    "# aquellos tokens que se encuentran en una longitud mayor al verdadero para determinado archivo\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "files_imgs = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\tokens.json\", 'r') as f:\n",
    "    tokens = json.load(f)\n",
    "tokensPerFile = {}\n",
    "items = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'r') as f:\n",
    "    items = json.load(f)\n",
    "# se guardab los tokens por archivo inkml haciendo referencia ahora a la imagen \n",
    "# generada a partir del archvio inkml\n",
    "for key in items:\n",
    "    newKey = LABELS_PATH +'\\\\images'+ key[len(LABELS_PATH)+11:][:-6]+'.jpg'\n",
    "    tokensPerFile[newKey] = []\n",
    "    files_imgs[newKey] = key\n",
    "    for command in items[key]:\n",
    "        tokensPerFile[newKey].append(tokens[command])\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labelsPerFile.json\", 'w') as f:\n",
    "    json.dump(tokensPerFile, f, indent=4)\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\files_img.json\", 'w') as f:\n",
    "    json.dump(files_imgs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 1024, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 510, 1022, 32 320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 510, 1022, 32 128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 510, 1022, 32 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 508, 1020, 32 9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 508, 1020, 32 128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 508, 1020, 32 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 506, 1018, 32 9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 506, 1018, 32 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 506, 1018, 32 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 504, 1016, 32 9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 504, 1016, 32 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 504, 1016, 32 128         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 504, 1016, 32 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 252, 508, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 250, 506, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 250, 506, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 250, 506, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 248, 504, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 248, 504, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 248, 504, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 246, 502, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 246, 502, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 246, 502, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 244, 500, 64) 36928       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 244, 500, 64) 0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 244, 500, 64) 256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 244, 500, 64) 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 122, 250, 64) 0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 120, 248, 64) 36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 120, 248, 64) 256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 120, 248, 64) 0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 118, 246, 64) 36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 118, 246, 64) 256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 118, 246, 64) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 116, 244, 64) 36928       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 116, 244, 64) 256         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 116, 244, 64) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 114, 242, 64) 36928       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 114, 242, 64) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 114, 242, 64) 256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 114, 242, 64) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 57, 121, 64)  0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 60, 128)  73856       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 60, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 28, 60, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 13, 29, 128)  147584      activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 29, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 13, 29, 128)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 6, 14, 128)   147584      activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             multiple             0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 6, 14, 128)   512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 6, 14, 128)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 2, 6, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2, 6, 128)    512         dropout_3[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2, 6, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 3, 128)    0           activation_15[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 826,272\n",
      "Trainable params: 823,968\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# se define la arquitectura del encoder en base a Zhang (2017)\n",
    "class FCN_encoder(tf.keras.Model):\n",
    "    def __init__(self, dropout_rate = 0.2):\n",
    "        super(FCN_encoder, self).__init__()\n",
    "        # super dentro del constructor permite que la clase herede y se convierta en un objeto de Keras\n",
    "        \n",
    "        # bloque de convolucion 1, 32 filtros\n",
    "        self.conv_1_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_3 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_4 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.drop_1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_1_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_4 = tf.keras.layers.Activation('relu')\n",
    "        \n",
    "        # maxpooling para reducir el tamaño\n",
    "        self.maxPool_1 = tf.keras.layers.MaxPooling2D()\n",
    "        \n",
    "        # bloque convolucional 2, 64 filtros\n",
    "        self.conv_2_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.drop_2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_2_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_2 = tf.keras.layers.MaxPooling2D()\n",
    "\n",
    "        self.conv_3_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.drop_3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_3_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_3 = tf.keras.layers.MaxPooling2D()\n",
    "\n",
    "        self.conv_4_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.drop_4 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_4_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_4 = tf.keras.layers.MaxPooling2D()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.conv_1_1(inputs)\n",
    "        x = self.batch_1_1(x)\n",
    "        x = self.act_1_1(x)\n",
    "        x = self.conv_1_2(x)\n",
    "        x = self.batch_1_2(x)\n",
    "        x = self.act_1_2(x)\n",
    "        x = self.conv_1_3(x)\n",
    "        x = self.batch_1_3(x)\n",
    "        x = self.act_1_3(x)\n",
    "        x = self.conv_1_4(x)\n",
    "        x = self.drop_1(x)\n",
    "        x = self.batch_1_4(x)\n",
    "        x = self.act_1_4(x)\n",
    "        x = self.maxPool_1(x)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.batch_2_1(x)\n",
    "        x = self.act_2_1(x)\n",
    "        x = self.conv_2_2(x)\n",
    "        x = self.batch_2_2(x)\n",
    "        x = self.act_2_2(x)\n",
    "        x = self.conv_2_3(x)\n",
    "        x = self.batch_2_3(x)\n",
    "        x = self.act_2_3(x)\n",
    "        x = self.conv_2_4(x)\n",
    "        x = self.drop_2(x)\n",
    "        x = self.batch_2_4(x)\n",
    "        x = self.act_2_4(x)\n",
    "        x = self.maxPool_2(x)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.batch_3_1(x)\n",
    "        x = self.act_3_1(x)\n",
    "        x = self.conv_3_2(x)\n",
    "        x = self.batch_3_2(x)\n",
    "        x = self.act_3_2(x)\n",
    "        x = self.conv_3_3(x)\n",
    "        x = self.batch_3_3(x)\n",
    "        x = self.act_3_3(x)\n",
    "        x = self.conv_3_4(x)\n",
    "        x = self.drop_3(x)\n",
    "        x = self.batch_3_4(x)\n",
    "        x = self.act_3_4(x)\n",
    "        x = self.maxPool_3(x)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.batch_4_1(x)\n",
    "        x = self.act_4_1(x)\n",
    "        x = self.conv_4_2(x)\n",
    "        x = self.batch_4_2(x)\n",
    "        x = self.act_4_2(x)\n",
    "        x = self.conv_4_3(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = self.batch_4_3(x)\n",
    "        x = self.act_4_3(x)\n",
    "        x = self.conv_4_4(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = self.batch_4_4(x)\n",
    "        x = self.act_4_4(x)\n",
    "        x = self.maxPool_4(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def model(self):\n",
    "        input = tf.keras.layers.Input(shape=(512, 1024, 1))\n",
    "        return tf.keras.Model(inputs = input, outputs = self.call(input) )\n",
    "print(FCN_encoder().model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el modelo de atencion\n",
    "class Attender(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Attender, self).__init__()\n",
    "        # se instancia los distintos dense layers parametrizados en Zhang\n",
    "        self.W_1 = tf.keras.layers.Dense(128)\n",
    "        self.U_a = tf.keras.layers.Dense(128)\n",
    "        # la dimension de atencion es 128\n",
    "        self.V_a = tf.keras.layers.Dense(128)\n",
    "        #self.F = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2)\n",
    "    \n",
    "    def call(self, a, h):\n",
    "        # se espanden dimensiones para el hidden state\n",
    "        h_t = tf.expand_dims(h, 1)\n",
    "        # se calcula el estado intermedio llamando a los dense layers y la funcion de tangente \n",
    "        # hiperbolica con la suma de los dos dense layers que reciben como parametro el hidden state\n",
    "        # y el vector de anotacion\n",
    "        e_ti = self.V_a( (tf.nn.tanh( self.W_1(h_t) + self.U_a(a))))\n",
    "        # se aplica la activacion softmax al resultado\n",
    "        a_ti = tf.nn.softmax(e_ti)\n",
    "        # se calcula el vector de contexto multiplicando los coeficientes a_ti por el vector de anotacion\n",
    "        context = a_ti * a\n",
    "        # se obtiene la suma del resutado de la multiplicacion anterior\n",
    "        context = (tf.reduce_sum(tf.reduce_sum(context, axis =1), axis=1))\n",
    "        # se regresa el vector de contexto y los coeficientes a_ti\n",
    "        return context, a_ti       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ = None\n",
    "# se define el modelo decoder que utiliza el gru\n",
    "class GRU_decoder(tf.keras.Model):\n",
    "    def __init__(self, dimension, units, label_len):\n",
    "        super(GRU_decoder, self).__init__()\n",
    "        # las unidades del gru\n",
    "        self.units = units\n",
    "        # la capa de embedding, establecida en Zhang como E\n",
    "        self.embedding = tf.keras.layers.Embedding(label_len, dimension)\n",
    "        # la capa del gru, se especifica que se desea el regreso de las secuencias y el ultimo estado calculado\n",
    "        self.gru = tf.keras.layers.GRU( self.units, return_sequences=True, return_state = True, recurrent_initializer='glorot_uniform')\n",
    "        # dense layers para el calculo de las probabilidades para cada palabra en el diccionario de palabras\n",
    "        # es decir, los tokens\n",
    "        self.fc1 = tf.keras.layers.Dense(128)\n",
    "        self.fc2 = tf.keras.layers.Dense(128)#,activation='softmax')\n",
    "        self.fc3 = tf.keras.layers.Dense(128)\n",
    "        # la ultima capa se define con una activacion softmax\n",
    "        self.fc4 = tf.keras.layers.Dense(127, activation='softmax')\n",
    "        # se instancia el modelo de atencion\n",
    "        self.attention = Attender()\n",
    "        self.g = None\n",
    "      \n",
    "    def call(self, x, a, h):\n",
    "        # la llamada recibe la entrada del decoder, la salida del encoder y el estado anterior del decoder\n",
    "        # se llama al modelo de atencion y se recibe el vector de contexto y los coeficientes de atencion\n",
    "        context_v, attention_pro = self.attention(a,h)\n",
    "        x = self.embedding(x)\n",
    "        #x = tf.reduce_sum(x, axis = 1)\n",
    "        # se anade el contexto a la entrada del decoder para utilizar el conocimeinto previo\n",
    "        t = tf.concat([context_v,x], axis =-1)\n",
    "        t = tf.expand_dims(t, 1)\n",
    "        # se alimenta al gru con dicha informacion y se obtiene una salida y su ultimo estado\n",
    "        out, state = self.gru(t)\n",
    "        out = tf.reduce_sum(out, axis=1)\n",
    "        self.g = out\n",
    "        \n",
    "        # es necesario calcular las probabilidades condicionales, por lo que se utiliza \n",
    "        # lo descrito por Zhang para cada parte de la salida del gru\n",
    "        a = self.fc1(out)\n",
    "        b = self.fc2(context_v)\n",
    "        c = self.fc3(x)\n",
    "        # se suman los resultados\n",
    "        res = a+b+c\n",
    "        # se obtienen las probabilidades gracias al softmax del ultimo layer\n",
    "        res = self.fc4(res)\n",
    "        #print(res.shape)\n",
    "        #x = tf.argmax(res, 1)\n",
    "        # se regresan las probabilidades, el estado y los coeficientes de atencion\n",
    "        return res, state, attention_pro\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "    def reset(self, batch):\n",
    "        return tf.zeros((batch,3, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isntanciacion del encoder\n",
    "encoder = FCN_encoder()\n",
    "# isntanciacion del decoder, con valores para la dimension del embedding, del gru y la cantidad de tokens\n",
    "decoder = GRU_decoder(128,128,len(list(word_index.keys())))\n",
    "# se define una funcion de optimizacion para el modelo, el cual permite realizar la optimizacion en base\n",
    "# al gradiente de los errores\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# definimos el tipo de calculo para los errores entre los correspondientes labels del ground truth de cada\n",
    "# imagen y las predicciones\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
    "\n",
    "# se define una fucnion de loss (perdida o error) que recibe como parametro un label del ground truth por imagen \n",
    "# en el batch las matrices de prediccion asociadas a cada una de esas imagenes\n",
    "def loss_function(real, pred):\n",
    "    # se realiza una conversion del tipo de dato para las probabilidades de las predicciones\n",
    "    pred = tf.cast(pred, tf.float32)\n",
    "    # se establece una mascara para aquellas imagenes cuyo label sea 0, es decir, que\n",
    "    # es el padding agregado y que de esta forma no se considere su error para el error general\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    # se calcula el error\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    # se anade la mascara al los obtenido\n",
    "    loss_ *= mask\n",
    "    # se retorna la media de las perdidas para las imagenes en el batch\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "# se obtienen los tokens por imagen\n",
    "LABELS_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\"\n",
    "with open(LABELS_PATH+'\\\\labelsPerFile.json',  'r') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (512, 1024, 1)\n",
      "Label:  [ 4  7 32 13 10  9 28 14  9 28 98  5  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "files_img = {}\n",
    "# se obtienen los nombres de las imagenes\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\files_img.json\", 'r') as f:\n",
    "    files_img = json.load(f)\n",
    "    f.close()\n",
    "keys = list(files_img.keys())\n",
    "# se obtiene el dataset a partir del diccionario que contiene los tokens por archivo\n",
    "list_ds = tf.data.Dataset.list_files(list(data.keys()))\n",
    "\n",
    "# funcion que obtiene la imagen y su label, tiene como parametro el path de la imagen\n",
    "def getProcessedImages(f):\n",
    "    index = keys.index(f)\n",
    "    # se lee la imagen\n",
    "    image = tf.io.read_file(f)\n",
    "    # se decodifica el formato jpg y se establece como imagen en un solo canal, es decir\n",
    "    # blanco y negro\n",
    "    image = tf.image.decode_jpeg(image, channels = 1)  \n",
    "    # se convierte su tipo de dato a flotante\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # se redimensiona para que concuerde con el modelo del encoder\n",
    "    image = tf.image.resize(image, [512, 1024] ) \n",
    "    # se retorna la imagen (su matriz de pixels) y su label\n",
    "    return image, train_padded[index] #[data[str(tf.constant(f).numpy())[2:-1].replace('\\\\\\\\', '\\\\') ]]\n",
    "    \n",
    "# define el dataset a utilizar como un mapeo de los archvios dentro de list_ds que manda llamar a la funcion getProcessedImages\n",
    "labeledDataset = list_ds.map(lambda x: tf.py_function(getProcessedImages, [x], [tf.float32, tf.int32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# solo para verificar que funciona, imprime las dimensioens de la imagen y su label\n",
    "for image, label in labeledDataset.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se establece el tamano de batch como 8, es decir, se ingresara al entrenamiento paquetes de 8 imagenes\n",
    "labeledDataset = labeledDataset.batch(8)\n",
    "#labeledDataset = labeledDataset.prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# se define la funcion que entrena al modelo de encoder-decoder\n",
    "# recibe como parametros el batch de imagenes y su ground truth (labels)\n",
    "def train(image, groundTruth):\n",
    "    loss = 0\n",
    "    # el estado del gru se inicializa como ceros\n",
    "    hidden = decoder.reset(groundTruth.shape[0])\n",
    "    # el input del decoder se inicializa como un tensor con valores para el primer token en todas las imagenes\n",
    "    input_decoder = tf.constant([word_index['<start>']] * groundTruth.shape[0])\n",
    "    #input_decoder = tf.expand_dims([[word_index['<start>']]*3] * groundTruth.shape[0], 1)\n",
    "    #print(input_decoder.shape, hidden.shape)\n",
    "    # ciclo que permite el entrenamiento al generar un entorno donde las variables de entrenamiento son 'vigiladas'\n",
    "    # durante el entrenamiento para poder corregirlas y ajusstar el modelo\n",
    "    count = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        # se llama al encoder con la imagen la cual regresa el feature map con las caracteristicas extraidas de la imagen\n",
    "        feature_map = encoder(image)\n",
    "        # se itera por la cantidad de posibles palabras en un groundTruth\n",
    "        for i in range(1, groundTruth.shape[1]):\n",
    "            count +=1\n",
    "            # para cada palabra se verifica si su tensor corresponde a solo valores en cero, para lo cual se rompe el ciclo\n",
    "            # terminando el entrenamiento de este batch\n",
    "            sum_ = tf.reduce_sum(groundTruth[:,i])\n",
    "            allZero = tf.equal(sum_, 0)\n",
    "            if (allZero):\n",
    "                break\n",
    "            # si existe por lo menos un label por predecir entonces se llama al decoder envindole \n",
    "            # su respectivo input, las salidas del encoder y el hidden state anterior\n",
    "            pred, hidden, alphas = decoder(input_decoder, feature_map, hidden)\n",
    "            #print(groundTruth[:,i], pred.shape, hidden.shape, alphas.shape)\n",
    "            # se calcula el error de las predicciones y se suma al actual para el batch\n",
    "            loss += loss_function(groundTruth[:, i], pred)\n",
    "            #print(i,\"loss:\", loss)\n",
    "            # la siguiente entrada para el decoder son las anotaciones para la iteracion actual\n",
    "            # es decir, la anterior para la siguiente interacion (h-1)\n",
    "            input_decoder = groundTruth[:, i]\n",
    "    # una vez que termina la entrada del batch se calcula el error total con el error obtenido\n",
    "    total_loss = (loss / count)\n",
    "    # se obtienen las variables a las que se les puede modificar los parametros para ajustarlas (entrenarlas)\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    # se obtiene el gradiente de error en base al error obtenido\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    # se realiza el ajuste en base al gradiente de error\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    # se regresa el error y el error total\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que itera sobre el dataset para entrenarlo\n",
    "def trainData(dataset, EPOCHS = 2):\n",
    "    print(len(dataset))\n",
    "    # se itera por las epocas de entrenamiento\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        num = 0\n",
    "        # para cada batch de images en el dataset\n",
    "        for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "            # se llama a la funcion de entrenamiento para cada batch enviando el tensor de imagenes y de labels\n",
    "            # obteniendo los erroes\n",
    "            print(\"batch\",batch+1, end=\" \")\n",
    "            batch_loss, t_loss = train(img_tensor, target)\n",
    "            print(t_loss, end=\"\\n\")\n",
    "            total_loss += t_loss\n",
    "            num +=1\n",
    "            '''if ((batch +1)%10 ==0 ):\n",
    "                break'''\n",
    "        print('Epoch {0:d}/{1:d}'.format(epoch+1, EPOCHS))\n",
    "        print('===============>  train-loss=%.3f' % (total_loss/num))\n",
    "        encoder.save_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{0}.h5\".format(epoch))\n",
    "        decoder.save_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec\\epoch{0}.h5\".format(epoch),\n",
    "                    save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "batch 1 tf.Tensor(3.2298903, shape=(), dtype=float32)\n",
      "batch 2 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4440/1993992813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# se llama la funcion principal de entrenamiento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeledDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4440/2752474234.py\u001b[0m in \u001b[0;36mtrainData\u001b[1;34m(dataset, EPOCHS)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# obteniendo los erroes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4440/3652842491.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(image, groundTruth)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mtrainable_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m# se obtiene el gradiente de error en base al error obtenido\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;31m# se realiza el ajuste en base al gradiente de error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           data_format=data_format),\n\u001b[1;32m--> 591\u001b[1;33m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[0;32m    592\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[0mshape_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1077\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   1080\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Conv2DBackpropFilter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# se llama la funcion principal de entrenamiento\n",
    "trainData(labeledDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.save(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{}\".format(EPOCH))\n",
    "decoder.save_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec1.h5\",\n",
    "                    save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "SEPARACION\n",
      "[<tf.Variable 'gru_decoder_3/embedding_3/embeddings:0' shape=(127, 128) dtype=float32, numpy=\n",
      "array([[-0.01477681, -0.00083109,  0.0246141 , ..., -0.02491452,\n",
      "         0.01436717,  0.04005599],\n",
      "       [ 0.0266441 ,  0.03006789, -0.01880538, ..., -0.02905656,\n",
      "        -0.03080729,  0.02648106],\n",
      "       [ 0.00509453,  0.01611452,  0.02640239, ...,  0.00314472,\n",
      "        -0.03507783, -0.02023392],\n",
      "       ...,\n",
      "       [ 0.00990045,  0.04260354, -0.01738317, ..., -0.04194837,\n",
      "        -0.00976751, -0.02747607],\n",
      "       [ 0.04997372, -0.04390636, -0.04418349, ...,  0.01049598,\n",
      "         0.04968127, -0.04424227],\n",
      "       [-0.03353405,  0.02352481, -0.03084638, ...,  0.01700519,\n",
      "         0.03782406,  0.04353401]], dtype=float32)>, <tf.Variable 'gru_decoder_3/gru_3/gru_cell_3/kernel:0' shape=(256, 384) dtype=float32, numpy=\n",
      "array([[-0.0769023 ,  0.07694457,  0.03505715, ..., -0.06062751,\n",
      "         0.07975876, -0.04656413],\n",
      "       [ 0.09587385, -0.05393796, -0.03405109, ...,  0.04376782,\n",
      "        -0.07464743,  0.0318906 ],\n",
      "       [ 0.09424929, -0.07506758,  0.04569662, ..., -0.04786265,\n",
      "        -0.00724045, -0.06318609],\n",
      "       ...,\n",
      "       [-0.04910183, -0.07372338,  0.08936629, ...,  0.05779987,\n",
      "        -0.00584819, -0.0240369 ],\n",
      "       [-0.09976105, -0.08450963,  0.02652964, ..., -0.02086792,\n",
      "         0.03842227,  0.08699107],\n",
      "       [-0.08747969,  0.03058947, -0.01535956, ...,  0.03144246,\n",
      "         0.07977846,  0.08105452]], dtype=float32)>, <tf.Variable 'gru_decoder_3/gru_3/gru_cell_3/recurrent_kernel:0' shape=(128, 384) dtype=float32, numpy=\n",
      "array([[ 0.03494161,  0.01195532, -0.08232992, ...,  0.06990976,\n",
      "         0.00032134,  0.05519758],\n",
      "       [-0.10787607, -0.04619246,  0.10295258, ..., -0.01654525,\n",
      "        -0.08555999,  0.02606373],\n",
      "       [ 0.08598291,  0.0301372 ,  0.08195866, ..., -0.01991971,\n",
      "         0.07182836,  0.09121146],\n",
      "       ...,\n",
      "       [ 0.08122233,  0.04019061, -0.06323885, ..., -0.0623988 ,\n",
      "         0.01934328,  0.09036908],\n",
      "       [-0.03111368, -0.08860506, -0.03817499, ...,  0.06481391,\n",
      "        -0.06972805, -0.03921236],\n",
      "       [ 0.07512025,  0.06058076,  0.06743918, ...,  0.06885374,\n",
      "        -0.00040853,  0.05268966]], dtype=float32)>, <tf.Variable 'gru_decoder_3/gru_3/gru_cell_3/bias:0' shape=(2, 384) dtype=float32, numpy=\n",
      "array([[-3.5316984e-03,  1.3805843e-03, -3.8111592e-03, -1.8161784e-03,\n",
      "         2.2106846e-03, -3.7218714e-03, -3.5874625e-03, -4.9777277e-04,\n",
      "        -2.9089330e-03, -1.0881848e-03, -3.6242635e-03, -3.6213556e-03,\n",
      "         8.7473594e-04, -3.1653342e-03,  1.5997252e-03, -3.8291642e-03,\n",
      "         3.7289415e-03,  2.8115052e-03,  3.4680191e-04,  2.0901843e-03,\n",
      "        -3.7124348e-03, -3.5365450e-03,  1.1319830e-04, -3.7093342e-03,\n",
      "        -3.5054232e-03, -3.6964582e-03,  2.2296838e-03, -3.9739218e-03,\n",
      "        -3.5280890e-03,  3.0434639e-03, -3.4288031e-03, -3.4556119e-03,\n",
      "        -3.5439930e-03,  2.7513660e-03, -1.2911521e-03, -5.0597766e-04,\n",
      "        -3.8835641e-03,  2.4074647e-03, -1.9334055e-03,  2.6686299e-03,\n",
      "        -1.0062619e-03, -3.6021629e-03, -3.5854101e-03, -2.8222296e-03,\n",
      "        -3.5115296e-03, -3.7674808e-03, -3.8083333e-03, -3.6876150e-03,\n",
      "         3.4267292e-03, -3.6260709e-03,  2.4553840e-03, -3.8515111e-03,\n",
      "         3.4270836e-03, -3.4882131e-03,  4.5787287e-04, -1.1400882e-03,\n",
      "         2.1370121e-03, -3.8606324e-03, -1.2656315e-03, -3.4833874e-03,\n",
      "         6.8375724e-04, -3.6726398e-03,  1.8615081e-03, -3.6364747e-03,\n",
      "        -2.4095285e-03,  3.2927468e-03, -2.1220245e-03,  3.4592897e-03,\n",
      "         2.7600743e-03,  2.4200738e-03,  2.4817893e-03, -3.4205620e-03,\n",
      "         3.1333670e-03, -3.8389787e-03, -3.5288376e-03,  1.8050760e-03,\n",
      "         1.3583461e-03, -3.5481136e-03, -3.7848847e-03, -3.3551934e-03,\n",
      "        -3.4640082e-03, -3.7862530e-03,  3.5973603e-03,  7.4283336e-05,\n",
      "         2.8083688e-03, -3.4899011e-03,  1.4302775e-03, -5.7329045e-04,\n",
      "         2.0951784e-04, -3.7639444e-03, -1.4932570e-03, -3.6707269e-03,\n",
      "         3.5972670e-03,  3.8437871e-03,  1.9043006e-03,  4.7470519e-04,\n",
      "         1.4005622e-03, -9.7464153e-04,  3.8305796e-03, -3.7006228e-03,\n",
      "        -2.2931707e-03, -1.2755708e-03,  1.8780376e-03, -3.6015464e-03,\n",
      "        -3.8263297e-03,  2.1096664e-03, -3.3605373e-03, -3.6807123e-03,\n",
      "         1.8385709e-03,  2.2416077e-04,  1.2732272e-03, -1.3504404e-03,\n",
      "         3.4890417e-03, -3.5267326e-03, -1.2370108e-03,  2.1518692e-03,\n",
      "         1.4437258e-03, -3.5538026e-03,  2.3786623e-03, -1.2333437e-03,\n",
      "         1.7382992e-03,  2.5135139e-03, -3.5190058e-03, -3.5752764e-03,\n",
      "         3.4270850e-03, -6.0343277e-04,  9.6271886e-04, -3.3191997e-03,\n",
      "         3.2414515e-03,  1.2333083e-03,  3.5776617e-03,  1.6109329e-03,\n",
      "        -2.4140419e-03, -2.3941356e-03,  1.2293728e-03,  3.4474744e-03,\n",
      "         3.8829900e-03, -1.9469580e-03,  3.7362515e-03,  3.3910484e-03,\n",
      "        -2.4858918e-03, -1.5020721e-03,  3.6244090e-03, -1.9915809e-04,\n",
      "        -2.3811194e-03, -2.7424397e-03, -1.8108436e-03, -8.0717239e-04,\n",
      "        -1.4612204e-03, -1.8794481e-03,  2.0490128e-03,  6.0192263e-04,\n",
      "         5.4241158e-05,  3.7275860e-03, -3.8656404e-03, -3.9042630e-03,\n",
      "         3.6618353e-03, -1.0292034e-03, -2.0033862e-03, -1.5597693e-03,\n",
      "         9.7865867e-04, -1.5727375e-03,  1.5120517e-03,  3.8647854e-03,\n",
      "         3.7976247e-03, -3.6872472e-03,  3.5535805e-03, -2.3435482e-03,\n",
      "        -3.9202296e-03,  5.1572721e-04,  3.4901747e-03, -4.4387649e-05,\n",
      "         3.4649433e-03,  4.0730450e-04,  2.6968166e-03, -2.5867887e-03,\n",
      "         3.6501391e-03, -3.5567121e-03, -3.1296273e-03,  3.9504236e-03,\n",
      "         3.4620026e-03,  3.1640562e-03, -3.6851217e-03, -3.1883528e-03,\n",
      "        -1.9388292e-03,  3.5391825e-03,  3.4293816e-03,  3.2806345e-03,\n",
      "         1.8659563e-04,  2.1561536e-03, -1.0244156e-03,  3.6042838e-03,\n",
      "         6.8449517e-05, -3.1909880e-03, -1.0346456e-03,  3.2229708e-03,\n",
      "        -1.0218653e-03,  3.0201378e-03,  3.6029010e-03,  1.7197034e-03,\n",
      "        -3.5722330e-03,  3.1247518e-03,  3.3430019e-03, -1.0956535e-03,\n",
      "         2.4514827e-03,  3.3005406e-03, -3.9723446e-03,  1.6454783e-03,\n",
      "        -3.7368180e-03, -2.3153394e-03, -3.5333172e-03,  3.8105145e-03,\n",
      "         2.4201358e-03,  3.2506145e-03,  3.7348695e-04, -1.8905421e-03,\n",
      "         3.8663184e-03,  2.8757143e-03, -1.6084430e-03,  3.6814772e-03,\n",
      "        -3.5932474e-03,  3.8468996e-03, -2.3875420e-03,  3.3354971e-03,\n",
      "        -8.5200369e-04, -3.6289445e-03, -2.5598397e-03, -1.3912264e-03,\n",
      "        -2.3123908e-03, -1.8941292e-03, -3.1246322e-03,  3.3599955e-03,\n",
      "         3.8441967e-03,  3.6575566e-03,  1.2594734e-03, -6.8758137e-04,\n",
      "        -2.3774798e-03, -1.4640093e-03, -3.9221868e-03,  3.0509871e-04,\n",
      "         2.2878703e-03,  3.3861583e-03, -3.7310740e-03, -3.4708783e-03,\n",
      "        -1.4706489e-03,  3.6618232e-03, -3.3916531e-03, -3.5290857e-04,\n",
      "         1.7320621e-05, -3.9622425e-03,  3.6598211e-03,  3.6841095e-03,\n",
      "        -3.1540368e-03,  3.2892674e-03,  3.3810141e-03,  2.8443986e-03,\n",
      "         3.8645547e-03,  3.4456083e-03, -3.8367084e-03, -3.6243005e-03,\n",
      "        -2.9623820e-03,  3.8804724e-03, -3.7758283e-03,  3.6400040e-03,\n",
      "         3.9509302e-03,  3.9190915e-03, -3.8908054e-03,  3.9384328e-03,\n",
      "         2.5174371e-03,  1.4586218e-03,  3.9767888e-03, -3.9687250e-03,\n",
      "         1.2141380e-03, -1.3339492e-03,  4.4875684e-05, -6.4959779e-04,\n",
      "        -3.7181110e-03,  3.8642511e-03, -3.8023260e-03, -3.7294431e-03,\n",
      "         3.4973728e-03, -3.9621522e-03,  7.8637095e-04, -3.9890301e-03,\n",
      "        -3.9373385e-03, -2.1363252e-03, -1.0843195e-03, -3.8387182e-03,\n",
      "        -3.8150018e-03, -2.0644855e-04,  1.5334461e-03,  3.9718258e-03,\n",
      "        -3.8886596e-03,  3.4590403e-03,  3.5744454e-03, -4.8710793e-04,\n",
      "        -1.8561917e-04, -2.1031892e-04,  3.9478755e-03, -3.3447959e-03,\n",
      "        -3.6008758e-03,  3.8865302e-03,  3.9453832e-03, -3.7394222e-03,\n",
      "         3.6466955e-03,  1.3694958e-03, -2.4559831e-03, -3.9987126e-03,\n",
      "         3.6518024e-03,  3.6547200e-03, -3.9967084e-03,  3.3353898e-04,\n",
      "        -2.4091927e-03,  2.8315252e-03, -3.8850005e-03, -3.8617791e-03,\n",
      "        -3.5815872e-03, -3.8301593e-03, -3.7885243e-03,  3.8606410e-03,\n",
      "        -4.7468749e-04,  2.2186732e-03, -1.1032709e-05,  3.6707763e-03,\n",
      "         3.3235142e-03, -3.8722870e-03,  1.7962499e-03,  3.5908045e-03,\n",
      "        -3.2239873e-03,  3.9998293e-03, -3.9561801e-03, -3.0084001e-03,\n",
      "         3.0120246e-03,  3.8130144e-03, -3.8963072e-03,  3.6166511e-03,\n",
      "        -3.6843126e-03, -3.7936745e-03,  3.2021722e-03,  3.9412579e-03,\n",
      "        -2.3610669e-03,  3.9328798e-03,  4.0055942e-03, -3.8042078e-03,\n",
      "        -3.9513716e-03, -2.2051083e-03, -3.7254007e-03, -3.9125215e-03,\n",
      "        -3.2419225e-03, -3.9229449e-03, -5.3826347e-04, -3.3543725e-03,\n",
      "        -6.7382673e-04, -3.9650304e-03, -2.9654528e-03, -3.7488025e-03,\n",
      "        -3.7588745e-03, -3.6906942e-03, -1.7477733e-03, -1.0904165e-03,\n",
      "         3.8345237e-03,  5.2004075e-04, -3.6910940e-03,  3.6556353e-03,\n",
      "         2.1815479e-03, -3.6289943e-03, -3.9628465e-03, -1.3248809e-03,\n",
      "         4.4157612e-04, -3.6137064e-03,  3.3480693e-03, -3.8960679e-03,\n",
      "        -3.6165947e-03,  3.8921162e-03, -1.2440538e-03, -3.7391484e-03,\n",
      "        -1.4325239e-03, -3.8706977e-03,  3.9738743e-03,  3.9165332e-03,\n",
      "        -3.2812923e-03, -3.9620535e-03, -3.5901903e-03, -3.7869692e-03],\n",
      "       [-3.5316984e-03,  1.3805843e-03, -3.8111592e-03, -1.8161784e-03,\n",
      "         2.2106846e-03, -3.7218714e-03, -3.5874625e-03, -4.9777277e-04,\n",
      "        -2.9089330e-03, -1.0881848e-03, -3.6242635e-03, -3.6213556e-03,\n",
      "         8.7473594e-04, -3.1653342e-03,  1.5997252e-03, -3.8291642e-03,\n",
      "         3.7289415e-03,  2.8115052e-03,  3.4680191e-04,  2.0901843e-03,\n",
      "        -3.7124348e-03, -3.5365450e-03,  1.1319830e-04, -3.7093342e-03,\n",
      "        -3.5054232e-03, -3.6964582e-03,  2.2296838e-03, -3.9739218e-03,\n",
      "        -3.5280890e-03,  3.0434639e-03, -3.4288031e-03, -3.4556119e-03,\n",
      "        -3.5439930e-03,  2.7513660e-03, -1.2911521e-03, -5.0597766e-04,\n",
      "        -3.8835641e-03,  2.4074647e-03, -1.9334055e-03,  2.6686299e-03,\n",
      "        -1.0062619e-03, -3.6021629e-03, -3.5854101e-03, -2.8222296e-03,\n",
      "        -3.5115296e-03, -3.7674808e-03, -3.8083333e-03, -3.6876150e-03,\n",
      "         3.4267292e-03, -3.6260709e-03,  2.4553840e-03, -3.8515111e-03,\n",
      "         3.4270836e-03, -3.4882131e-03,  4.5787287e-04, -1.1400882e-03,\n",
      "         2.1370121e-03, -3.8606324e-03, -1.2656315e-03, -3.4833874e-03,\n",
      "         6.8375724e-04, -3.6726398e-03,  1.8615081e-03, -3.6364747e-03,\n",
      "        -2.4095285e-03,  3.2927468e-03, -2.1220245e-03,  3.4592897e-03,\n",
      "         2.7600743e-03,  2.4200738e-03,  2.4817893e-03, -3.4205620e-03,\n",
      "         3.1333670e-03, -3.8389787e-03, -3.5288376e-03,  1.8050760e-03,\n",
      "         1.3583461e-03, -3.5481136e-03, -3.7848847e-03, -3.3551934e-03,\n",
      "        -3.4640082e-03, -3.7862530e-03,  3.5973603e-03,  7.4283336e-05,\n",
      "         2.8083688e-03, -3.4899011e-03,  1.4302775e-03, -5.7329045e-04,\n",
      "         2.0951784e-04, -3.7639444e-03, -1.4932570e-03, -3.6707269e-03,\n",
      "         3.5972670e-03,  3.8437871e-03,  1.9043006e-03,  4.7470519e-04,\n",
      "         1.4005622e-03, -9.7464153e-04,  3.8305796e-03, -3.7006228e-03,\n",
      "        -2.2931707e-03, -1.2755708e-03,  1.8780376e-03, -3.6015464e-03,\n",
      "        -3.8263297e-03,  2.1096664e-03, -3.3605373e-03, -3.6807123e-03,\n",
      "         1.8385709e-03,  2.2416077e-04,  1.2732272e-03, -1.3504404e-03,\n",
      "         3.4890417e-03, -3.5267326e-03, -1.2370108e-03,  2.1518692e-03,\n",
      "         1.4437258e-03, -3.5538026e-03,  2.3786623e-03, -1.2333437e-03,\n",
      "         1.7382992e-03,  2.5135139e-03, -3.5190058e-03, -3.5752764e-03,\n",
      "         3.4270850e-03, -6.0343277e-04,  9.6271886e-04, -3.3191997e-03,\n",
      "         3.2414515e-03,  1.2333083e-03,  3.5776617e-03,  1.6109329e-03,\n",
      "        -2.4140419e-03, -2.3941356e-03,  1.2293728e-03,  3.4474744e-03,\n",
      "         3.8829900e-03, -1.9469580e-03,  3.7362515e-03,  3.3910484e-03,\n",
      "        -2.4858918e-03, -1.5020721e-03,  3.6244090e-03, -1.9915809e-04,\n",
      "        -2.3811194e-03, -2.7424397e-03, -1.8108436e-03, -8.0717239e-04,\n",
      "        -1.4612204e-03, -1.8794481e-03,  2.0490128e-03,  6.0192263e-04,\n",
      "         5.4241158e-05,  3.7275860e-03, -3.8656404e-03, -3.9042630e-03,\n",
      "         3.6618353e-03, -1.0292034e-03, -2.0033862e-03, -1.5597693e-03,\n",
      "         9.7865867e-04, -1.5727375e-03,  1.5120517e-03,  3.8647854e-03,\n",
      "         3.7976247e-03, -3.6872472e-03,  3.5535805e-03, -2.3435482e-03,\n",
      "        -3.9202296e-03,  5.1572721e-04,  3.4901747e-03, -4.4387649e-05,\n",
      "         3.4649433e-03,  4.0730450e-04,  2.6968166e-03, -2.5867887e-03,\n",
      "         3.6501391e-03, -3.5567121e-03, -3.1296273e-03,  3.9504236e-03,\n",
      "         3.4620026e-03,  3.1640562e-03, -3.6851217e-03, -3.1883528e-03,\n",
      "        -1.9388292e-03,  3.5391825e-03,  3.4293816e-03,  3.2806345e-03,\n",
      "         1.8659563e-04,  2.1561536e-03, -1.0244156e-03,  3.6042838e-03,\n",
      "         6.8449517e-05, -3.1909880e-03, -1.0346456e-03,  3.2229708e-03,\n",
      "        -1.0218653e-03,  3.0201378e-03,  3.6029010e-03,  1.7197034e-03,\n",
      "        -3.5722330e-03,  3.1247518e-03,  3.3430019e-03, -1.0956535e-03,\n",
      "         2.4514827e-03,  3.3005406e-03, -3.9723446e-03,  1.6454783e-03,\n",
      "        -3.7368180e-03, -2.3153394e-03, -3.5333172e-03,  3.8105145e-03,\n",
      "         2.4201358e-03,  3.2506145e-03,  3.7348695e-04, -1.8905421e-03,\n",
      "         3.8663184e-03,  2.8757143e-03, -1.6084430e-03,  3.6814772e-03,\n",
      "        -3.5932474e-03,  3.8468996e-03, -2.3875420e-03,  3.3354971e-03,\n",
      "        -8.5200369e-04, -3.6289445e-03, -2.5598397e-03, -1.3912264e-03,\n",
      "        -2.3123908e-03, -1.8941292e-03, -3.1246322e-03,  3.3599955e-03,\n",
      "         3.8441967e-03,  3.6575566e-03,  1.2594734e-03, -6.8758137e-04,\n",
      "        -2.3774798e-03, -1.4640093e-03, -3.9221868e-03,  3.0509871e-04,\n",
      "         2.2878703e-03,  3.3861583e-03, -3.7310740e-03, -3.4708783e-03,\n",
      "        -1.4706489e-03,  3.6618232e-03, -3.3916531e-03, -3.5290857e-04,\n",
      "         1.7320621e-05, -3.9622425e-03,  3.6598211e-03,  3.6841095e-03,\n",
      "        -3.1540368e-03,  3.2892674e-03,  3.3810141e-03,  2.8443986e-03,\n",
      "         3.8608471e-03,  3.4490624e-03, -3.8359987e-03, -3.6218343e-03,\n",
      "        -2.9707253e-03,  3.8817767e-03, -3.7770178e-03,  3.6386875e-03,\n",
      "         3.9503891e-03,  3.9196596e-03, -3.8892850e-03,  3.9397199e-03,\n",
      "         2.5258532e-03,  1.4587445e-03,  3.9764908e-03, -3.9689960e-03,\n",
      "         1.2189266e-03, -1.3406378e-03,  7.9200821e-05, -6.5760588e-04,\n",
      "        -3.7187086e-03,  3.8634818e-03, -3.7999288e-03, -3.7296584e-03,\n",
      "         3.4987442e-03, -3.9674500e-03,  7.8655279e-04, -3.9908523e-03,\n",
      "        -3.9285384e-03, -2.1413281e-03, -1.0838320e-03, -3.8388530e-03,\n",
      "        -3.8168854e-03, -2.0199438e-04,  1.5358694e-03,  3.9714472e-03,\n",
      "        -3.8882121e-03,  3.4531059e-03,  3.5728409e-03, -4.8422746e-04,\n",
      "        -1.7464595e-04, -2.3355128e-04,  3.9470717e-03, -3.3435854e-03,\n",
      "        -3.6009708e-03,  3.8857013e-03,  3.9454456e-03, -3.7391784e-03,\n",
      "         3.6512383e-03,  1.3694268e-03, -2.4502622e-03, -3.9958837e-03,\n",
      "         3.6486543e-03,  3.6575913e-03, -3.9970204e-03,  3.3338502e-04,\n",
      "        -2.4084477e-03,  2.8272434e-03, -3.8846447e-03, -3.8598226e-03,\n",
      "        -3.5881337e-03, -3.8288757e-03, -3.7844162e-03,  3.8618273e-03,\n",
      "        -4.7168299e-04,  2.2263094e-03, -2.7059054e-05,  3.6741097e-03,\n",
      "         3.3225045e-03, -3.8745622e-03,  1.7972306e-03,  3.5918029e-03,\n",
      "        -3.2290118e-03,  4.0003136e-03, -3.9562094e-03, -3.0231792e-03,\n",
      "         3.0108504e-03,  3.8147785e-03, -3.8951745e-03,  3.6165731e-03,\n",
      "        -3.6849445e-03, -3.7938352e-03,  3.2164282e-03,  3.9419709e-03,\n",
      "        -2.3451799e-03,  3.9320933e-03,  4.0051267e-03, -3.8040164e-03,\n",
      "        -3.9507523e-03, -2.1922928e-03, -3.7270195e-03, -3.9137257e-03,\n",
      "        -3.2455744e-03, -3.9232494e-03, -5.3817290e-04, -3.3526171e-03,\n",
      "        -6.7381008e-04, -3.9633978e-03, -2.9775465e-03, -3.7502213e-03,\n",
      "        -3.7593683e-03, -3.6935678e-03, -1.7581620e-03, -1.0807493e-03,\n",
      "         3.8325600e-03,  5.1974342e-04, -3.6935881e-03,  3.6564348e-03,\n",
      "         2.1844809e-03, -3.6335038e-03, -3.9619650e-03, -1.3267540e-03,\n",
      "         4.3140221e-04, -3.6133204e-03,  3.3485633e-03, -3.8968371e-03,\n",
      "        -3.6164857e-03,  3.8913260e-03, -1.2494043e-03, -3.7386143e-03,\n",
      "        -1.4132719e-03, -3.8703950e-03,  3.9711287e-03,  3.9167702e-03,\n",
      "        -3.2804280e-03, -3.9560609e-03, -3.5903987e-03, -3.7878833e-03]],\n",
      "      dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_21/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
      "array([[-0.13469002, -0.09698153, -0.10529198, ..., -0.05741825,\n",
      "        -0.01154371,  0.15088362],\n",
      "       [-0.01573418, -0.11805598,  0.14309484, ...,  0.03738417,\n",
      "         0.06824719, -0.07528434],\n",
      "       [ 0.06932022, -0.04166469, -0.06095231, ...,  0.13053529,\n",
      "         0.14383233,  0.06825558],\n",
      "       ...,\n",
      "       [ 0.10095392,  0.11675006,  0.12874283, ..., -0.13413388,\n",
      "        -0.08672056,  0.10443252],\n",
      "       [-0.11427003, -0.09030525, -0.03427633, ..., -0.08476032,\n",
      "         0.14675611,  0.00628569],\n",
      "       [-0.08918665, -0.12142435,  0.11627375, ...,  0.11729263,\n",
      "         0.05350652, -0.10668571]], dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_21/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.7696035e-03, -3.9939201e-03, -8.4220851e-04,  3.8790184e-03,\n",
      "        2.8454966e-03,  3.3035274e-03,  3.9376672e-03,  2.7238382e-03,\n",
      "        3.7646852e-03, -3.8737701e-03, -3.8580217e-03, -1.0797121e-03,\n",
      "        9.3619659e-05,  2.1801125e-03, -3.9457451e-03, -2.9061509e-03,\n",
      "        3.4411668e-03, -3.8172686e-03, -4.0112673e-03,  3.2280320e-03,\n",
      "       -3.9797635e-03,  1.6732516e-03, -3.7431424e-03, -9.0347987e-04,\n",
      "        2.3195654e-04, -3.9342451e-03, -3.3831364e-03, -3.8750807e-03,\n",
      "       -3.6924707e-03,  3.5275244e-03, -3.9256266e-03, -3.8858543e-03,\n",
      "       -3.7966536e-03, -1.3758859e-03, -1.9016949e-04,  3.9405883e-03,\n",
      "        3.6407204e-03,  1.1364101e-03, -4.0387036e-05,  3.9636213e-03,\n",
      "        3.8265516e-03, -3.7822924e-03, -3.8466845e-03,  3.8044218e-03,\n",
      "       -3.7101218e-03,  3.8489215e-03, -3.9646709e-03, -3.8030269e-03,\n",
      "        3.9214892e-03,  1.8505367e-03, -3.8876568e-03, -3.6957597e-03,\n",
      "        4.0026968e-03, -3.9349301e-03, -3.7633637e-03, -3.7768306e-03,\n",
      "        3.9282595e-03, -1.2492801e-03, -3.9413720e-03,  3.9973720e-03,\n",
      "        3.8600487e-03,  3.5267198e-03,  3.5848226e-03,  3.9654574e-03,\n",
      "        4.0093660e-03,  3.9562909e-03, -3.5626763e-03, -3.8414041e-03,\n",
      "       -2.9825887e-03, -3.9372761e-03, -3.8138051e-03, -3.9525917e-03,\n",
      "        3.8155767e-03,  3.8679207e-03, -3.0805767e-03, -3.2762308e-03,\n",
      "        3.7450860e-03, -8.3166210e-04, -9.9731935e-04, -3.6242320e-03,\n",
      "        3.8942515e-03,  3.9462298e-03, -3.9789593e-03,  3.8875255e-03,\n",
      "        8.8277954e-04, -3.9363769e-03, -3.8267402e-03, -3.5805239e-03,\n",
      "        3.3993723e-03,  3.7381437e-03, -3.8290243e-03, -3.8952492e-03,\n",
      "        3.7427589e-03, -1.6948740e-03,  3.9136950e-03, -1.9298631e-04,\n",
      "        3.9407955e-03, -3.5378125e-03, -3.6397246e-03, -3.2708880e-03,\n",
      "       -3.6940870e-03, -6.7671551e-04, -2.2371246e-03,  1.4276830e-03,\n",
      "        3.7421007e-03, -2.9670564e-03, -3.6575682e-03,  1.6490344e-03,\n",
      "        3.6578157e-03, -3.7497792e-03,  3.8009267e-03, -3.9312001e-03,\n",
      "       -3.7705121e-03,  2.3576620e-03,  3.9520813e-03, -1.9534659e-03,\n",
      "        2.7881954e-03,  3.7276957e-03, -3.9879493e-03,  3.6587233e-03,\n",
      "       -3.6866588e-03,  3.8723212e-03,  2.4757076e-03, -2.8262495e-03,\n",
      "       -3.6707674e-03, -3.7998180e-03,  3.8276668e-04,  2.2102993e-03],\n",
      "      dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_22/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
      "array([[-0.0284107 , -0.09675129,  0.07201632, ..., -0.08303388,\n",
      "        -0.12184164, -0.03151695],\n",
      "       [-0.0235902 , -0.06175324,  0.13199928, ..., -0.02206868,\n",
      "        -0.13351119,  0.06932936],\n",
      "       [ 0.13746627,  0.01628404, -0.12094424, ...,  0.08092465,\n",
      "         0.13763544,  0.02216087],\n",
      "       ...,\n",
      "       [-0.13255094,  0.14216448,  0.01579315, ...,  0.04955365,\n",
      "        -0.1410887 ,  0.09987   ],\n",
      "       [ 0.04258024,  0.14614597, -0.08648924, ..., -0.04697557,\n",
      "         0.14620449, -0.08346236],\n",
      "       [-0.12685342,  0.031149  ,  0.02610664, ...,  0.03908699,\n",
      "         0.10611794, -0.11270975]], dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_22/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.7696035e-03, -3.9939201e-03, -8.4220851e-04,  3.8790184e-03,\n",
      "        2.8454966e-03,  3.3035274e-03,  3.9376672e-03,  2.7238382e-03,\n",
      "        3.7646852e-03, -3.8737701e-03, -3.8580217e-03, -1.0797121e-03,\n",
      "        9.3619659e-05,  2.1801125e-03, -3.9457451e-03, -2.9061509e-03,\n",
      "        3.4411668e-03, -3.8172686e-03, -4.0112673e-03,  3.2280320e-03,\n",
      "       -3.9797635e-03,  1.6732516e-03, -3.7431424e-03, -9.0347987e-04,\n",
      "        2.3195654e-04, -3.9342451e-03, -3.3831364e-03, -3.8750807e-03,\n",
      "       -3.6924707e-03,  3.5275244e-03, -3.9256266e-03, -3.8858543e-03,\n",
      "       -3.7966536e-03, -1.3758859e-03, -1.9016949e-04,  3.9405883e-03,\n",
      "        3.6407204e-03,  1.1364101e-03, -4.0387036e-05,  3.9636213e-03,\n",
      "        3.8265516e-03, -3.7822924e-03, -3.8466845e-03,  3.8044218e-03,\n",
      "       -3.7101218e-03,  3.8489215e-03, -3.9646709e-03, -3.8030269e-03,\n",
      "        3.9214892e-03,  1.8505367e-03, -3.8876568e-03, -3.6957597e-03,\n",
      "        4.0026968e-03, -3.9349301e-03, -3.7633637e-03, -3.7768306e-03,\n",
      "        3.9282595e-03, -1.2492801e-03, -3.9413720e-03,  3.9973720e-03,\n",
      "        3.8600487e-03,  3.5267198e-03,  3.5848226e-03,  3.9654574e-03,\n",
      "        4.0093660e-03,  3.9562909e-03, -3.5626763e-03, -3.8414041e-03,\n",
      "       -2.9825887e-03, -3.9372761e-03, -3.8138051e-03, -3.9525917e-03,\n",
      "        3.8155767e-03,  3.8679207e-03, -3.0805767e-03, -3.2762308e-03,\n",
      "        3.7450860e-03, -8.3166210e-04, -9.9731935e-04, -3.6242320e-03,\n",
      "        3.8942515e-03,  3.9462298e-03, -3.9789593e-03,  3.8875255e-03,\n",
      "        8.8277954e-04, -3.9363769e-03, -3.8267402e-03, -3.5805239e-03,\n",
      "        3.3993723e-03,  3.7381437e-03, -3.8290243e-03, -3.8952492e-03,\n",
      "        3.7427589e-03, -1.6948740e-03,  3.9136950e-03, -1.9298631e-04,\n",
      "        3.9407955e-03, -3.5378125e-03, -3.6397246e-03, -3.2708880e-03,\n",
      "       -3.6940870e-03, -6.7671551e-04, -2.2371246e-03,  1.4276830e-03,\n",
      "        3.7421007e-03, -2.9670564e-03, -3.6575682e-03,  1.6490344e-03,\n",
      "        3.6578157e-03, -3.7497792e-03,  3.8009267e-03, -3.9312001e-03,\n",
      "       -3.7705121e-03,  2.3576620e-03,  3.9520813e-03, -1.9534659e-03,\n",
      "        2.7881954e-03,  3.7276957e-03, -3.9879493e-03,  3.6587233e-03,\n",
      "       -3.6866588e-03,  3.8723212e-03,  2.4757076e-03, -2.8262495e-03,\n",
      "       -3.6707674e-03, -3.7998180e-03,  3.8276668e-04,  2.2102993e-03],\n",
      "      dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_23/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
      "array([[-0.12421496, -0.1313639 ,  0.03626276, ...,  0.11123864,\n",
      "         0.13251072,  0.06108602],\n",
      "       [-0.13532078, -0.14665857,  0.0640457 , ...,  0.01595846,\n",
      "         0.03209594, -0.12971705],\n",
      "       [ 0.13332532, -0.1473727 , -0.12597837, ..., -0.12214538,\n",
      "        -0.05724436,  0.06888927],\n",
      "       ...,\n",
      "       [-0.01956321,  0.12421352,  0.01888057, ..., -0.11097936,\n",
      "        -0.09571629, -0.14599963],\n",
      "       [-0.13263023, -0.1267492 , -0.06684884, ..., -0.0764121 ,\n",
      "         0.08414664, -0.14702454],\n",
      "       [ 0.03650059,  0.13914473,  0.0315696 , ..., -0.05878401,\n",
      "        -0.05100555, -0.1032007 ]], dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_23/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 1.7696035e-03, -3.9939201e-03, -8.4220851e-04,  3.8790184e-03,\n",
      "        2.8454966e-03,  3.3035274e-03,  3.9376672e-03,  2.7238382e-03,\n",
      "        3.7646852e-03, -3.8737701e-03, -3.8580217e-03, -1.0797121e-03,\n",
      "        9.3619659e-05,  2.1801125e-03, -3.9457451e-03, -2.9061509e-03,\n",
      "        3.4411668e-03, -3.8172686e-03, -4.0112673e-03,  3.2280320e-03,\n",
      "       -3.9797635e-03,  1.6732516e-03, -3.7431424e-03, -9.0347987e-04,\n",
      "        2.3195654e-04, -3.9342451e-03, -3.3831364e-03, -3.8750807e-03,\n",
      "       -3.6924707e-03,  3.5275244e-03, -3.9256266e-03, -3.8858543e-03,\n",
      "       -3.7966536e-03, -1.3758859e-03, -1.9016949e-04,  3.9405883e-03,\n",
      "        3.6407204e-03,  1.1364101e-03, -4.0387036e-05,  3.9636213e-03,\n",
      "        3.8265516e-03, -3.7822924e-03, -3.8466845e-03,  3.8044218e-03,\n",
      "       -3.7101218e-03,  3.8489215e-03, -3.9646709e-03, -3.8030269e-03,\n",
      "        3.9214892e-03,  1.8505367e-03, -3.8876568e-03, -3.6957597e-03,\n",
      "        4.0026968e-03, -3.9349301e-03, -3.7633637e-03, -3.7768306e-03,\n",
      "        3.9282595e-03, -1.2492801e-03, -3.9413720e-03,  3.9973720e-03,\n",
      "        3.8600487e-03,  3.5267198e-03,  3.5848226e-03,  3.9654574e-03,\n",
      "        4.0093660e-03,  3.9562909e-03, -3.5626763e-03, -3.8414041e-03,\n",
      "       -2.9825887e-03, -3.9372761e-03, -3.8138051e-03, -3.9525917e-03,\n",
      "        3.8155767e-03,  3.8679207e-03, -3.0805767e-03, -3.2762308e-03,\n",
      "        3.7450860e-03, -8.3166210e-04, -9.9731935e-04, -3.6242320e-03,\n",
      "        3.8942515e-03,  3.9462298e-03, -3.9789593e-03,  3.8875255e-03,\n",
      "        8.8277954e-04, -3.9363769e-03, -3.8267402e-03, -3.5805239e-03,\n",
      "        3.3993723e-03,  3.7381437e-03, -3.8290243e-03, -3.8952492e-03,\n",
      "        3.7427589e-03, -1.6948740e-03,  3.9136950e-03, -1.9298631e-04,\n",
      "        3.9407955e-03, -3.5378125e-03, -3.6397246e-03, -3.2708880e-03,\n",
      "       -3.6940870e-03, -6.7671551e-04, -2.2371246e-03,  1.4276830e-03,\n",
      "        3.7421007e-03, -2.9670564e-03, -3.6575682e-03,  1.6490344e-03,\n",
      "        3.6578157e-03, -3.7497792e-03,  3.8009267e-03, -3.9312001e-03,\n",
      "       -3.7705121e-03,  2.3576620e-03,  3.9520813e-03, -1.9534659e-03,\n",
      "        2.7881954e-03,  3.7276957e-03, -3.9879493e-03,  3.6587233e-03,\n",
      "       -3.6866588e-03,  3.8723212e-03,  2.4757076e-03, -2.8262495e-03,\n",
      "       -3.6707674e-03, -3.7998180e-03,  3.8276668e-04,  2.2102993e-03],\n",
      "      dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_24/kernel:0' shape=(128, 127) dtype=float32, numpy=\n",
      "array([[ 0.14385854,  0.1109089 , -0.01351176, ..., -0.07372692,\n",
      "         0.03329514,  0.13972515],\n",
      "       [-0.01687683, -0.01287041,  0.06829274, ...,  0.07730115,\n",
      "         0.1109489 ,  0.06269464],\n",
      "       [ 0.10198481,  0.12302563, -0.10181551, ...,  0.10504714,\n",
      "         0.01751086, -0.00509234],\n",
      "       ...,\n",
      "       [-0.05825373, -0.10166209,  0.08784699, ..., -0.01860755,\n",
      "        -0.11810308,  0.13101393],\n",
      "       [-0.06168726, -0.1429312 ,  0.04828558, ...,  0.01378365,\n",
      "        -0.06350591,  0.1282415 ],\n",
      "       [-0.0819043 , -0.06732451, -0.08397393, ..., -0.12466957,\n",
      "        -0.04381386, -0.12152556]], dtype=float32)>, <tf.Variable 'gru_decoder_3/dense_24/bias:0' shape=(127,) dtype=float32, numpy=\n",
      "array([-0.0040023 , -0.0040011 ,  0.00388527,  0.00388615, -0.00400021,\n",
      "        0.00399154,  0.00388198,  0.00398498,  0.00382387,  0.00369021,\n",
      "        0.00377306,  0.00364261,  0.00394615,  0.00257049,  0.00255876,\n",
      "        0.00263181,  0.00330784,  0.00354411,  0.00337634,  0.00197381,\n",
      "        0.0011621 , -0.00067897,  0.00269107,  0.00227275,  0.00203192,\n",
      "       -0.00339522, -0.00221439,  0.00078046,  0.00121731,  0.00029407,\n",
      "       -0.00317596, -0.00232617, -0.00092455,  0.0007956 , -0.00230267,\n",
      "       -0.00284273, -0.00400278, -0.00337461, -0.00372309, -0.00400049,\n",
      "        0.00030657, -0.00380639, -0.00376385,  0.00197951,  0.000285  ,\n",
      "       -0.00400337, -0.00119212, -0.00399614, -0.00344408, -0.0032752 ,\n",
      "       -0.00399982, -0.00400267, -0.00399995, -0.00180092, -0.00163937,\n",
      "       -0.00119382, -0.00058436, -0.00267541, -0.00399104, -0.00399454,\n",
      "       -0.00400132, -0.00400146, -0.00399672,  0.00031218, -0.00400185,\n",
      "       -0.00115917, -0.0033496 , -0.00399465, -0.00210392, -0.00399827,\n",
      "       -0.0020564 , -0.00400158, -0.00400217, -0.00400335, -0.00337108,\n",
      "       -0.00399914, -0.00359117, -0.00400107, -0.0039944 , -0.00399746,\n",
      "       -0.00400252, -0.00400383, -0.0035881 , -0.00382963, -0.00400193,\n",
      "       -0.00400205, -0.00400152, -0.00399926, -0.00339368, -0.00361949,\n",
      "       -0.00341624, -0.00301746, -0.00400169, -0.00400275, -0.00400164,\n",
      "       -0.00355832, -0.00400115, -0.00341593, -0.0039998 , -0.00400139,\n",
      "       -0.00399777, -0.00399831, -0.00362079, -0.00400416, -0.00400305,\n",
      "       -0.00399971, -0.00400361, -0.00399105, -0.00400319, -0.00399405,\n",
      "       -0.00399831, -0.00400207, -0.00399538, -0.00400064, -0.00399916,\n",
      "       -0.00400097, -0.00400022, -0.0040009 , -0.00399891, -0.00400076,\n",
      "       -0.00400256, -0.00111825, -0.00400189, -0.00399624, -0.00400428,\n",
      "       -0.00399377, -0.00400161], dtype=float32)>, <tf.Variable 'gru_decoder_3/attender_3/dense_25/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
      "array([[ 1.39666989e-01, -6.19209325e-03, -9.59782153e-02, ...,\n",
      "         1.57626718e-02, -1.08944826e-01, -1.98319387e-02],\n",
      "       [ 6.85224533e-02, -9.51500759e-02, -8.26988183e-03, ...,\n",
      "         7.90377632e-02, -1.16682157e-01,  6.86687678e-02],\n",
      "       [ 1.46994919e-01, -4.33905199e-02, -1.42759338e-01, ...,\n",
      "        -1.24599010e-01, -9.85082909e-02, -6.22091554e-02],\n",
      "       ...,\n",
      "       [ 4.67418581e-02,  3.56533565e-02,  7.40814582e-02, ...,\n",
      "         7.07526281e-02,  1.22511372e-01, -1.31796047e-01],\n",
      "       [ 7.80832171e-02,  1.17733225e-01,  5.66286109e-02, ...,\n",
      "        -1.00450031e-01,  5.83104510e-03,  4.39539999e-02],\n",
      "       [-3.81978676e-02, -9.89959165e-02,  8.80037551e-05, ...,\n",
      "         1.36177793e-01,  1.12273186e-01, -1.51116520e-01]], dtype=float32)>, <tf.Variable 'gru_decoder_3/attender_3/dense_25/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 2.4143537e-03, -2.9920612e-03, -2.7878061e-03, -2.1387304e-03,\n",
      "        1.2397013e-03, -1.9255433e-03,  3.1680767e-03, -2.9660668e-03,\n",
      "        4.3632122e-04, -2.6346350e-03,  1.0715923e-03, -5.9075165e-04,\n",
      "       -3.0447519e-03,  3.1217474e-03, -3.1330176e-03,  2.6493708e-03,\n",
      "        3.0311593e-03,  2.8798121e-03, -2.9931681e-03, -2.9144632e-03,\n",
      "        3.0213303e-03, -2.4550518e-03,  2.2992198e-03, -3.0554053e-03,\n",
      "       -3.0477864e-03,  3.1344916e-03,  3.0023190e-03, -3.1131385e-03,\n",
      "        3.1266708e-03, -7.4483082e-04, -1.1906524e-03, -1.1912517e-03,\n",
      "        1.1771563e-03,  1.8121439e-03, -2.9241932e-03,  3.0242880e-03,\n",
      "        6.5397669e-04,  3.1313370e-03, -2.2046231e-03, -2.2121804e-04,\n",
      "       -9.4838545e-04,  1.5932792e-03,  3.0522393e-03, -1.9479832e-03,\n",
      "        1.5582220e-04,  1.0185784e-03,  2.9774413e-03, -3.0491708e-03,\n",
      "       -2.3381580e-03, -2.6126297e-03, -2.8855246e-03,  1.4164080e-03,\n",
      "        1.1165519e-03, -1.2883546e-03,  2.8405166e-03, -3.2162420e-03,\n",
      "       -2.6873590e-03, -3.2036712e-03, -4.1553547e-04,  1.7489633e-04,\n",
      "       -1.1163298e-03,  2.9050200e-03,  2.2490806e-04,  3.1019372e-03,\n",
      "       -1.2408772e-03, -2.4230599e-03,  2.7621377e-03, -2.9181088e-03,\n",
      "        1.0749209e-03, -2.1145795e-03, -1.8230469e-03, -3.0654431e-03,\n",
      "       -3.0124562e-03,  3.0556852e-03, -3.1018707e-03, -2.6966662e-03,\n",
      "        2.7418868e-03, -3.0132488e-03,  1.3572013e-03, -2.3604375e-03,\n",
      "       -2.5514951e-03,  1.1691826e-03, -3.0918538e-03,  2.2532917e-03,\n",
      "        4.2705215e-05, -2.9856516e-03,  2.7540375e-03,  1.9315518e-03,\n",
      "       -3.1403028e-03,  2.8722654e-03, -2.6140388e-03,  2.6634212e-03,\n",
      "        2.9284153e-03,  1.1841590e-03, -2.9918826e-03,  1.3877691e-03,\n",
      "        2.5820071e-03,  2.9923890e-03,  3.1006732e-03,  2.1934125e-03,\n",
      "       -2.7822508e-03, -3.0770707e-03, -2.4202024e-03, -3.2020865e-03,\n",
      "        3.1776744e-04, -1.7788694e-03, -2.4708598e-03, -3.1374674e-03,\n",
      "        1.7853479e-03, -2.5107581e-03,  3.1712411e-03, -1.9084470e-04,\n",
      "        1.3117029e-03,  3.1124353e-03,  8.7024516e-04, -3.1578448e-03,\n",
      "       -3.0120905e-03, -1.3068609e-03, -5.8939413e-04,  3.0232337e-03,\n",
      "        1.6561585e-03, -2.8749851e-03, -1.4953595e-03,  2.8063734e-03,\n",
      "        3.0811485e-03,  1.2516531e-03,  1.8242646e-03,  1.7703660e-03],\n",
      "      dtype=float32)>, <tf.Variable 'gru_decoder_3/attender_3/dense_26/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
      "array([[ 0.11474724, -0.06713079,  0.10990297, ..., -0.11317267,\n",
      "         0.04921099, -0.09431472],\n",
      "       [ 0.01926508, -0.1500873 ,  0.07743078, ...,  0.04395583,\n",
      "         0.04833417, -0.00142209],\n",
      "       [-0.11878397,  0.1337429 ,  0.01146899, ..., -0.13795686,\n",
      "        -0.10608577, -0.07019038],\n",
      "       ...,\n",
      "       [-0.02168318, -0.06576592, -0.05472952, ...,  0.14743063,\n",
      "        -0.12133572,  0.01598267],\n",
      "       [-0.09590543, -0.1230926 ,  0.08608037, ...,  0.04641292,\n",
      "         0.08086553, -0.12170762],\n",
      "       [-0.12883067, -0.06226858, -0.03622675, ..., -0.02827977,\n",
      "        -0.15005122,  0.0371052 ]], dtype=float32)>, <tf.Variable 'gru_decoder_3/attender_3/dense_26/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 2.4143539e-03, -2.9920612e-03, -2.7878061e-03, -2.1387301e-03,\n",
      "        1.2397011e-03, -1.9255432e-03,  3.1680767e-03, -2.9660668e-03,\n",
      "        4.3632134e-04, -2.6346350e-03,  1.0715923e-03, -5.9075147e-04,\n",
      "       -3.0447519e-03,  3.1217474e-03, -3.1330178e-03,  2.6493708e-03,\n",
      "        3.0311591e-03,  2.8798121e-03, -2.9931683e-03, -2.9144632e-03,\n",
      "        3.0213306e-03, -2.4550518e-03,  2.2992201e-03, -3.0554053e-03,\n",
      "       -3.0477864e-03,  3.1344916e-03,  3.0023190e-03, -3.1131385e-03,\n",
      "        3.1266708e-03, -7.4483023e-04, -1.1906524e-03, -1.1912517e-03,\n",
      "        1.1771563e-03,  1.8121438e-03, -2.9241929e-03,  3.0242880e-03,\n",
      "        6.5397681e-04,  3.1313370e-03, -2.2046235e-03, -2.2121816e-04,\n",
      "       -9.4838557e-04,  1.5932792e-03,  3.0522395e-03, -1.9479829e-03,\n",
      "        1.5582237e-04,  1.0185784e-03,  2.9774413e-03, -3.0491708e-03,\n",
      "       -2.3381577e-03, -2.6126299e-03, -2.8855246e-03,  1.4164080e-03,\n",
      "        1.1165519e-03, -1.2883549e-03,  2.8405164e-03, -3.2162422e-03,\n",
      "       -2.6873590e-03, -3.2036714e-03, -4.1553547e-04,  1.7489633e-04,\n",
      "       -1.1163296e-03,  2.9050200e-03,  2.2490788e-04,  3.1019372e-03,\n",
      "       -1.2408772e-03, -2.4230601e-03,  2.7621377e-03, -2.9181088e-03,\n",
      "        1.0749206e-03, -2.1145795e-03, -1.8230469e-03, -3.0654431e-03,\n",
      "       -3.0124562e-03,  3.0556852e-03, -3.1018707e-03, -2.6966662e-03,\n",
      "        2.7418868e-03, -3.0132488e-03,  1.3572013e-03, -2.3604375e-03,\n",
      "       -2.5514951e-03,  1.1691826e-03, -3.0918538e-03,  2.2532919e-03,\n",
      "        4.2705855e-05, -2.9856514e-03,  2.7540373e-03,  1.9315518e-03,\n",
      "       -3.1403026e-03,  2.8722654e-03, -2.6140390e-03,  2.6634210e-03,\n",
      "        2.9284153e-03,  1.1841590e-03, -2.9918826e-03,  1.3877691e-03,\n",
      "        2.5820066e-03,  2.9923890e-03,  3.1006732e-03,  2.1934127e-03,\n",
      "       -2.7822508e-03, -3.0770707e-03, -2.4202024e-03, -3.2020863e-03,\n",
      "        3.1776726e-04, -1.7788690e-03, -2.4708598e-03, -3.1374674e-03,\n",
      "        1.7853479e-03, -2.5107579e-03,  3.1712414e-03, -1.9084476e-04,\n",
      "        1.3117029e-03,  3.1124353e-03,  8.7024533e-04, -3.1578448e-03,\n",
      "       -3.0120905e-03, -1.3068611e-03, -5.8939419e-04,  3.0232337e-03,\n",
      "        1.6561586e-03, -2.8749851e-03, -1.4953596e-03,  2.8063734e-03,\n",
      "        3.0811485e-03,  1.2516531e-03,  1.8242642e-03,  1.7703658e-03],\n",
      "      dtype=float32)>, <tf.Variable 'gru_decoder_3/attender_3/dense_27/kernel:0' shape=(128, 128) dtype=float32, numpy=\n",
      "array([[ 0.08947647, -0.1442137 ,  0.06337854, ...,  0.05190831,\n",
      "        -0.00642575,  0.15057956],\n",
      "       [-0.14564656, -0.04226086,  0.11381467, ...,  0.11876769,\n",
      "         0.0369811 , -0.01208979],\n",
      "       [-0.09676455,  0.04244372,  0.00532128, ...,  0.02751756,\n",
      "         0.06692699, -0.10239221],\n",
      "       ...,\n",
      "       [-0.06368253,  0.06494514, -0.00294734, ..., -0.09484005,\n",
      "         0.15245676, -0.09624285],\n",
      "       [-0.14789703, -0.10755793, -0.05171969, ...,  0.01748677,\n",
      "         0.04684799,  0.06007722],\n",
      "       [-0.08435993, -0.05642449,  0.10756501, ...,  0.11045603,\n",
      "         0.14936562,  0.00149748]], dtype=float32)>, <tf.Variable 'gru_decoder_3/attender_3/dense_27/bias:0' shape=(128,) dtype=float32, numpy=\n",
      "array([ 0.0031328 , -0.00271472,  0.00144689, -0.00213053,  0.00297518,\n",
      "       -0.00215924, -0.00210196, -0.00215829,  0.00291146, -0.00253252,\n",
      "       -0.00215228, -0.00129167, -0.00298392, -0.00212012, -0.0002633 ,\n",
      "       -0.00321234, -0.00214751, -0.00311883,  0.00246752,  0.00303575,\n",
      "       -0.00267215,  0.00299545, -0.00255501, -0.00211512, -0.00247249,\n",
      "       -0.0032629 , -0.0021907 , -0.00215693, -0.00296817, -0.00214079,\n",
      "       -0.00211438, -0.00224157, -0.00271415, -0.00213686,  0.00302937,\n",
      "       -0.00215916, -0.00247919,  0.00300695, -0.00212144, -0.00220656,\n",
      "        0.00193582, -0.00213368, -0.00213071, -0.00287144, -0.00215771,\n",
      "        0.00134896,  0.00047097,  0.001631  , -0.00209671, -0.00216416,\n",
      "       -0.00321732, -0.00167851,  0.00267234, -0.00211815, -0.00242702,\n",
      "       -0.00210219,  0.00212846, -0.0026584 , -0.00207826, -0.00211742,\n",
      "        0.00267899, -0.00229211, -0.00226691, -0.00150488, -0.00302214,\n",
      "       -0.00210399, -0.00288149,  0.00272352, -0.00221821, -0.00146213,\n",
      "        0.00282317, -0.00210335, -0.00117613, -0.00318751, -0.00260918,\n",
      "       -0.00210337, -0.00216621, -0.00210617, -0.00254317, -0.00212289,\n",
      "       -0.002135  , -0.00224217,  0.00292945, -0.00283814, -0.00213198,\n",
      "       -0.00292873, -0.00301322,  0.00243903,  0.00265359, -0.00284688,\n",
      "       -0.00228876, -0.00031921, -0.00214011, -0.00209194,  0.00172259,\n",
      "       -0.00161581, -0.00284852,  0.00279332,  0.00120888, -0.00221571,\n",
      "       -0.00160909, -0.00161711, -0.00229658, -0.00212752, -0.00315509,\n",
      "       -0.00216359, -0.00212704, -0.00310527,  0.0022256 , -0.00209049,\n",
      "        0.00292354, -0.00309268, -0.00263551, -0.00227042, -0.00213885,\n",
      "       -0.00214873, -0.00113921, -0.00217295,  0.00086158, -0.0021648 ,\n",
      "        0.00318213, -0.00243206, -0.00211898, -0.00226791, -0.00216083,\n",
      "       -0.00211931, -0.0025396 , -0.00210969], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "decoder2 = GRU_decoder(128,128,len(list(word_index.keys())))\n",
    "decoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignorar todo a partir de aqui, es para hacer pruebas jeje :)\n",
    "\n",
    "'''\n",
    "def preTraining(dataSet, cache=True, shuffle_buffer_size=1000):\n",
    "    dataSet = dataSet.shuffle( buffer_size=shuffle_buffer_size )\n",
    "    #dataSet = dataSet.repeat()\n",
    "    dataSet = dataSet.batch(16) #batch size =32\n",
    "    #dataSet = dataSet.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "    return dataSet\n",
    "trainDS = preTraining(labeledDataset)\n",
    "#image_batch, label_batch = next(iter(trainDS))\n",
    "#show_batch(image_batch.numpy(), label_batch.numpy())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Dimensions :  (512, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert to grayscale\n",
    "PATH = r\"G:\\\\Documents\\\\CROHME\\\\CROHME\\\\CROHME2013_data\\\\TrainINKML\\\\images\\\\expressmatch\\\\101_alfonso.jpg\"\n",
    "image = cv.imread(PATH)\n",
    "resized = cv.resize(image, (1024,512), interpolation = cv.INTER_AREA)\n",
    " \n",
    "print('Resized Dimensions : ',resized.shape)\n",
    " \n",
    "cv.imshow(\"Resized image\", resized)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "#grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\\expressmatch\\65_alfonso.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables necesarias, ignorar por ahora\n",
    "# M = embdedding dimmensionality\n",
    "# N = GRU dimensionality\n",
    "# L = number of annotation vectors\n",
    "# D = dimensionality of annotation vectors\n",
    "# K = number of words in vocabulary\n",
    "# N_prime = attention dimentionality\n",
    "\n",
    "L = 3\n",
    "D = 128\n",
    "K = 127\n",
    "N_prime = 128\n",
    "N = 64\n",
    "M = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros((16,1,3, 128))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 56)\n",
      "(None, 128)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense \n",
    "model = Sequential() \n",
    "layer_1 = Dense(128, input_shape = (56,)) \n",
    "\n",
    "model.add(layer_1) \n",
    "print(layer_1.input_shape) \n",
    "print(layer_1.output_shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.0077122  0.00798441 0.0082583  0.00813114 0.00758686 0.00765422\n",
      " 0.00819508 0.00801731 0.00778867 0.00793868 0.00817909 0.0077188\n",
      " 0.00780235 0.00792794 0.00782531 0.00801626 0.00759206 0.00791037\n",
      " 0.00784708 0.00803427 0.00783526 0.00810021 0.00777087 0.00752414\n",
      " 0.00764606 0.00757418 0.007841   0.00777249 0.00772197 0.00759741\n",
      " 0.0077856  0.0078179  0.00805625 0.00800839 0.00779082 0.00805504\n",
      " 0.00801177 0.00805107 0.00823483 0.0081527  0.00743428 0.00756936\n",
      " 0.00782649 0.00787631 0.00812574 0.00805205 0.00788147 0.00777273\n",
      " 0.00788906 0.00815082 0.00745555 0.00793089 0.00765897 0.00804335\n",
      " 0.00789843 0.0077011  0.00802226 0.00792664 0.0081496  0.00784043\n",
      " 0.00800649 0.0077229  0.00779958 0.00769156 0.00797984 0.0078022\n",
      " 0.00766275 0.00797059 0.00790793 0.0080414  0.00796528 0.0081026\n",
      " 0.00842888 0.00783339 0.00775519 0.00776263 0.0078705  0.0076692\n",
      " 0.00840811 0.00759783 0.00786747 0.00764156 0.00765676 0.00792471\n",
      " 0.00792545 0.00794002 0.00792474 0.00750257 0.00773712 0.00808666\n",
      " 0.00778254 0.00804139 0.00782606 0.00767495 0.00779922 0.00801521\n",
      " 0.00814676 0.00785039 0.00806912 0.00779993 0.0079702  0.00775691\n",
      " 0.00774464 0.00762086 0.00766431 0.00750018 0.00788963 0.0078758\n",
      " 0.00800091 0.00793499 0.00777898 0.00768511 0.00793518 0.00793537\n",
      " 0.00771615 0.00773617 0.00767745 0.00790054 0.00780226 0.00813506\n",
      " 0.00783516 0.00799613 0.00790621 0.00805534 0.00827717 0.00782513\n",
      " 0.00797879], shape=(127,), dtype=float32) tf.Tensor(0.008428884, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = decoder.g\n",
    "\n",
    "class test(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(test, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(128)\n",
    "        self.fc2 = tf.keras.layers.Dense(128)#,activation='softmax')\n",
    "        self.fc3 = tf.keras.layers.Dense(128)\n",
    "        self.fc4 = tf.keras.layers.Dense(127, activation='softmax')\n",
    "    \n",
    "    def call(self, a, b, c):\n",
    "        a = self.fc1(a)\n",
    "        b = self.fc2(b)\n",
    "        c = self.fc3(c)\n",
    "        res = a+b+c\n",
    "        res = self.fc4(res)\n",
    "        return res\n",
    "tst = test()\n",
    "res = tst(t[:,0], t[:,1], t[:,2])\n",
    "print(res[1], max(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.00836815 0.00836697 0.00836866 0.00836738 0.00836732 0.0083674\n",
      " 0.00836789 0.0083669 ], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''import tensorflow_probability as tfp\n",
    "resp = tfp.distributions.Multinomial(probs=[.2,.5,.6], num_samples=1)\n",
    "print(resp)'''\n",
    "'''import tensorflow as tf\n",
    "samples = tf.constant([[.25,.26,.6], [.85, .9, 0.25], [.3, .8, .4]])\n",
    "shape = samples.shape\n",
    "for i in range(shape[1]):\n",
    "print(samples)\n",
    "print(tf.reduce_max(tf.compat.v1.multinomial(samples, 1), axis=1))'''\n",
    "res_words = tf.reduce_max(res, axis=1)\n",
    "\n",
    "\n",
    "print(tf.reduce_max(res, axis=1))\n",
    "#print(tf.compat.v1.multinomial(logits=samples, num_samples=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([72 72 72 72 72 72 72 72], shape=(8,), dtype=int64) tf.Tensor([72 72 72 72 72 72 72 72], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "print(tf.argmax(res, 1), tf.transpose(tf.argmax(res, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices()\n",
    "print(\"Num GPUs Available\", gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Yo\\AppData\\Local\\Temp/ipykernel_19424/3597539986.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tf.test.is_gpu_available())\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
