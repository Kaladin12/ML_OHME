{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "#import keras\n",
    "import inkml2img\n",
    "import re\n",
    "import json\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['expressmatch', 'extension', 'HAMEX', 'KAIST', 'MathBrush', 'MfrDB']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"    for t in arr[i]:\\n    # si la extension no es .lg\\n    if ('.lg' not in t):\\n        # se llama a la funcion inkml2img del modulo hominimo, especificando la ruta del inkml y la ruta a guardar la imagen\\n        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\\n        print(t)\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En esta celda se convierten los archivos inkml a .jpg con ayuda del modulo inkml2img\n",
    "# PATH indica la ubicacion de los archivos .inkml\n",
    "PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "# DIR_PATH indica el directorio donde se guardarán las imagenes\n",
    "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\"\n",
    "# se obtiene el nombre de las carpetas que contienen los archivos .inkml\n",
    "dataSets = os.listdir(PATH)\n",
    "# se genera una lista con listas vacias (la cantidad de carpetas en dataSets)\n",
    "arr = [[] for _ in range(len(dataSets))]\n",
    "print(dataSets)\n",
    "# se itera por cada carpeta de archivos .inkml\n",
    "for i in range(len(dataSets)):\n",
    "    # se agrega a la lista los archivos en determinada carpeta (la de la iteracion actual)\n",
    "    arr[i] = os.listdir(PATH+'\\\\'+dataSets[i])\n",
    "    # se itera por los archivos .inkml de la carpeta\n",
    "    for t in arr[i]:\n",
    "    # si la extension no es .lg\n",
    "    if ('.lg' not in t):\n",
    "        # se llama a la funcion inkml2img del modulo hominimo, especificando la ruta del inkml y la ruta a guardar la imagen\n",
    "        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en esta celda se obtienen los labels (el ground truth en latex) asociado a cada archivo .inkml\n",
    "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
    "LABELS_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\"\n",
    "# diccionario donde el ground truth se guardara para cada archivo\n",
    "items = {}\n",
    "index = 0\n",
    "count = 0\n",
    "# se itera por la cantidad de carpetas que contienen archivos .inkml\n",
    "for t in arr:\n",
    "    # se itera por cada archivo inkml\n",
    "    for i in t:\n",
    "        if (\".lg\" not in i):\n",
    "            # se obtiene el path del archivo concatenando DIR_PATH con el nombre de la carpeta y del archivo\n",
    "            imgPath = DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i\n",
    "            # dado que .inkml es un tipo de XML, tiene una estructura de arbol, por lo que se utiliza \n",
    "            # la funcion ET.parse para hacer uso de esta estructura\n",
    "            tree = ET.parse(imgPath)\n",
    "            # se otbiene la raiz del archivo (primera etiqueta en el .inkml)\n",
    "            root = tree.getroot()\n",
    "            count =0\n",
    "            # se itera por cada hijo de la raiz\n",
    "            for item in root:\n",
    "                # si el hijo posee texto entonces es posible que contenga el ground truth (label) deseado\n",
    "                if item.text:\n",
    "                    # existen tres posibilidades debido a la forma en que fueron codificados los archivos en distintas carpetas\n",
    "                    # el primero es que el groud truth en latex se encuetre entre simbolos de dolar $\n",
    "                    if \"$\" in item.text:\n",
    "                        current = item.text\n",
    "                        # se añade como key del diccionario el nombre del archivo y se le asocia el ground truth en latex\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
    "                        break\n",
    "                    if \"\\\\\" in item.text and dataSets[index] == \"MathBrush\":\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
    "                        break\n",
    "                    # para la carpeta KAIST el latex se encuentra sin elementos externos, por lo que se agrega sin mas\n",
    "                    if (count ==1 and dataSets[index]==\"KAIST\" and len(item.text)>2):\n",
    "                        current = item.text\n",
    "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current\n",
    "                        break\n",
    "                count +=1\n",
    "        else:\n",
    "            print(i)\n",
    "    index +=1 \n",
    "# se verifica que el comando log no se encuentre como una secuencia de letras separadas\n",
    "for key in items:\n",
    "    if ('l o g' in items[key]):\n",
    "        # si se encuentra se reemplaza por su respectivo comando en latex correcto\n",
    "        items[key] = items[key].replace('l o g', '\\\\log')\n",
    "# se guarda el diccionario en formato json\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\label.json\", 'w') as f:\n",
    "    json.dump(items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se realiza un filtrado de los groud truth para separar cada comando, letra y numero presente en el dataset\n",
    "# establece los comandos a borrar, ya que no proporcionan informacion relevante para la ecuacion\n",
    "delete = ['\\\\Bigg','\\\\left','\\\\right','\\\\Big','\\\\mathrm']\n",
    "# comandos a reemplazar por el comando latex correcto\n",
    "replace = {'\\\\to':'\\\\rightarrow', '\\\\gt':'>', '\\\\lt':'<'}\n",
    "# simbolos a los que se les añade espacios en blanco antes y despues para un mejor tratamiento\n",
    "add = ['_','{','}','=','(',')','-','+','^','[',']', ',']\n",
    "count = 0\n",
    "# se iteran los archivos .inkml, items representa el mismo diccionario guardado en labels.json\n",
    "for key in items:\n",
    "    # si existe alguno de los comandos descritos en las listas y diccionario anteriores se realizan la soperaciones\n",
    "    # correspondientes\n",
    "    for dele in delete:\n",
    "        if dele in items[key]:\n",
    "            items[key] = items[key].replace(dele, \"\")\n",
    "    for rep in replace:\n",
    "        if (rep in items[key]):\n",
    "            items[key] = items[key].replace(rep, replace[rep])\n",
    "    for it in add:\n",
    "        if (it in items[key]):\n",
    "            items[key] = items[key].replace(it, \" \"+it+\" \")\n",
    "    # se agrega un espacio en blanco antes de \\\\ para que pueda diferenciarse a los comandos del resto de letras o numeros\n",
    "    if ('\\\\' in items[key]):\n",
    "        items[key] = items[key].replace('\\\\', \" \\\\\")\n",
    "    # se separa el ground truth, siendo la condicion para separa el que existan uno o mas espacios en blanco entre caracteres\n",
    "    items[key] = re.split(r'\\s+', items[key])\n",
    "    count = 0\n",
    "    # se itera sobre la lista generada de letras, numeros, simbolos y comandos para cada archivo inkml\n",
    "    # separando los caracteres que se encuentren juntos y no sean parte de un comando, \n",
    "    # por ejemplo 'abc' se separa en 'a', 'b', 'c'\n",
    "    for a in items[key]:\n",
    "        if ('\\\\' not in a and len(a)>1):\n",
    "            uno = items[key][:count]\n",
    "            dos = re.split('', a)[1:-1]\n",
    "            tres = items[key][count+1:]\n",
    "            count+= len(dos)-1\n",
    "            uno.extend(dos)\n",
    "            uno.extend(tres)\n",
    "            items[key] = uno\n",
    "        count+=1\n",
    "    if (items[key][-1]==\"\"):\n",
    "        items[key] = items[key][:-1]\n",
    "    if (items[key][0]==\"\"):\n",
    "        items[key] = items[key][1:]\n",
    "# se guarda en labels.json\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\label.json\", 'w') as f:\n",
    "    json.dump(items, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> S = ( \\sum _ { i = 1 } ^ { n } \\theta _ i - ( n - 2 ) \\pi ) r ^ 2 <end>\n"
     ]
    }
   ],
   "source": [
    "# se instancia la llamada a la funcion Tokenizer de tensorflow\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# se define el numero maximo de palabras a tokenizar\n",
    "num_words = 1000\n",
    "# token para labels desconocidas\n",
    "oov_token = '<UNK>'\n",
    "pad_type = 'post'\n",
    "trunc_type = 'post'\n",
    "\n",
    "items = {}\n",
    "# se obtienen las listas de labels (numeros, comandos latex, simbolos y letras) para cada archivo inkml\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'r') as f:\n",
    "    items = json.load(f)\n",
    "tokens = {}\n",
    "count = 0\n",
    "# se itera para cada archivo\n",
    "for key in items:\n",
    "    # se convierte a string\n",
    "    items[key] = ' '.join(map(str, items[key]))\n",
    "    # se anade al inicio y final los labels start y end para indicar inicio y final del ground truth\n",
    "    items[key] = '<start> '+items[key] + ' <end>'\n",
    "    # se vuelven a separar\n",
    "    items[key] = re.sub(r\"\\s+\", \" \", items[key])\n",
    "# se obtiene la cantidad de archvios inkml a tratar\n",
    "keys = list(items.keys())\n",
    "# se anade el groud truth de cada archivo a una lista\n",
    "data = [ items[key] for key in keys ]\n",
    "print(data[0])\n",
    "# se instancia la funcion tokenizer con los parametros establecidos en un principio\n",
    "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token, filters='', lower=False)\n",
    "# se obtienen los tokens para el conjunto de datos, es decir, a cada comando de latex, letra, numero o simbolo\n",
    "# utilizado se le asigna un numero entero en base a su frecuencia de aparicion\n",
    "tokenizer.fit_on_texts(data)\n",
    "# se define la cantidad de palabras o tokens\n",
    "word_index = tokenizer.word_index\n",
    "# se guardan los tokens en tokens.json\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\tokens.json\", 'w') as f:\n",
    "    json.dump(word_index, f, indent=4)\n",
    "# se convierten los labels a tokens para cada archivo inkml\n",
    "# por ejemplo ['a','b','c'] se convierte a [1,2,3] asumiendo que estos son sus tokens\n",
    "train_sequences = tokenizer.texts_to_sequences(data)\n",
    "# se obtiene la longitud del label mas grande\n",
    "maxlen = max([len(x) for x in train_sequences])\n",
    "# se asocian los tokens a cada archivo haciendo un pad hacia la maxima longitud\n",
    "# tal que todos los archivos tenga por label una lista de la misma longitud, rellenando con ceros\n",
    "# aquellos tokens que se encuentran en una longitud mayor al verdadero para determinado archivo\n",
    "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "files_imgs = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\tokens.json\", 'r') as f:\n",
    "    tokens = json.load(f)\n",
    "tokensPerFile = {}\n",
    "items = {}\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labels.json\", 'r') as f:\n",
    "    items = json.load(f)\n",
    "# se guardab los tokens por archivo inkml haciendo referencia ahora a la imagen \n",
    "# generada a partir del archvio inkml\n",
    "for key in items:\n",
    "    newKey = LABELS_PATH +'\\\\images'+ key[len(LABELS_PATH)+11:][:-6]+'.jpg'\n",
    "    tokensPerFile[newKey] = []\n",
    "    files_imgs[newKey] = key\n",
    "    for command in items[key]:\n",
    "        tokensPerFile[newKey].append(tokens[command])\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\labelsPerFile.json\", 'w') as f:\n",
    "    json.dump(tokensPerFile, f, indent=4)\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\files_img.json\", 'w') as f:\n",
    "    json.dump(files_imgs, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 512, 1024, 1 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 510, 1022, 32 320         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 510, 1022, 32 128         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 510, 1022, 32 0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 508, 1020, 32 9248        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 508, 1020, 32 128         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 508, 1020, 32 0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 506, 1018, 32 9248        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 506, 1018, 32 128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 506, 1018, 32 0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 504, 1016, 32 9248        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 504, 1016, 32 0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 504, 1016, 32 128         dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 504, 1016, 32 0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 252, 508, 32) 0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 250, 506, 64) 18496       max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 250, 506, 64) 256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 250, 506, 64) 0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 248, 504, 64) 36928       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 248, 504, 64) 256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 248, 504, 64) 0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 246, 502, 64) 36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 246, 502, 64) 256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 246, 502, 64) 0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 244, 500, 64) 36928       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 244, 500, 64) 0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 244, 500, 64) 256         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 244, 500, 64) 0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 122, 250, 64) 0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 120, 248, 64) 36928       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 120, 248, 64) 256         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 120, 248, 64) 0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 118, 246, 64) 36928       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 118, 246, 64) 256         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 118, 246, 64) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 116, 244, 64) 36928       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 116, 244, 64) 256         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 116, 244, 64) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 114, 242, 64) 36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 114, 242, 64) 0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 114, 242, 64) 256         dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 114, 242, 64) 0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 57, 121, 64)  0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 28, 60, 128)  73856       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 28, 60, 128)  512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 28, 60, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 13, 29, 128)  147584      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 13, 29, 128)  512         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 13, 29, 128)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 14, 128)   147584      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            multiple             0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 14, 128)   512         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 14, 128)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 2, 6, 128)    147584      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 2, 6, 128)    512         dropout_11[1][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 6, 128)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 1, 3, 128)    0           activation_47[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 826,272\n",
      "Trainable params: 823,968\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# se define la arquitectura del encoder en base a Zhang (2017)\n",
    "class FCN_encoder(tf.keras.Model):\n",
    "    def __init__(self, dropout_rate = 0.2):\n",
    "        super(FCN_encoder, self).__init__()\n",
    "        # super dentro del constructor permite que la clase herede y se convierta en un objeto de Keras\n",
    "        \n",
    "        # bloque de convolucion 1, 32 filtros\n",
    "        self.conv_1_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_3 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.batch_1_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_1_4 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
    "        self.drop_1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_1_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_1_4 = tf.keras.layers.Activation('relu')\n",
    "        \n",
    "        # maxpooling para reducir el tamaño\n",
    "        self.maxPool_1 = tf.keras.layers.MaxPooling2D()\n",
    "        \n",
    "        # bloque convolucional 2, 64 filtros\n",
    "        self.conv_2_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_2_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_2_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.drop_2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_2_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_2_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_2 = tf.keras.layers.MaxPooling2D()\n",
    "\n",
    "        self.conv_3_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.batch_3_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_3_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
    "        self.drop_3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_3_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_3_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_3 = tf.keras.layers.MaxPooling2D()\n",
    "\n",
    "        self.conv_4_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_1 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_2 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.batch_4_3 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_3 = tf.keras.layers.Activation('relu')\n",
    "        self.conv_4_4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
    "        self.drop_4 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.batch_4_4 = tf.keras.layers.BatchNormalization()\n",
    "        self.act_4_4 = tf.keras.layers.Activation('relu')\n",
    "\n",
    "        self.maxPool_4 = tf.keras.layers.MaxPooling2D()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.conv_1_1(inputs)\n",
    "        x = self.batch_1_1(x)\n",
    "        x = self.act_1_1(x)\n",
    "        x = self.conv_1_2(x)\n",
    "        x = self.batch_1_2(x)\n",
    "        x = self.act_1_2(x)\n",
    "        x = self.conv_1_3(x)\n",
    "        x = self.batch_1_3(x)\n",
    "        x = self.act_1_3(x)\n",
    "        x = self.conv_1_4(x)\n",
    "        x = self.drop_1(x)\n",
    "        x = self.batch_1_4(x)\n",
    "        x = self.act_1_4(x)\n",
    "        x = self.maxPool_1(x)\n",
    "        \n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.batch_2_1(x)\n",
    "        x = self.act_2_1(x)\n",
    "        x = self.conv_2_2(x)\n",
    "        x = self.batch_2_2(x)\n",
    "        x = self.act_2_2(x)\n",
    "        x = self.conv_2_3(x)\n",
    "        x = self.batch_2_3(x)\n",
    "        x = self.act_2_3(x)\n",
    "        x = self.conv_2_4(x)\n",
    "        x = self.drop_2(x)\n",
    "        x = self.batch_2_4(x)\n",
    "        x = self.act_2_4(x)\n",
    "        x = self.maxPool_2(x)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.batch_3_1(x)\n",
    "        x = self.act_3_1(x)\n",
    "        x = self.conv_3_2(x)\n",
    "        x = self.batch_3_2(x)\n",
    "        x = self.act_3_2(x)\n",
    "        x = self.conv_3_3(x)\n",
    "        x = self.batch_3_3(x)\n",
    "        x = self.act_3_3(x)\n",
    "        x = self.conv_3_4(x)\n",
    "        x = self.drop_3(x)\n",
    "        x = self.batch_3_4(x)\n",
    "        x = self.act_3_4(x)\n",
    "        x = self.maxPool_3(x)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.batch_4_1(x)\n",
    "        x = self.act_4_1(x)\n",
    "        x = self.conv_4_2(x)\n",
    "        x = self.batch_4_2(x)\n",
    "        x = self.act_4_2(x)\n",
    "        x = self.conv_4_3(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = self.batch_4_3(x)\n",
    "        x = self.act_4_3(x)\n",
    "        x = self.conv_4_4(x)\n",
    "        x = self.drop_4(x)\n",
    "        x = self.batch_4_4(x)\n",
    "        x = self.act_4_4(x)\n",
    "        x = self.maxPool_4(x)\n",
    "    \n",
    "        return x\n",
    "    \n",
    "    def model(self):\n",
    "        input = tf.keras.layers.Input(shape=(512, 1024, 1))\n",
    "        return tf.keras.Model(inputs = input, outputs = self.call(input) )\n",
    "print(FCN_encoder().model().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# el modelo de atencion\n",
    "class Attender(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Attender, self).__init__()\n",
    "        # se instancia los distintos dense layers parametrizados en Zhang\n",
    "        self.W_1 = tf.keras.layers.Dense(128)\n",
    "        self.U_a = tf.keras.layers.Dense(128)\n",
    "        # la dimension de atencion es 128\n",
    "        self.V_a = tf.keras.layers.Dense(128)\n",
    "        #self.F = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2)\n",
    "    \n",
    "    def call(self, a, h):\n",
    "        # se espanden dimensiones para el hidden state\n",
    "        h_t = tf.expand_dims(h, 1)\n",
    "        # se calcula el estado intermedio llamando a los dense layers y la funcion de tangente \n",
    "        # hiperbolica con la suma de los dos dense layers que reciben como parametro el hidden state\n",
    "        # y el vector de anotacion\n",
    "        e_ti = self.V_a( (tf.nn.tanh( self.W_1(h_t) + self.U_a(a))))\n",
    "        # se aplica la activacion softmax al resultado\n",
    "        a_ti = tf.nn.softmax(e_ti)\n",
    "        # se calcula el vector de contexto multiplicando los coeficientes a_ti por el vector de anotacion\n",
    "        context = a_ti * a\n",
    "        # se obtiene la suma del resutado de la multiplicacion anterior\n",
    "        context = tf.reduce_sum(context, axis =1)\n",
    "        # se regresa el vector de contexto y los coeficientes a_ti\n",
    "        return context, a_ti       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_ = None\n",
    "# se define el modelo decoder que utiliza el gru\n",
    "class GRU_decoder(tf.keras.Model):\n",
    "    def __init__(self, dimension, units, label_len):\n",
    "        super(GRU_decoder, self).__init__()\n",
    "        # las unidades del gru\n",
    "        self.units = units\n",
    "        # la capa de embedding, establecida en Zhang como E\n",
    "        self.embedding = tf.keras.layers.Embedding(label_len, dimension)\n",
    "        # la capa del gru, se especifica que se desea el regreso de las secuencias y el ultimo estado calculado\n",
    "        self.gru = tf.keras.layers.GRU( self.units, return_sequences=True, return_state = True, recurrent_initializer='glorot_uniform')\n",
    "        # dense layers para el calculo de las probabilidades para cada palabra en el diccionario de palabras\n",
    "        # es decir, los tokens\n",
    "        self.fc1 = tf.keras.layers.Dense(128)\n",
    "        self.fc2 = tf.keras.layers.Dense(128)#,activation='softmax')\n",
    "        self.fc3 = tf.keras.layers.Dense(128)\n",
    "        # la ultima capa se define con una activacion softmax\n",
    "        self.fc4 = tf.keras.layers.Dense(127, activation='softmax')\n",
    "        # se instancia el modelo de atencion\n",
    "        self.attention = Attender()\n",
    "        self.g = None\n",
    "        \n",
    "    def call(self, x, a, h):\n",
    "        # la llamada recibe la entrada del decoder, la salida del encoder y el estado anterior del decoder\n",
    "        # se llama al modelo de atencion y se recibe el vector de contexto y los coeficientes de atencion\n",
    "        context_v, attention_pro = self.attention(a,h)\n",
    "        x = self.embedding(x)\n",
    "        # se anade el contexto a la entrada del decoder para utilizar el conocimeinto previo\n",
    "        x = tf.concat([context_v,x], axis =-1)\n",
    "        # se alimenta al gru con dicha informacion y se obtiene una salida y su ultimo estado\n",
    "        out, state = self.gru(x)\n",
    "        self.g = out\n",
    "        # es necesario calcular las probabilidades condicionales, por lo que se utiliza \n",
    "        # lo descrito por Zhang para cada parte de la salida del gru\n",
    "        a = self.fc1(out[:,0])\n",
    "        b = self.fc2(out[:,1])\n",
    "        c = self.fc3(out[:,2])\n",
    "        # se suman los resultados\n",
    "        res = a+b+c\n",
    "        # se obtienen las probabilidades gracias al softmax del ultimo layer\n",
    "        res = self.fc4(res)\n",
    "        #print(res.shape)\n",
    "        #x = tf.argmax(res, 1)\n",
    "        # se regresan las probabilidades, el estado y los coeficientes de atencion\n",
    "        return res, state, attention_pro\n",
    "    \n",
    "    def reset(self, batch):\n",
    "        return tf.zeros((batch,3, self.units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# isntanciacion del encoder\n",
    "encoder = FCN_encoder()\n",
    "# isntanciacion del decoder, con valores para la dimension del embedding, del gru y la cantidad de tokens\n",
    "decoder = GRU_decoder(128,128,len(list(word_index.keys())))\n",
    "# se define una funcion de optimizacion para el modelo, el cual permite realizar la optimizacion en base\n",
    "# al gradiente de los errores\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# definimos el tipo de calculo para los errores entre los correspondientes labels del ground truth de cada\n",
    "# imagen y las predicciones\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "# se define una fucnion de loss (perdida o error) que recibe como parametro un label del ground truth por imagen \n",
    "# en el batch las matrices de prediccion asociadas a cada una de esas imagenes\n",
    "def loss_function(real, pred):\n",
    "    # se realiza una conversion del tipo de dato para las probabilidades de las predicciones\n",
    "    pred = tf.cast(pred, tf.float32)\n",
    "    print(real, pred)\n",
    "    # se establece una mascara para aquellas imagenes cuyo label sea 0, es decir, que\n",
    "    # es el padding agregado y que de esta forma no se considere su error para el error general\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    # se calcula el error\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    # se anade la mascara al los obtenido\n",
    "    loss_ *= mask\n",
    "    # se retorna la media de las perdidas para las imagenes en el batch\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "# se obtienen los tokens por imagen\n",
    "LABELS_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\"\n",
    "with open(LABELS_PATH+'\\\\labelsPerFile.json',  'r') as f:\n",
    "    data = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (512, 1024, 1)\n",
      "Label:  [ 4 47  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "files_img = {}\n",
    "# se obtienen los nombres de las imagenes\n",
    "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\files_img.json\", 'r') as f:\n",
    "    files_img = json.load(f)\n",
    "    f.close()\n",
    "keys = list(files_img.keys())\n",
    "# se obtiene el dataset a partir del diccionario que contiene los tokens por archivo\n",
    "list_ds = tf.data.Dataset.list_files(list(data.keys()))\n",
    "\n",
    "# funcion que obtiene la imagen y su label, tiene como parametro el path de la imagen\n",
    "def getProcessedImages(f):\n",
    "    index = keys.index(f)\n",
    "    # se lee la imagen\n",
    "    image = tf.io.read_file(f)\n",
    "    # se decodifica el formato jpg y se establece como imagen en un solo canal, es decir\n",
    "    # blanco y negro\n",
    "    image = tf.image.decode_jpeg(image, channels = 1)  \n",
    "    # se convierte su tipo de dato a flotante\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    # se redimensiona para que concuerde con el modelo del encoder\n",
    "    image = tf.image.resize(image, [512, 1024] ) \n",
    "    # se retorna la imagen (su matriz de pixels) y su label\n",
    "    return image, train_padded[index] #[data[str(tf.constant(f).numpy())[2:-1].replace('\\\\\\\\', '\\\\') ]]\n",
    "    \n",
    "# define el dataset a utilizar como un mapeo de los archvios dentro de list_ds que manda llamar a la funcion getProcessedImages\n",
    "labeledDataset = list_ds.map(lambda x: tf.py_function(getProcessedImages, [x], [tf.float32, tf.int32]) ,num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# solo para verificar que funciona, imprime las dimensioens de la imagen y su label\n",
    "for image, label in labeledDataset.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se establece el tamano de batch como 8, es decir, se ingresara al entrenamiento paquetes de 8 imagenes\n",
    "labeledDataset = labeledDataset.batch(8)\n",
    "#labeledDataset = labeledDataset.prefetch(buffer_size = tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# se define la funcion que entrena al modelo de encoder-decoder\n",
    "# recibe como parametros el batch de imagenes y su ground truth (labels)\n",
    "def train(image, groundTruth):\n",
    "    loss = 0\n",
    "    # el estado del gru se inicializa como ceros\n",
    "    hidden = decoder.reset(groundTruth.shape[0])\n",
    "    # el input del decoder se inicializa como un tensor con valores para el primer token en todas las imagenes\n",
    "    input_decoder = tf.constant([[word_index['<start>']]*3] * groundTruth.shape[0])\n",
    "    #input_decoder = tf.expand_dims([[word_index['<start>']]*3] * groundTruth.shape[0], 1)\n",
    "    #print(input_decoder.shape, hidden.shape)\n",
    "    # ciclo que permite el entrenamiento al generar un entorno donde las variables de entrenamiento son 'vigiladas'\n",
    "    # durante el entrenamiento para poder corregirlas y ajusstar el modelo\n",
    "    with tf.GradientTape() as tape:\n",
    "        # se llama al encoder con la imagen la cual regresa el feature map con las caracteristicas extraidas de la imagen\n",
    "        feature_map = encoder(image)\n",
    "        # se itera por la cantidad de posibles palabras en un groundTruth\n",
    "        for i in range(1, groundTruth.shape[1]):\n",
    "            print(i)\n",
    "            # para cada palabra se verifica si su tensor corresponde a solo valores en cero, para lo cual se rompe el ciclo\n",
    "            # terminando el entrenamiento de este batch\n",
    "            sum_ = tf.reduce_sum(groundTruth[:,i])\n",
    "            allZero = tf.equal(sum_, 0)\n",
    "            if (allZero):\n",
    "                break\n",
    "            # si existe por lo menos un label por predecir entonces se llama al decoder envindole \n",
    "            # su respectivo input, las salidas del encoder y el hidden state anterior\n",
    "            pred, hidden, alphas = decoder(input_decoder, feature_map, hidden)\n",
    "            #print(groundTruth[:,i], pred.shape, hidden.shape, alphas.shape)\n",
    "            # se calcula el error de las predicciones y se suma al actual para el batch\n",
    "            loss += loss_function(groundTruth[:, i], pred)\n",
    "            print(\"loss:\", loss)\n",
    "            # la siguiente entrada para el decoder son las anotaciones para la iteracion actual\n",
    "            # es decir, la anterior para la siguiente interacion (h-1)\n",
    "            dec_input = tf.expand_dims(groundTruth[:, i], 1)\n",
    "    # una vez que termina la entrada del batch se calcula el error total con el error obtenido\n",
    "    total_loss = (loss / int(groundTruth.shape[1]))\n",
    "    # se obtienen las variables a las que se les puede modificar los parametros para ajustarlas (entrenarlas)\n",
    "    trainable_variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    # se obtiene el gradiente de error en base al error obtenido\n",
    "    gradients = tape.gradient(loss, trainable_variables)\n",
    "    # se realiza el ajuste en base al gradiente de error\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
    "    # se regresa el error y el error total\n",
    "    return loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion que itera sobre el dataset para entrenarlo\n",
    "def trainData(dataset, EPOCHS = 1):\n",
    "    print(len(dataset))\n",
    "    # se itera por las epocas de entrenamiento\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        num = 0\n",
    "        # para cada batch de images en el dataset\n",
    "        for (batch, (img_tensor, target)) in enumerate(dataset):\n",
    "            # se llama a la funcion de entrenamiento para cada batch enviando el tensor de imagenes y de labels\n",
    "            # obteniendo los erroes\n",
    "            batch_loss, t_loss = train(img_tensor, target)\n",
    "            total_loss += t_loss\n",
    "            num +=1\n",
    "            print(batch)\n",
    "            if (batch+1) % 10 == 0:\n",
    "                break\n",
    "                #average_batch_loss = batch_loss.numpy()/int(target.shape[1])\n",
    "        print('Epoch {0:d}/{1:d}'.format(epoch+1, EPOCHS))\n",
    "        print('===============>  train-loss=%.3f' % (total_loss/num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "1\n",
      "tf.Tensor([10 10 26  6 64 23 41  6], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788662 0.00814367 0.00786305 ... 0.00774502 0.00764944 0.00831493]\n",
      " [0.00788662 0.00814367 0.00786306 ... 0.00774502 0.00764944 0.00831492]\n",
      " [0.00788662 0.00814368 0.00786305 ... 0.00774502 0.00764944 0.00831493]\n",
      " ...\n",
      " [0.00788662 0.00814367 0.00786305 ... 0.00774502 0.00764944 0.00831493]\n",
      " [0.00788662 0.00814367 0.00786305 ... 0.00774502 0.00764944 0.00831493]\n",
      " [0.00788662 0.00814367 0.00786305 ... 0.00774501 0.00764944 0.00831493]], shape=(8, 127), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4929: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tf.Tensor(4.8467283, shape=(), dtype=float32)\n",
      "2\n",
      "tf.Tensor([ 8 11 11  9 11  2 11 34], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(9.692477, shape=(), dtype=float32)\n",
      "3\n",
      "tf.Tensor([ 2  6  2  7  2 20  2 18], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(14.548902, shape=(), dtype=float32)\n",
      "4\n",
      "tf.Tensor([29 42 29  9 10  2 60 42], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(19.397375, shape=(), dtype=float32)\n",
      "5\n",
      "tf.Tensor([ 9 10 40 81 17 80 18 38], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(24.242367, shape=(), dtype=float32)\n",
      "6\n",
      "tf.Tensor([ 7 11 61  9 31  3  3 38], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(29.096584, shape=(), dtype=float32)\n",
      "7\n",
      "tf.Tensor([61  7  3 19 31  3  8 82], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(33.954006, shape=(), dtype=float32)\n",
      "8\n",
      "tf.Tensor([42 42  5 15 67  5 21  6], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(38.788303, shape=(), dtype=float32)\n",
      "9\n",
      "tf.Tensor([45 10  0 16 59  0 16 34], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(42.421844, shape=(), dtype=float32)\n",
      "10\n",
      "tf.Tensor([ 8 11  0  2 17  0  6  6], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(46.05919, shape=(), dtype=float32)\n",
      "11\n",
      "tf.Tensor([ 2 18  0 19  3  0  2  6], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(49.69674, shape=(), dtype=float32)\n",
      "12\n",
      "tf.Tensor([18 42  0 13 37  0 49 33], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(53.334923, shape=(), dtype=float32)\n",
      "13\n",
      "tf.Tensor([ 3 10  0 19 13  0  8  5], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(56.978176, shape=(), dtype=float32)\n",
      "14\n",
      "tf.Tensor([12 11  0  9 10  0 35  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(60.01127, shape=(), dtype=float32)\n",
      "15\n",
      "tf.Tensor([ 7 25  0  6 14  0  9  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(63.042053, shape=(), dtype=float32)\n",
      "16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([16 15  0 14 15  0  6  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(66.06706, shape=(), dtype=float32)\n",
      "17\n",
      "tf.Tensor([ 2 66  0  3 90  0  3  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(69.107765, shape=(), dtype=float32)\n",
      "18\n",
      "tf.Tensor([61  5  0  2  5  0 26  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(72.13911, shape=(), dtype=float32)\n",
      "19\n",
      "tf.Tensor([ 3  0  0  7  0  0 35  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(73.96273, shape=(), dtype=float32)\n",
      "20\n",
      "tf.Tensor([2 0 0 3 0 0 5 0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(75.78086, shape=(), dtype=float32)\n",
      "21\n",
      "tf.Tensor([29  0  0  5  0  0  0  0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(76.99079, shape=(), dtype=float32)\n",
      "22\n",
      "tf.Tensor([3 0 0 0 0 0 0 0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(77.59887, shape=(), dtype=float32)\n",
      "23\n",
      "tf.Tensor([3 0 0 0 0 0 0 0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(78.20695, shape=(), dtype=float32)\n",
      "24\n",
      "tf.Tensor([5 0 0 0 0 0 0 0], shape=(8,), dtype=int32) tf.Tensor(\n",
      "[[0.00788661 0.00814354 0.0078632  ... 0.00774509 0.00764958 0.00831461]\n",
      " [0.0078866  0.00814355 0.00786323 ... 0.00774514 0.00764959 0.00831453]\n",
      " [0.00788661 0.00814357 0.00786319 ... 0.00774511 0.00764957 0.00831462]\n",
      " ...\n",
      " [0.0078866  0.00814353 0.00786321 ... 0.00774515 0.00764957 0.00831462]\n",
      " [0.0078866  0.00814355 0.0078632  ... 0.0077451  0.00764956 0.00831462]\n",
      " [0.00788659 0.00814352 0.00786318 ... 0.00774507 0.00764957 0.00831459]], shape=(8, 127), dtype=float32)\n",
      "loss: tf.Tensor(78.8113, shape=(), dtype=float32)\n",
      "25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23412/1993992813.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# se llama la funcion principal de entrenamiento\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabeledDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23412/1700936303.py\u001b[0m in \u001b[0;36mtrainData\u001b[1;34m(dataset, EPOCHS)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;31m# se llama a la funcion de entrenamiento para cada batch enviando el tensor de imagenes y de labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;31m# obteniendo los erroes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mbatch_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mt_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mnum\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23412/3415666700.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(image, groundTruth)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mtrainable_variables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# se obtiene el gradiente de error en base al error obtenido\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[1;31m# se realiza el ajuste en base al gradiente de error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1072\u001b[0m                           for x in nest.flatten(output_gradients)]\n\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1074\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1075\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1076\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     72\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m    589\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m           data_format=data_format),\n\u001b[1;32m--> 591\u001b[1;33m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[0;32m    592\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m           \u001b[0mshape_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[1;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1077\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1078\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1079\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   1080\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Conv2DBackpropFilter\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m         \u001b[1;34m\"strides\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# se llama la funcion principal de entrenamiento\n",
    "trainData(labeledDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignorar todo a partir de aqui, es para hacer pruebas jeje :)\n",
    "\n",
    "'''\n",
    "def preTraining(dataSet, cache=True, shuffle_buffer_size=1000):\n",
    "    dataSet = dataSet.shuffle( buffer_size=shuffle_buffer_size )\n",
    "    #dataSet = dataSet.repeat()\n",
    "    dataSet = dataSet.batch(16) #batch size =32\n",
    "    #dataSet = dataSet.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
    "    return dataSet\n",
    "trainDS = preTraining(labeledDataset)\n",
    "#image_batch, label_batch = next(iter(trainDS))\n",
    "#show_batch(image_batch.numpy(), label_batch.numpy())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Dimensions :  (512, 1024, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert to grayscale\n",
    "PATH = r\"G:\\\\Documents\\\\CROHME\\\\CROHME\\\\CROHME2013_data\\\\TrainINKML\\\\images\\\\expressmatch\\\\101_alfonso.jpg\"\n",
    "image = cv.imread(PATH)\n",
    "resized = cv.resize(image, (1024,512), interpolation = cv.INTER_AREA)\n",
    " \n",
    "print('Resized Dimensions : ',resized.shape)\n",
    " \n",
    "cv.imshow(\"Resized image\", resized)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "#grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\\expressmatch\\65_alfonso.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables necesarias, ignorar por ahora\n",
    "# M = embdedding dimmensionality\n",
    "# N = GRU dimensionality\n",
    "# L = number of annotation vectors\n",
    "# D = dimensionality of annotation vectors\n",
    "# K = number of words in vocabulary\n",
    "# N_prime = attention dimentionality\n",
    "\n",
    "L = 3\n",
    "D = 128\n",
    "K = 127\n",
    "N_prime = 128\n",
    "N = 64\n",
    "M = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1, 3, 128)\n"
     ]
    }
   ],
   "source": [
    "a = tf.zeros((16,1,3, 128))\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 56)\n",
      "(None, 128)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Activation, Dense \n",
    "model = Sequential() \n",
    "layer_1 = Dense(128, input_shape = (56,)) \n",
    "\n",
    "model.add(layer_1) \n",
    "print(layer_1.input_shape) \n",
    "print(layer_1.output_shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.0077122  0.00798441 0.0082583  0.00813114 0.00758686 0.00765422\n",
      " 0.00819508 0.00801731 0.00778867 0.00793868 0.00817909 0.0077188\n",
      " 0.00780235 0.00792794 0.00782531 0.00801626 0.00759206 0.00791037\n",
      " 0.00784708 0.00803427 0.00783526 0.00810021 0.00777087 0.00752414\n",
      " 0.00764606 0.00757418 0.007841   0.00777249 0.00772197 0.00759741\n",
      " 0.0077856  0.0078179  0.00805625 0.00800839 0.00779082 0.00805504\n",
      " 0.00801177 0.00805107 0.00823483 0.0081527  0.00743428 0.00756936\n",
      " 0.00782649 0.00787631 0.00812574 0.00805205 0.00788147 0.00777273\n",
      " 0.00788906 0.00815082 0.00745555 0.00793089 0.00765897 0.00804335\n",
      " 0.00789843 0.0077011  0.00802226 0.00792664 0.0081496  0.00784043\n",
      " 0.00800649 0.0077229  0.00779958 0.00769156 0.00797984 0.0078022\n",
      " 0.00766275 0.00797059 0.00790793 0.0080414  0.00796528 0.0081026\n",
      " 0.00842888 0.00783339 0.00775519 0.00776263 0.0078705  0.0076692\n",
      " 0.00840811 0.00759783 0.00786747 0.00764156 0.00765676 0.00792471\n",
      " 0.00792545 0.00794002 0.00792474 0.00750257 0.00773712 0.00808666\n",
      " 0.00778254 0.00804139 0.00782606 0.00767495 0.00779922 0.00801521\n",
      " 0.00814676 0.00785039 0.00806912 0.00779993 0.0079702  0.00775691\n",
      " 0.00774464 0.00762086 0.00766431 0.00750018 0.00788963 0.0078758\n",
      " 0.00800091 0.00793499 0.00777898 0.00768511 0.00793518 0.00793537\n",
      " 0.00771615 0.00773617 0.00767745 0.00790054 0.00780226 0.00813506\n",
      " 0.00783516 0.00799613 0.00790621 0.00805534 0.00827717 0.00782513\n",
      " 0.00797879], shape=(127,), dtype=float32) tf.Tensor(0.008428884, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "t = decoder.g\n",
    "\n",
    "class test(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(test, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(128)\n",
    "        self.fc2 = tf.keras.layers.Dense(128)#,activation='softmax')\n",
    "        self.fc3 = tf.keras.layers.Dense(128)\n",
    "        self.fc4 = tf.keras.layers.Dense(127, activation='softmax')\n",
    "    \n",
    "    def call(self, a, b, c):\n",
    "        a = self.fc1(a)\n",
    "        b = self.fc2(b)\n",
    "        c = self.fc3(c)\n",
    "        res = a+b+c\n",
    "        res = self.fc4(res)\n",
    "        return res\n",
    "tst = test()\n",
    "res = tst(t[:,0], t[:,1], t[:,2])\n",
    "print(res[1], max(res[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[0.00836815 0.00836697 0.00836866 0.00836738 0.00836732 0.0083674\n",
      " 0.00836789 0.0083669 ], shape=(8,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "'''import tensorflow_probability as tfp\n",
    "resp = tfp.distributions.Multinomial(probs=[.2,.5,.6], num_samples=1)\n",
    "print(resp)'''\n",
    "'''import tensorflow as tf\n",
    "samples = tf.constant([[.25,.26,.6], [.85, .9, 0.25], [.3, .8, .4]])\n",
    "shape = samples.shape\n",
    "for i in range(shape[1]):\n",
    "print(samples)\n",
    "print(tf.reduce_max(tf.compat.v1.multinomial(samples, 1), axis=1))'''\n",
    "res_words = tf.reduce_max(res, axis=1)\n",
    "\n",
    "\n",
    "print(tf.reduce_max(res, axis=1))\n",
    "#print(tf.compat.v1.multinomial(logits=samples, num_samples=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([72 72 72 72 72 72 72 72], shape=(8,), dtype=int64) tf.Tensor([72 72 72 72 72 72 72 72], shape=(8,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
    "                 [14, 45, 23, 5, 27]])\n",
    "print(tf.argmax(res, 1), tf.transpose(tf.argmax(res, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
