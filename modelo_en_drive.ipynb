{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "modelo_en_drive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAmTq34loCGL",
        "outputId": "00775aaf-cc8d-4ac3-c163-995bdbf58bbf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-66WsO14m06r"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "#import keras\n",
        "#import inkml2img\n",
        "import re\n",
        "import json\n",
        "#import xml.etree.ElementTree as ET"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH5pcWP_m061",
        "outputId": "3f63fd06-1167-432e-ff13-b47aa82464b7"
      },
      "source": [
        "# IGNORAR PARA ENTRENAMIENTO\n",
        "# En esta celda se convierten los archivos inkml a .jpg con ayuda del modulo inkml2img\n",
        "# PATH indica la ubicacion de los archivos .inkml\n",
        "PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
        "# DIR_PATH indica el directorio donde se guardarÃ¡n las imagenes\n",
        "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\"\n",
        "# se obtiene el nombre de las carpetas que contienen los archivos .inkml\n",
        "dataSets = os.listdir(PATH)\n",
        "# se genera una lista con listas vacias (la cantidad de carpetas en dataSets)\n",
        "arr = [[] for _ in range(len(dataSets))]\n",
        "print(dataSets)\n",
        "# se itera por cada carpeta de archivos .inkml\n",
        "for i in range(len(dataSets)):\n",
        "    # se agrega a la lista los archivos en determinada carpeta (la de la iteracion actual)\n",
        "    arr[i] = os.listdir(PATH+'\\\\'+dataSets[i])\n",
        "    # se itera por los archivos .inkml de la carpeta\n",
        "    for t in arr[i]:\n",
        "    # si la extension no es .lg\n",
        "    if ('.lg' not in t):\n",
        "        # se llama a la funcion inkml2img del modulo hominimo, especificando la ruta del inkml y la ruta a guardar la imagen\n",
        "        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\n",
        "        print(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['expressmatch', 'extension', 'HAMEX', 'KAIST', 'MathBrush', 'MfrDB']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"    for t in arr[i]:\\n    # si la extension no es .lg\\n    if ('.lg' not in t):\\n        # se llama a la funcion inkml2img del modulo hominimo, especificando la ruta del inkml y la ruta a guardar la imagen\\n        inkml2img.inkml2img(PATH+'\\\\'+dataSets[i]+'\\\\'+t,DIR_PATH+'\\\\'+t[:-5]+'jpg')\\n        print(t)\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvuvu5h_m063"
      },
      "source": [
        "# IGNORAR PARA ENTRENAMIENTO\n",
        "# en esta celda se obtienen los labels (el ground truth en latex) asociado a cada archivo .inkml\n",
        "DIR_PATH = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\TrainINKML\"\n",
        "LABELS_PATH = r\"/content/drive/My Drive/Colab Notebooks/TrainINKML/\"\n",
        "# diccionario donde el ground truth se guardara para cada archivo\n",
        "items = {}\n",
        "index = 0\n",
        "count = 0\n",
        "# se itera por la cantidad de carpetas que contienen archivos .inkml\n",
        "for t in arr:\n",
        "    # se itera por cada archivo inkml\n",
        "    for i in t:\n",
        "        if (\".lg\" not in i):\n",
        "            # se obtiene el path del archivo concatenando DIR_PATH con el nombre de la carpeta y del archivo\n",
        "            imgPath = DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i\n",
        "            # dado que .inkml es un tipo de XML, tiene una estructura de arbol, por lo que se utiliza \n",
        "            # la funcion ET.parse para hacer uso de esta estructura\n",
        "            tree = ET.parse(imgPath)\n",
        "            # se otbiene la raiz del archivo (primera etiqueta en el .inkml)\n",
        "            root = tree.getroot()\n",
        "            count =0\n",
        "            # se itera por cada hijo de la raiz\n",
        "            for item in root:\n",
        "                # si el hijo posee texto entonces es posible que contenga el ground truth (label) deseado\n",
        "                if item.text:\n",
        "                    # existen tres posibilidades debido a la forma en que fueron codificados los archivos en distintas carpetas\n",
        "                    # el primero es que el groud truth en latex se encuetre entre simbolos de dolar $\n",
        "                    if \"$\" in item.text:\n",
        "                        current = item.text\n",
        "                        # se aÃ±ade como key del diccionario el nombre del archivo y se le asocia el ground truth en latex\n",
        "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
        "                        break\n",
        "                    if \"\\\\\" in item.text and dataSets[index] == \"MathBrush\":\n",
        "                        current = item.text\n",
        "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current[1:-1]\n",
        "                        break\n",
        "                    # para la carpeta KAIST el latex se encuentra sin elementos externos, por lo que se agrega sin mas\n",
        "                    if (count ==1 and dataSets[index]==\"KAIST\" and len(item.text)>2):\n",
        "                        current = item.text\n",
        "                        items[DIR_PATH+\"\\\\\"+ dataSets[index]+ \"\\\\\"+i] = current\n",
        "                        break\n",
        "                count +=1\n",
        "        else:\n",
        "            print(i)\n",
        "    index +=1 \n",
        "# se verifica que el comando log no se encuentre como una secuencia de letras separadas\n",
        "for key in items:\n",
        "    if ('l o g' in items[key]):\n",
        "        # si se encuentra se reemplaza por su respectivo comando en latex correcto\n",
        "        items[key] = items[key].replace('l o g', '\\\\log')\n",
        "# se guarda el diccionario en formato json\n",
        "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\label.json\", 'w') as f:\n",
        "    json.dump(items, f, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_6f1juom065"
      },
      "source": [
        "# IGNORAR PARA ENTRENAMIENTO\n",
        "# se realiza un filtrado de los groud truth para separar cada comando, letra y numero presente en el dataset\n",
        "# establece los comandos a borrar, ya que no proporcionan informacion relevante para la ecuacion\n",
        "delete = ['\\\\Bigg','\\\\left','\\\\right','\\\\Big','\\\\mathrm']\n",
        "# comandos a reemplazar por el comando latex correcto\n",
        "replace = {'\\\\to':'\\\\rightarrow', '\\\\gt':'>', '\\\\lt':'<'}\n",
        "# simbolos a los que se les aÃ±ade espacios en blanco antes y despues para un mejor tratamiento\n",
        "add = ['_','{','}','=','(',')','-','+','^','[',']', ',']\n",
        "count = 0\n",
        "# se iteran los archivos .inkml, items representa el mismo diccionario guardado en labels.json\n",
        "for key in items:\n",
        "    # si existe alguno de los comandos descritos en las listas y diccionario anteriores se realizan la soperaciones\n",
        "    # correspondientes\n",
        "    for dele in delete:\n",
        "        if dele in items[key]:\n",
        "            items[key] = items[key].replace(dele, \"\")\n",
        "    for rep in replace:\n",
        "        if (rep in items[key]):\n",
        "            items[key] = items[key].replace(rep, replace[rep])\n",
        "    for it in add:\n",
        "        if (it in items[key]):\n",
        "            items[key] = items[key].replace(it, \" \"+it+\" \")\n",
        "    # se agrega un espacio en blanco antes de \\\\ para que pueda diferenciarse a los comandos del resto de letras o numeros\n",
        "    if ('\\\\' in items[key]):\n",
        "        items[key] = items[key].replace('\\\\', \" \\\\\")\n",
        "    # se separa el ground truth, siendo la condicion para separa el que existan uno o mas espacios en blanco entre caracteres\n",
        "    items[key] = re.split(r'\\s+', items[key])\n",
        "    count = 0\n",
        "    # se itera sobre la lista generada de letras, numeros, simbolos y comandos para cada archivo inkml\n",
        "    # separando los caracteres que se encuentren juntos y no sean parte de un comando, \n",
        "    # por ejemplo 'abc' se separa en 'a', 'b', 'c'\n",
        "    for a in items[key]:\n",
        "        if ('\\\\' not in a and len(a)>1):\n",
        "            uno = items[key][:count]\n",
        "            dos = re.split('', a)[1:-1]\n",
        "            tres = items[key][count+1:]\n",
        "            count+= len(dos)-1\n",
        "            uno.extend(dos)\n",
        "            uno.extend(tres)\n",
        "            items[key] = uno\n",
        "        count+=1\n",
        "    if (items[key][-1]==\"\"):\n",
        "        items[key] = items[key][:-1]\n",
        "    if (items[key][0]==\"\"):\n",
        "        items[key] = items[key][1:]\n",
        "# se guarda en labels.json\n",
        "with open(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\label.json\", 'w') as f:\n",
        "    json.dump(items, f, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeL-Ufr0m066",
        "outputId": "222f4e99-2b56-4c2b-f325-98c471c265db"
      },
      "source": [
        "# se instancia la llamada a la funcion Tokenizer de tensorflow\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# se define el numero maximo de palabras a tokenizar\n",
        "num_words = 1000\n",
        "# token para labels desconocidas\n",
        "oov_token = '<UNK>'\n",
        "pad_type = 'post'\n",
        "trunc_type = 'post'\n",
        "\n",
        "items = {}\n",
        "# se obtienen las listas de labels (numeros, comandos latex, simbolos y letras) para cada archivo inkml\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/TrainINKML/labels.json\", 'r') as f:\n",
        "    items = json.load(f)\n",
        "tokens = {}\n",
        "count = 0\n",
        "# se itera para cada archivo\n",
        "for key in items:\n",
        "    # se convierte a string\n",
        "    items[key] = ' '.join(map(str, items[key]))\n",
        "    # se anade al inicio y final los labels start y end para indicar inicio y final del ground truth\n",
        "    items[key] = '<start> '+items[key] + ' <end>'\n",
        "    # se vuelven a separar\n",
        "    items[key] = re.sub(r\"\\s+\", \" \", items[key])\n",
        "# se obtiene la cantidad de archvios inkml a tratar\n",
        "keys = list(items.keys())\n",
        "# se anade el groud truth de cada archivo a una lista\n",
        "data = [ items[key] for key in keys ]\n",
        "print(data[0])\n",
        "# se instancia la funcion tokenizer con los parametros establecidos en un principio\n",
        "tokenizer = Tokenizer(num_words=num_words, oov_token=oov_token, filters='', lower=False)\n",
        "# se obtienen los tokens para el conjunto de datos, es decir, a cada comando de latex, letra, numero o simbolo\n",
        "# utilizado se le asigna un numero entero en base a su frecuencia de aparicion\n",
        "tokenizer.fit_on_texts(data)\n",
        "# se define la cantidad de palabras o tokens\n",
        "word_index = tokenizer.word_index\n",
        "# se guardan los tokens en tokens.json\n",
        "with open(\"/tokens.json\", 'w') as f:\n",
        "    json.dump(word_index, f, indent=4)\n",
        "# se convierten los labels a tokens para cada archivo inkml\n",
        "# por ejemplo ['a','b','c'] se convierte a [1,2,3] asumiendo que estos son sus tokens\n",
        "train_sequences = tokenizer.texts_to_sequences(data)\n",
        "# se obtiene la longitud del label mas grande\n",
        "maxlen = max([len(x) for x in train_sequences])\n",
        "# se asocian los tokens a cada archivo haciendo un pad hacia la maxima longitud\n",
        "# tal que todos los archivos tenga por label una lista de la misma longitud, rellenando con ceros\n",
        "# aquellos tokens que se encuentran en una longitud mayor al verdadero para determinado archivo\n",
        "train_padded = pad_sequences(train_sequences, padding=pad_type, truncating=trunc_type, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> S = ( \\sum _ { i = 1 } ^ { n } \\theta _ i - ( n - 2 ) \\pi ) r ^ 2 <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnyncC_8m067"
      },
      "source": [
        "# IGNORAR PARA ENTRENAMIENTO\n",
        "NEW_PATH = R\"C:\\Users\\USUARIO\\Desktop\\Escuela\\OneDrive\\School Stuff\\Semestre 5\\Machine learning\\entrenamiento_proyecto\\TrainINKML\"\n",
        "LABELS_PATH = r\"/content/drive/My Drive/Colab Notebooks/TrainINKML\"\n",
        "tokens = {}\n",
        "files_imgs = {}\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/TrainINKML/tokens.json\", 'r') as f:\n",
        "    tokens = json.load(f)\n",
        "tokensPerFile = {}\n",
        "items = {}\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/TrainINKML/labels.json\", 'r') as f:\n",
        "    items = json.load(f)\n",
        "# se guardab los tokens por archivo inkml haciendo referencia ahora a la imagen \n",
        "# generada a partir del archvio inkml\n",
        "for key in items:\n",
        "    newKey = LABELS_PATH +'/images/'+ key[len(LABELS_PATH)+15:][:-6].replace('\\\\','/')+'.jpg'\n",
        "    tokensPerFile[newKey] = []\n",
        "    files_imgs[newKey] = NEW_PATH + key[43:].replace('\\\\','/')\n",
        "\n",
        "    for command in items[key]:\n",
        "        tokensPerFile[newKey].append(tokens[command])\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/TrainINKML/labelsPerFile.json\", 'w') as f:\n",
        "    json.dump(tokensPerFile, f, indent=4)\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/TrainINKML/files_img.json\", 'w') as f:\n",
        "    json.dump(files_imgs, f, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALcPac7Rm067",
        "outputId": "09e975d7-ecae-4136-f627-1b398921eb36"
      },
      "source": [
        "# se define la arquitectura del encoder en base a Zhang (2017)\n",
        "class FCN_encoder(tf.keras.Model):\n",
        "    def __init__(self, dropout_rate = 0.2):\n",
        "        super(FCN_encoder, self).__init__()\n",
        "        # super dentro del constructor permite que la clase herede y se convierta en un objeto de Keras\n",
        "        \n",
        "        # bloque de convolucion 1, 32 filtros\n",
        "        self.conv_1_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
        "        self.batch_1_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_1_1 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_1_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
        "        self.batch_1_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_1_2 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_1_3 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
        "        self.batch_1_3 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_1_3 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_1_4 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=1)\n",
        "        self.drop_1 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.batch_1_4 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_1_4 = tf.keras.layers.Activation('relu')\n",
        "        \n",
        "        # maxpooling para reducir el tamaÃ±o\n",
        "        self.maxPool_1 = tf.keras.layers.MaxPooling2D()\n",
        "        \n",
        "        # bloque convolucional 2, 64 filtros\n",
        "        self.conv_2_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.batch_2_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_2_1 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_2_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.batch_2_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_2_2 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_2_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.batch_2_3 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_2_3 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_2_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.drop_2 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.batch_2_4 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_2_4 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        self.maxPool_2 = tf.keras.layers.MaxPooling2D()\n",
        "\n",
        "        self.conv_3_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.batch_3_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_3_1 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_3_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.batch_3_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_3_2 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_3_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.batch_3_3 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_3_3 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_3_4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=1)\n",
        "        self.drop_3 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.batch_3_4 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_3_4 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        self.maxPool_3 = tf.keras.layers.MaxPooling2D()\n",
        "\n",
        "        self.conv_4_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
        "        self.batch_4_1 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_4_1 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_4_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
        "        self.batch_4_2 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_4_2 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_4_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
        "        self.batch_4_3 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_4_3 = tf.keras.layers.Activation('relu')\n",
        "        self.conv_4_4 = tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2)\n",
        "        self.drop_4 = tf.keras.layers.Dropout(dropout_rate)\n",
        "        self.batch_4_4 = tf.keras.layers.BatchNormalization()\n",
        "        self.act_4_4 = tf.keras.layers.Activation('relu')\n",
        "\n",
        "        self.maxPool_4 = tf.keras.layers.MaxPooling2D()\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        \n",
        "        x = self.conv_1_1(inputs)\n",
        "        x = self.batch_1_1(x)\n",
        "        x = self.act_1_1(x)\n",
        "        x = self.conv_1_2(x)\n",
        "        x = self.batch_1_2(x)\n",
        "        x = self.act_1_2(x)\n",
        "        x = self.conv_1_3(x)\n",
        "        x = self.batch_1_3(x)\n",
        "        x = self.act_1_3(x)\n",
        "        x = self.conv_1_4(x)\n",
        "        x = self.drop_1(x)\n",
        "        x = self.batch_1_4(x)\n",
        "        x = self.act_1_4(x)\n",
        "        x = self.maxPool_1(x)\n",
        "        \n",
        "        x = self.conv_2_1(x)\n",
        "        x = self.batch_2_1(x)\n",
        "        x = self.act_2_1(x)\n",
        "        x = self.conv_2_2(x)\n",
        "        x = self.batch_2_2(x)\n",
        "        x = self.act_2_2(x)\n",
        "        x = self.conv_2_3(x)\n",
        "        x = self.batch_2_3(x)\n",
        "        x = self.act_2_3(x)\n",
        "        x = self.conv_2_4(x)\n",
        "        x = self.drop_2(x)\n",
        "        x = self.batch_2_4(x)\n",
        "        x = self.act_2_4(x)\n",
        "        x = self.maxPool_2(x)\n",
        "        \n",
        "        x = self.conv_3_1(x)\n",
        "        x = self.batch_3_1(x)\n",
        "        x = self.act_3_1(x)\n",
        "        x = self.conv_3_2(x)\n",
        "        x = self.batch_3_2(x)\n",
        "        x = self.act_3_2(x)\n",
        "        x = self.conv_3_3(x)\n",
        "        x = self.batch_3_3(x)\n",
        "        x = self.act_3_3(x)\n",
        "        x = self.conv_3_4(x)\n",
        "        x = self.drop_3(x)\n",
        "        x = self.batch_3_4(x)\n",
        "        x = self.act_3_4(x)\n",
        "        x = self.maxPool_3(x)\n",
        "        \n",
        "        x = self.conv_4_1(x)\n",
        "        x = self.batch_4_1(x)\n",
        "        x = self.act_4_1(x)\n",
        "        x = self.conv_4_2(x)\n",
        "        x = self.batch_4_2(x)\n",
        "        x = self.act_4_2(x)\n",
        "        x = self.conv_4_3(x)\n",
        "        x = self.drop_4(x)\n",
        "        x = self.batch_4_3(x)\n",
        "        x = self.act_4_3(x)\n",
        "        x = self.conv_4_4(x)\n",
        "        x = self.drop_4(x)\n",
        "        x = self.batch_4_4(x)\n",
        "        x = self.act_4_4(x)\n",
        "        x = self.maxPool_4(x)\n",
        "    \n",
        "        return x\n",
        "    \n",
        "    def model(self):\n",
        "        input = tf.keras.layers.Input(shape=(512, 1024, 1))\n",
        "        return tf.keras.Model(inputs = input, outputs = self.call(input) )\n",
        "print(FCN_encoder().model().summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 512, 1024, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 510, 1022, 32 320         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 510, 1022, 32 128         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 510, 1022, 32 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 508, 1020, 32 9248        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 508, 1020, 32 128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 508, 1020, 32 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 506, 1018, 32 9248        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 506, 1018, 32 128         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 506, 1018, 32 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 504, 1016, 32 9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 504, 1016, 32 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 504, 1016, 32 128         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 504, 1016, 32 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 252, 508, 32) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 250, 506, 64) 18496       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 250, 506, 64) 256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 250, 506, 64) 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 248, 504, 64) 36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 248, 504, 64) 256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 248, 504, 64) 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 246, 502, 64) 36928       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 246, 502, 64) 256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 246, 502, 64) 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 244, 500, 64) 36928       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 244, 500, 64) 0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 244, 500, 64) 256         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 244, 500, 64) 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 122, 250, 64) 0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 120, 248, 64) 36928       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 120, 248, 64) 256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 120, 248, 64) 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 118, 246, 64) 36928       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 118, 246, 64) 256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 118, 246, 64) 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 116, 244, 64) 36928       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 116, 244, 64) 256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 116, 244, 64) 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 114, 242, 64) 36928       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 114, 242, 64) 0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 114, 242, 64) 256         dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 114, 242, 64) 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 57, 121, 64)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 60, 128)  73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 60, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 60, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 13, 29, 128)  147584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 13, 29, 128)  512         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 13, 29, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 6, 14, 128)   147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             multiple             0           conv2d_14[0][0]                  \n",
            "                                                                 conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 6, 14, 128)   512         dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 6, 14, 128)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 2, 6, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 2, 6, 128)    512         dropout_3[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 2, 6, 128)    0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 1, 3, 128)    0           activation_15[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 826,272\n",
            "Trainable params: 823,968\n",
            "Non-trainable params: 2,304\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBdEvEt6m068"
      },
      "source": [
        "# el modelo de atencion\n",
        "class Attender(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Attender, self).__init__()\n",
        "        # se instancia los distintos dense layers parametrizados en Zhang\n",
        "        self.W_1 = tf.keras.layers.Dense(128)\n",
        "        self.U_a = tf.keras.layers.Dense(128)\n",
        "        # la dimension de atencion es 128\n",
        "        self.V_a = tf.keras.layers.Dense(128)\n",
        "        #self.F = tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2)\n",
        "    \n",
        "    def call(self, a, h):\n",
        "        # se espanden dimensiones para el hidden state\n",
        "        h_t = tf.expand_dims(h, 1)\n",
        "        # se calcula el estado intermedio llamando a los dense layers y la funcion de tangente \n",
        "        # hiperbolica con la suma de los dos dense layers que reciben como parametro el hidden state\n",
        "        # y el vector de anotacion\n",
        "        e_ti = self.V_a( (tf.nn.tanh( self.W_1(h_t) + self.U_a(a))))\n",
        "        # se aplica la activacion softmax al resultado\n",
        "        a_ti = tf.nn.softmax(e_ti)\n",
        "        # se calcula el vector de contexto multiplicando los coeficientes a_ti por el vector de anotacion\n",
        "        context = a_ti * a\n",
        "        # se obtiene la suma del resutado de la multiplicacion anterior\n",
        "        context = (tf.reduce_sum(tf.reduce_sum(context, axis =1), axis=1))\n",
        "        # se regresa el vector de contexto y los coeficientes a_ti\n",
        "        return context, a_ti       "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j_uVk59m069"
      },
      "source": [
        "global_ = None\n",
        "# se define el modelo decoder que utiliza el gru\n",
        "class GRU_decoder(tf.keras.Model):\n",
        "    def __init__(self, dimension, units, label_len):\n",
        "        super(GRU_decoder, self).__init__()\n",
        "        # las unidades del gru\n",
        "        self.units = units\n",
        "        # la capa de embedding, establecida en Zhang como E\n",
        "        self.embedding = tf.keras.layers.Embedding(label_len, dimension)\n",
        "        # la capa del gru, se especifica que se desea el regreso de las secuencias y el ultimo estado calculado\n",
        "        self.gru = tf.keras.layers.GRU( self.units, return_sequences=True, return_state = True, recurrent_initializer='glorot_uniform')\n",
        "        # dense layers para el calculo de las probabilidades para cada palabra en el diccionario de palabras\n",
        "        # es decir, los tokens\n",
        "        self.fc1 = tf.keras.layers.Dense(128)\n",
        "        self.fc2 = tf.keras.layers.Dense(128)#,activation='softmax')\n",
        "        self.fc3 = tf.keras.layers.Dense(128)\n",
        "        # la ultima capa se define con una activacion softmax\n",
        "        self.fc4 = tf.keras.layers.Dense(128, activation='softmax')\n",
        "        # se instancia el modelo de atencion\n",
        "        self.attention = Attender()\n",
        "        self.g = None\n",
        "      \n",
        "    def call(self, x, a, h):\n",
        "        # la llamada recibe la entrada del decoder, la salida del encoder y el estado anterior del decoder\n",
        "        # se llama al modelo de atencion y se recibe el vector de contexto y los coeficientes de atencion\n",
        "        context_v, attention_pro = self.attention(a,h)\n",
        "        x = self.embedding(x)\n",
        "        #x = tf.reduce_sum(x, axis = 1)\n",
        "        # se anade el contexto a la entrada del decoder para utilizar el conocimeinto previo\n",
        "        t = tf.concat([context_v,x], axis =-1)\n",
        "        t = tf.expand_dims(t, 1)\n",
        "        # se alimenta al gru con dicha informacion y se obtiene una salida y su ultimo estado\n",
        "        out, state = self.gru(t)\n",
        "        out = tf.reduce_sum(out, axis=1)\n",
        "        self.g = out\n",
        "        \n",
        "        # es necesario calcular las probabilidades condicionales, por lo que se utiliza \n",
        "        # lo descrito por Zhang para cada parte de la salida del gru\n",
        "        a = self.fc1(out)\n",
        "        b = self.fc2(context_v)\n",
        "        c = self.fc3(x)\n",
        "        # se suman los resultados\n",
        "        res = a+b+c\n",
        "        # se obtienen las probabilidades gracias al softmax del ultimo layer\n",
        "        res = self.fc4(res)\n",
        "        #print(res.shape)\n",
        "        #x = tf.argmax(res, 1)\n",
        "        # se regresan las probabilidades, el estado y los coeficientes de atencion\n",
        "        return res, state, attention_pro\n",
        "    \n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        return cls(**config)\n",
        "\n",
        "    def reset(self, batch):\n",
        "        return tf.zeros((batch,3, self.units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUTMherym06-"
      },
      "source": [
        "# isntanciacion del encoder\n",
        "encoder = FCN_encoder()\n",
        "# isntanciacion del decoder, con valores para la dimension del embedding, del gru y la cantidad de tokens\n",
        "decoder = GRU_decoder(128,128,len(list(word_index.keys())))\n",
        "# se define una funcion de optimizacion para el modelo, el cual permite realizar la optimizacion en base\n",
        "# al gradiente de los errores\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "# definimos el tipo de calculo para los errores entre los correspondientes labels del ground truth de cada\n",
        "# imagen y las predicciones\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction='none')\n",
        "\n",
        "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "# se define una fucnion de loss (perdida o error) que recibe como parametro un label del ground truth por imagen \n",
        "# en el batch las matrices de prediccion asociadas a cada una de esas imagenes\n",
        "def loss_function(real, pred):\n",
        "    # se realiza una conversion del tipo de dato para las probabilidades de las predicciones\n",
        "    pred = tf.cast(pred, tf.float32)\n",
        "    # se establece una mascara para aquellas imagenes cuyo label sea 0, es decir, que\n",
        "    # es el padding agregado y que de esta forma no se considere su error para el error general\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    # se calcula el error\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    # se anade la mascara al los obtenido\n",
        "    loss_ *= mask\n",
        "    # se retorna la media de las perdidas para las imagenes en el batch\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sfEL4Psm06_"
      },
      "source": [
        "data = {}\n",
        "# se obtienen los tokens por imagen\n",
        "LABELS_PATH = \"/content/drive/My Drive/Colab Notebooks/TrainINKML/labelsPerFile.json\"\n",
        "with open(LABELS_PATH,  'r') as f:\n",
        "    data = json.load(f)\n",
        "    f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz69MKV0m07A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ddc249d-4c3f-46cb-b58a-515593f782e2"
      },
      "source": [
        "files_img = {}\n",
        "# se obtienen los nombres de las imagenes\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/TrainINKML/files_img.json\", 'r') as f:\n",
        "    files_img = json.load(f)\n",
        "    f.close()\n",
        "keys = list(files_img.keys())\n",
        "files = list(data.keys())\n",
        "# se obtiene el dataset a partir del diccionario que contiene los tokens por archivo\n",
        "list_ds = tf.data.Dataset.list_files(files)\n",
        "\n",
        "# funcion que obtiene la imagen y su label, tiene como parametro el path de la imagen\n",
        "def getProcessedImages(f):\n",
        "    index = keys.index(f)\n",
        "    # se lee la imagen\n",
        "    image = tf.io.read_file(f)\n",
        "    # se decodifica el formato jpg y se establece como imagen en un solo canal, es decir\n",
        "    # blanco y negro\n",
        "    image = tf.image.decode_jpeg(image, channels = 1)  \n",
        "    # se convierte su tipo de dato a flotante\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    # se redimensiona para que concuerde con el modelo del encoder\n",
        "    image = tf.image.resize(image, [512, 1024] ) \n",
        "    # se retorna la imagen (su matriz de pixels) y su label\n",
        "    return image, train_padded[index] #[data[str(tf.constant(f).numpy())[2:-1].replace('\\\\\\\\', '\\\\') ]]\n",
        "\n",
        "# define el dataset a utilizar como un mapeo de los archvios dentro de list_ds que manda llamar a la funcion getProcessedImages\n",
        "labeledDataset = list_ds.map(lambda x: tf.py_function(getProcessedImages, [x], [tf.float32, tf.int32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# solo para verificar que funciona, imprime las dimensioens de la imagen y su label\n",
        "for image, label in labeledDataset.take(1):\n",
        "    print(\"Image shape: \", image.numpy().shape)\n",
        "    print(\"Label: \", label.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape:  (512, 1024, 1)\n",
            "Label:  [ 4  2 23  2 20  2 88  3  3  3  8  2 62  3  5  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKAOv3vQm07B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc815cee-4742-4c68-df81-75d6184b6551"
      },
      "source": [
        "# se establece el tamano de batch como 8, es decir, se ingresara al entrenamiento paquetes de 8 imagenes\n",
        "labeledDataset = labeledDataset.shuffle(buffer_size=20)\n",
        "labeledDataset = labeledDataset.batch(8)\n",
        "print(len(labeledDataset))\n",
        "#labeledDataset = labeledDataset.prefetch(buffer_size = tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1023\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqvyQ5XXm07C"
      },
      "source": [
        "import random\n",
        "# se define la funcion que entrena al modelo de encoder-decoder\n",
        "# recibe como parametros el batch de imagenes y su ground truth (labels)\n",
        "def train(image, groundTruth):\n",
        "    loss = 0\n",
        "    # el estado del gru se inicializa como ceros\n",
        "    hidden = decoder.reset(groundTruth.shape[0])\n",
        "    # el input del decoder se inicializa como un tensor con valores para el primer token en todas las imagenes\n",
        "    input_decoder = tf.constant([word_index['<start>']] * groundTruth.shape[0])\n",
        "    #input_decoder = tf.expand_dims([[word_index['<start>']]*3] * groundTruth.shape[0], 1)\n",
        "    #print(input_decoder.shape, hidden.shape)\n",
        "    # ciclo que permite el entrenamiento al generar un entorno donde las variables de entrenamiento son 'vigiladas'\n",
        "    # durante el entrenamiento para poder corregirlas y ajusstar el modelo\n",
        "    count = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        # se llama al encoder con la imagen la cual regresa el feature map con las caracteristicas extraidas de la imagen\n",
        "        feature_map = encoder(image)\n",
        "        # se itera por la cantidad de posibles palabras en un groundTruth\n",
        "        for i in range(1, groundTruth.shape[1]):\n",
        "            count +=1\n",
        "            # para cada palabra se verifica si su tensor corresponde a solo valores en cero, para lo cual se rompe el ciclo\n",
        "            # terminando el entrenamiento de este batch\n",
        "            sum_ = tf.reduce_sum(groundTruth[:,i])\n",
        "            allZero = tf.equal(sum_, 0)\n",
        "            if (allZero):\n",
        "                break\n",
        "            # si existe por lo menos un label por predecir entonces se llama al decoder envindole \n",
        "            # su respectivo input, las salidas del encoder y el hidden state anterior\n",
        "            pred, hidden, alphas = decoder(input_decoder, feature_map, hidden)\n",
        "            #encoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{0}.h5\".format(2))\n",
        "            #decoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec\\epoch{0}.h5\".format(2))\n",
        "            \n",
        "            #print(groundTruth[:,i], pred.shape, hidden.shape, alphas.shape)\n",
        "            # se calcula el error de las predicciones y se suma al actual para el batch\n",
        "            loss += loss_function(groundTruth[:, i], pred)\n",
        "            accuracy.update_state(groundTruth[:, i], pred)\n",
        "            #print(i,\"loss:\", loss)\n",
        "            # la siguiente entrada para el decoder son las anotaciones para la iteracion actual\n",
        "            # es decir, la anterior para la siguiente interacion (h-1)\n",
        "            input_decoder = groundTruth[:, i]\n",
        "    # una vez que termina la entrada del batch se calcula el error total con el error obtenido\n",
        "    total_loss = (loss / count)\n",
        "    # se obtienen las variables a las que se les puede modificar los parametros para ajustarlas (entrenarlas)\n",
        "    trainable_variables = encoder.trainable_weights + decoder.trainable_weights\n",
        "    # se obtiene el gradiente de error en base al error obtenido\n",
        "    gradients = tape.gradient(loss, trainable_variables)\n",
        "    # se realiza el ajuste en base al gradiente de error\n",
        "    optimizer.apply_gradients(zip(gradients, trainable_variables))\n",
        "    # se regresa el error y el error total\n",
        "    return loss, total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT-y7pKJm07C"
      },
      "source": [
        "# funcion que itera sobre el dataset para entrenarlo\n",
        "def trainData(dataset, EPOCHS = 2):\n",
        "    print(len(dataset))\n",
        "    # se itera por las epocas de entrenamiento\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        num = 0\n",
        "        # para cada batch de images en el dataset\n",
        "        for (batch, (img_tensor, target)) in enumerate(dataset):\n",
        "            # se llama a la funcion de entrenamiento para cada batch enviando el tensor de imagenes y de labels\n",
        "            # obteniendo los erroes\n",
        "            print(\"batch\",batch+1, end=\" \")\n",
        "            batch_loss, t_loss = train(img_tensor, target)\n",
        "            #encoder.load_weights(\"/content/drive/My Drive/Colab Notebooks/train/enc/epoch{0}.h5\".format(4))\n",
        "            #decoder.load_weights(\"/content/drive/My Drive/Colab Notebooks/train/dec/epoch{0}.h5\".format(4))\n",
        "            #break\n",
        "            print(\"accuracy:\", accuracy.result(), end=\"\\n\")\n",
        "            total_loss += t_loss\n",
        "            num +=1\n",
        "            '''if ((batch +1)%10 ==0 ):\n",
        "                break'''\n",
        "        #break\n",
        "        print('Epoch {0:d}/{1:d}'.format(epoch+1, EPOCHS))\n",
        "        print('===============>  train-loss=%.3f' % (total_loss/num))\n",
        "        \n",
        "        encoder.save_weights(\"/content/drive/My Drive/Colab Notebooks/train/enc/epoch{0}.h5\".format(epoch),\n",
        "                            save_format='h5')\n",
        "        decoder.save_weights(\"/content/drive/My Drive/Colab Notebooks/train/dec/epoch{0}.h5\".format(epoch),\n",
        "                    save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y84oT5Ozm07D",
        "outputId": "30fc92d4-a6d3-404b-c1a3-81c8dd9cdbf8"
      },
      "source": [
        "# se llama la funcion principal de entrenamiento\n",
        "'''encoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{0}.h5\".format(0))\n",
        "decoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec\\epoch{0}.h5\".format(0))'''\n",
        "trainData(labeledDataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1023\n",
            "batch 1 accuracy: tf.Tensor(0.072115384, shape=(), dtype=float32)\n",
            "batch 2 accuracy: tf.Tensor(0.10185185, shape=(), dtype=float32)\n",
            "batch 3 accuracy: tf.Tensor(0.10873984, shape=(), dtype=float32)\n",
            "batch 4 accuracy: tf.Tensor(0.14102565, shape=(), dtype=float32)\n",
            "batch 5 accuracy: tf.Tensor(0.14605263, shape=(), dtype=float32)\n",
            "batch 6 accuracy: tf.Tensor(0.14497717, shape=(), dtype=float32)\n",
            "batch 7 accuracy: tf.Tensor(0.1495098, shape=(), dtype=float32)\n",
            "batch 8 accuracy: tf.Tensor(0.14967105, shape=(), dtype=float32)\n",
            "batch 9 accuracy: tf.Tensor(0.15415452, shape=(), dtype=float32)\n",
            "batch 10 accuracy: tf.Tensor(0.15607923, shape=(), dtype=float32)\n",
            "batch 11 accuracy: tf.Tensor(0.15394402, shape=(), dtype=float32)\n",
            "batch 12 accuracy: tf.Tensor(0.15458937, shape=(), dtype=float32)\n",
            "batch 13 accuracy: tf.Tensor(0.15308988, shape=(), dtype=float32)\n",
            "batch 14 accuracy: tf.Tensor(0.15171161, shape=(), dtype=float32)\n",
            "batch 15 accuracy: tf.Tensor(0.15315534, shape=(), dtype=float32)\n",
            "batch 16 accuracy: tf.Tensor(0.15262681, shape=(), dtype=float32)\n",
            "batch 17 accuracy: tf.Tensor(0.15303938, shape=(), dtype=float32)\n",
            "batch 18 accuracy: tf.Tensor(0.155625, shape=(), dtype=float32)\n",
            "batch 19 accuracy: tf.Tensor(0.15976563, shape=(), dtype=float32)\n",
            "batch 20 accuracy: tf.Tensor(0.15978423, shape=(), dtype=float32)\n",
            "batch 21 accuracy: tf.Tensor(0.1592031, shape=(), dtype=float32)\n",
            "batch 22 accuracy: tf.Tensor(0.15405047, shape=(), dtype=float32)\n",
            "batch 23 accuracy: tf.Tensor(0.15239295, shape=(), dtype=float32)\n",
            "batch 24 accuracy: tf.Tensor(0.15146531, shape=(), dtype=float32)\n",
            "batch 25 accuracy: tf.Tensor(0.1515748, shape=(), dtype=float32)\n",
            "batch 26 accuracy: tf.Tensor(0.15060242, shape=(), dtype=float32)\n",
            "batch 27 accuracy: tf.Tensor(0.14955357, shape=(), dtype=float32)\n",
            "batch 28 accuracy: tf.Tensor(0.15103118, shape=(), dtype=float32)\n",
            "batch 29 accuracy: tf.Tensor(0.1518635, shape=(), dtype=float32)\n",
            "batch 30 accuracy: tf.Tensor(0.1521028, shape=(), dtype=float32)\n",
            "batch 31 accuracy: tf.Tensor(0.1528777, shape=(), dtype=float32)\n",
            "batch 32 accuracy: tf.Tensor(0.15355888, shape=(), dtype=float32)\n",
            "batch 33 accuracy: tf.Tensor(0.15300429, shape=(), dtype=float32)\n",
            "batch 34 accuracy: tf.Tensor(0.15078707, shape=(), dtype=float32)\n",
            "batch 35 accuracy: tf.Tensor(0.15054744, shape=(), dtype=float32)\n",
            "batch 36 accuracy: tf.Tensor(0.15083136, shape=(), dtype=float32)\n",
            "batch 37 accuracy: tf.Tensor(0.15015303, shape=(), dtype=float32)\n",
            "batch 38 accuracy: tf.Tensor(0.14955357, shape=(), dtype=float32)\n",
            "batch 39 accuracy: tf.Tensor(0.14992669, shape=(), dtype=float32)\n",
            "batch 40 accuracy: tf.Tensor(0.15107527, shape=(), dtype=float32)\n",
            "batch 41 accuracy: tf.Tensor(0.1521739, shape=(), dtype=float32)\n",
            "batch 42 accuracy: tf.Tensor(0.15248963, shape=(), dtype=float32)\n",
            "batch 43 accuracy: tf.Tensor(0.1529482, shape=(), dtype=float32)\n",
            "batch 44 accuracy: tf.Tensor(0.15356183, shape=(), dtype=float32)\n",
            "batch 45 accuracy: tf.Tensor(0.15388381, shape=(), dtype=float32)\n",
            "batch 46 accuracy: tf.Tensor(0.15422286, shape=(), dtype=float32)\n",
            "batch 47 accuracy: tf.Tensor(0.15382798, shape=(), dtype=float32)\n",
            "batch 48 accuracy: tf.Tensor(0.1541411, shape=(), dtype=float32)\n",
            "batch 49 accuracy: tf.Tensor(0.15468279, shape=(), dtype=float32)\n",
            "batch 50 accuracy: tf.Tensor(0.15466984, shape=(), dtype=float32)\n",
            "batch 51 accuracy: tf.Tensor(0.15398024, shape=(), dtype=float32)\n",
            "batch 52 accuracy: tf.Tensor(0.15521191, shape=(), dtype=float32)\n",
            "batch 53 accuracy: tf.Tensor(0.1547486, shape=(), dtype=float32)\n",
            "batch 54 accuracy: tf.Tensor(0.15284455, shape=(), dtype=float32)\n",
            "batch 55 accuracy: tf.Tensor(0.15391201, shape=(), dtype=float32)\n",
            "batch 56 accuracy: tf.Tensor(0.15414071, shape=(), dtype=float32)\n",
            "batch 57 accuracy: tf.Tensor(0.15144597, shape=(), dtype=float32)\n",
            "batch 58 accuracy: tf.Tensor(0.15119047, shape=(), dtype=float32)\n",
            "batch 59 accuracy: tf.Tensor(0.15162322, shape=(), dtype=float32)\n",
            "batch 60 accuracy: tf.Tensor(0.15119106, shape=(), dtype=float32)\n",
            "batch 61 accuracy: tf.Tensor(0.14919356, shape=(), dtype=float32)\n",
            "batch 62 accuracy: tf.Tensor(0.14946784, shape=(), dtype=float32)\n",
            "batch 63 accuracy: tf.Tensor(0.14926636, shape=(), dtype=float32)\n",
            "batch 64 accuracy: tf.Tensor(0.14953166, shape=(), dtype=float32)\n",
            "batch 65 accuracy: tf.Tensor(0.14915828, shape=(), dtype=float32)\n",
            "batch 66 accuracy: tf.Tensor(0.1493161, shape=(), dtype=float32)\n",
            "batch 67 accuracy: tf.Tensor(0.14957173, shape=(), dtype=float32)\n",
            "batch 68 accuracy: tf.Tensor(0.15077265, shape=(), dtype=float32)\n",
            "batch 69 accuracy: tf.Tensor(0.1504397, shape=(), dtype=float32)\n",
            "batch 70 accuracy: tf.Tensor(0.15065546, shape=(), dtype=float32)\n",
            "batch 71 accuracy: tf.Tensor(0.15047131, shape=(), dtype=float32)\n",
            "batch 72 accuracy: tf.Tensor(0.15094899, shape=(), dtype=float32)\n",
            "batch 73 accuracy: tf.Tensor(0.15079287, shape=(), dtype=float32)\n",
            "batch 74 accuracy: tf.Tensor(0.15098532, shape=(), dtype=float32)\n",
            "batch 75 accuracy: tf.Tensor(0.15074371, shape=(), dtype=float32)\n",
            "batch 76 accuracy: tf.Tensor(0.15072696, shape=(), dtype=float32)\n",
            "batch 77 accuracy: tf.Tensor(0.15040156, shape=(), dtype=float32)\n",
            "batch 78 accuracy: tf.Tensor(0.14993618, shape=(), dtype=float32)\n",
            "batch 79 accuracy: tf.Tensor(0.14962053, shape=(), dtype=float32)\n",
            "batch 80 accuracy: tf.Tensor(0.14982079, shape=(), dtype=float32)\n",
            "batch 81 accuracy: tf.Tensor(0.15002666, shape=(), dtype=float32)\n",
            "batch 82 accuracy: tf.Tensor(0.15018526, shape=(), dtype=float32)\n",
            "batch 83 accuracy: tf.Tensor(0.14969406, shape=(), dtype=float32)\n",
            "batch 84 accuracy: tf.Tensor(0.1495174, shape=(), dtype=float32)\n",
            "batch 85 accuracy: tf.Tensor(0.14928058, shape=(), dtype=float32)\n",
            "batch 86 accuracy: tf.Tensor(0.14922908, shape=(), dtype=float32)\n",
            "batch 87 accuracy: tf.Tensor(0.14858411, shape=(), dtype=float32)\n",
            "batch 88 accuracy: tf.Tensor(0.14835669, shape=(), dtype=float32)\n",
            "batch 89 accuracy: tf.Tensor(0.14786136, shape=(), dtype=float32)\n",
            "batch 90 accuracy: tf.Tensor(0.14800291, shape=(), dtype=float32)\n",
            "batch 91 accuracy: tf.Tensor(0.148435, shape=(), dtype=float32)\n",
            "batch 92 accuracy: tf.Tensor(0.14882651, shape=(), dtype=float32)\n",
            "batch 93 accuracy: tf.Tensor(0.14953819, shape=(), dtype=float32)\n",
            "batch 94 accuracy: tf.Tensor(0.1498062, shape=(), dtype=float32)\n",
            "batch 95 accuracy: tf.Tensor(0.15048283, shape=(), dtype=float32)\n",
            "batch 96 accuracy: tf.Tensor(0.15000756, shape=(), dtype=float32)\n",
            "batch 97 accuracy: tf.Tensor(0.15135723, shape=(), dtype=float32)\n",
            "batch 98 accuracy: tf.Tensor(0.15010247, shape=(), dtype=float32)\n",
            "batch 99 accuracy: tf.Tensor(0.15013017, shape=(), dtype=float32)\n",
            "batch 100 accuracy: tf.Tensor(0.15013665, shape=(), dtype=float32)\n",
            "batch 101 accuracy: tf.Tensor(0.15046889, shape=(), dtype=float32)\n",
            "batch 102 accuracy: tf.Tensor(0.15105782, shape=(), dtype=float32)\n",
            "batch 103 accuracy: tf.Tensor(0.15113923, shape=(), dtype=float32)\n",
            "batch 104 accuracy: tf.Tensor(0.1511395, shape=(), dtype=float32)\n",
            "batch 105 accuracy: tf.Tensor(0.15135562, shape=(), dtype=float32)\n",
            "batch 106 accuracy: tf.Tensor(0.15120088, shape=(), dtype=float32)\n",
            "batch 107 accuracy: tf.Tensor(0.15135664, shape=(), dtype=float32)\n",
            "batch 108 accuracy: tf.Tensor(0.1512205, shape=(), dtype=float32)\n",
            "batch 109 accuracy: tf.Tensor(0.15173832, shape=(), dtype=float32)\n",
            "batch 110 accuracy: tf.Tensor(0.15176688, shape=(), dtype=float32)\n",
            "batch 111 accuracy: tf.Tensor(0.15121856, shape=(), dtype=float32)\n",
            "batch 112 accuracy: tf.Tensor(0.15164092, shape=(), dtype=float32)\n",
            "batch 113 accuracy: tf.Tensor(0.15140486, shape=(), dtype=float32)\n",
            "batch 114 accuracy: tf.Tensor(0.15139417, shape=(), dtype=float32)\n",
            "batch 115 accuracy: tf.Tensor(0.15130916, shape=(), dtype=float32)\n",
            "batch 116 accuracy: tf.Tensor(0.1501736, shape=(), dtype=float32)\n",
            "batch 117 accuracy: tf.Tensor(0.15028366, shape=(), dtype=float32)\n",
            "batch 118 accuracy: tf.Tensor(0.14930809, shape=(), dtype=float32)\n",
            "batch 119 accuracy: tf.Tensor(0.14929391, shape=(), dtype=float32)\n",
            "batch 120 accuracy: tf.Tensor(0.14947262, shape=(), dtype=float32)\n",
            "batch 121 accuracy: tf.Tensor(0.14935942, shape=(), dtype=float32)\n",
            "batch 122 accuracy: tf.Tensor(0.14945081, shape=(), dtype=float32)\n",
            "batch 123 accuracy: tf.Tensor(0.14961155, shape=(), dtype=float32)\n",
            "batch 124 accuracy: tf.Tensor(0.15017861, shape=(), dtype=float32)\n",
            "batch 125 accuracy: tf.Tensor(0.14974937, shape=(), dtype=float32)\n",
            "batch 126 accuracy: tf.Tensor(0.14943525, shape=(), dtype=float32)\n",
            "batch 127 accuracy: tf.Tensor(0.14937194, shape=(), dtype=float32)\n",
            "batch 128 accuracy: tf.Tensor(0.14940305, shape=(), dtype=float32)\n",
            "batch 129 accuracy: tf.Tensor(0.1489565, shape=(), dtype=float32)\n",
            "batch 130 accuracy: tf.Tensor(0.14885226, shape=(), dtype=float32)\n",
            "batch 131 accuracy: tf.Tensor(0.14844087, shape=(), dtype=float32)\n",
            "batch 132 accuracy: tf.Tensor(0.14853412, shape=(), dtype=float32)\n",
            "batch 133 accuracy: tf.Tensor(0.14819099, shape=(), dtype=float32)\n",
            "batch 134 accuracy: tf.Tensor(0.1482467, shape=(), dtype=float32)\n",
            "batch 135 accuracy: tf.Tensor(0.14812319, shape=(), dtype=float32)\n",
            "batch 136 accuracy: tf.Tensor(0.14783481, shape=(), dtype=float32)\n",
            "batch 137 accuracy: tf.Tensor(0.14737056, shape=(), dtype=float32)\n",
            "batch 138 accuracy: tf.Tensor(0.14740925, shape=(), dtype=float32)\n",
            "batch 139 accuracy: tf.Tensor(0.14776382, shape=(), dtype=float32)\n",
            "batch 140 accuracy: tf.Tensor(0.14745569, shape=(), dtype=float32)\n",
            "batch 141 accuracy: tf.Tensor(0.14759454, shape=(), dtype=float32)\n",
            "batch 142 accuracy: tf.Tensor(0.1473319, shape=(), dtype=float32)\n",
            "batch 143 accuracy: tf.Tensor(0.14746454, shape=(), dtype=float32)\n",
            "batch 144 accuracy: tf.Tensor(0.14716534, shape=(), dtype=float32)\n",
            "batch 145 accuracy: tf.Tensor(0.14736085, shape=(), dtype=float32)\n",
            "batch 146 accuracy: tf.Tensor(0.14737596, shape=(), dtype=float32)\n",
            "batch 147 accuracy: tf.Tensor(0.14739692, shape=(), dtype=float32)\n",
            "batch 148 accuracy: tf.Tensor(0.14719075, shape=(), dtype=float32)\n",
            "batch 149 accuracy: tf.Tensor(0.14702994, shape=(), dtype=float32)\n",
            "batch 150 accuracy: tf.Tensor(0.14698772, shape=(), dtype=float32)\n",
            "batch 151 accuracy: tf.Tensor(0.14718115, shape=(), dtype=float32)\n",
            "batch 152 accuracy: tf.Tensor(0.14697777, shape=(), dtype=float32)\n",
            "batch 153 accuracy: tf.Tensor(0.14722374, shape=(), dtype=float32)\n",
            "batch 154 accuracy: tf.Tensor(0.1474551, shape=(), dtype=float32)\n",
            "batch 155 accuracy: tf.Tensor(0.14797018, shape=(), dtype=float32)\n",
            "batch 156 accuracy: tf.Tensor(0.14798518, shape=(), dtype=float32)\n",
            "batch 157 accuracy: tf.Tensor(0.14823048, shape=(), dtype=float32)\n",
            "batch 158 accuracy: tf.Tensor(0.14780958, shape=(), dtype=float32)\n",
            "batch 159 accuracy: tf.Tensor(0.14807253, shape=(), dtype=float32)\n",
            "batch 160 accuracy: tf.Tensor(0.14835165, shape=(), dtype=float32)\n",
            "batch 161 accuracy: tf.Tensor(0.14836976, shape=(), dtype=float32)\n",
            "batch 162 accuracy: tf.Tensor(0.14823677, shape=(), dtype=float32)\n",
            "batch 163 accuracy: tf.Tensor(0.14812113, shape=(), dtype=float32)\n",
            "batch 164 accuracy: tf.Tensor(0.14784695, shape=(), dtype=float32)\n",
            "batch 165 accuracy: tf.Tensor(0.14734848, shape=(), dtype=float32)\n",
            "batch 166 accuracy: tf.Tensor(0.14739837, shape=(), dtype=float32)\n",
            "batch 167 accuracy: tf.Tensor(0.1475345, shape=(), dtype=float32)\n",
            "batch 168 accuracy: tf.Tensor(0.1473856, shape=(), dtype=float32)\n",
            "batch 169 accuracy: tf.Tensor(0.14745276, shape=(), dtype=float32)\n",
            "batch 170 accuracy: tf.Tensor(0.14714262, shape=(), dtype=float32)\n",
            "batch 171 accuracy: tf.Tensor(0.1471171, shape=(), dtype=float32)\n",
            "batch 172 accuracy: tf.Tensor(0.14714986, shape=(), dtype=float32)\n",
            "batch 173 accuracy: tf.Tensor(0.14686699, shape=(), dtype=float32)\n",
            "batch 174 accuracy: tf.Tensor(0.14706233, shape=(), dtype=float32)\n",
            "batch 175 accuracy: tf.Tensor(0.14685328, shape=(), dtype=float32)\n",
            "batch 176 accuracy: tf.Tensor(0.14682944, shape=(), dtype=float32)\n",
            "batch 177 accuracy: tf.Tensor(0.14628609, shape=(), dtype=float32)\n",
            "batch 178 accuracy: tf.Tensor(0.14610742, shape=(), dtype=float32)\n",
            "batch 179 accuracy: tf.Tensor(0.14619297, shape=(), dtype=float32)\n",
            "batch 180 accuracy: tf.Tensor(0.14591938, shape=(), dtype=float32)\n",
            "batch 181 accuracy: tf.Tensor(0.1457256, shape=(), dtype=float32)\n",
            "batch 182 accuracy: tf.Tensor(0.14535235, shape=(), dtype=float32)\n",
            "batch 183 accuracy: tf.Tensor(0.14567994, shape=(), dtype=float32)\n",
            "batch 184 accuracy: tf.Tensor(0.14555281, shape=(), dtype=float32)\n",
            "batch 185 accuracy: tf.Tensor(0.14551654, shape=(), dtype=float32)\n",
            "batch 186 accuracy: tf.Tensor(0.14538245, shape=(), dtype=float32)\n",
            "batch 187 accuracy: tf.Tensor(0.14571956, shape=(), dtype=float32)\n",
            "batch 188 accuracy: tf.Tensor(0.14572929, shape=(), dtype=float32)\n",
            "batch 189 accuracy: tf.Tensor(0.14574507, shape=(), dtype=float32)\n",
            "batch 190 accuracy: tf.Tensor(0.1453826, shape=(), dtype=float32)\n",
            "batch 191 accuracy: tf.Tensor(0.14535978, shape=(), dtype=float32)\n",
            "batch 192 accuracy: tf.Tensor(0.14540927, shape=(), dtype=float32)\n",
            "batch 193 accuracy: tf.Tensor(0.14549534, shape=(), dtype=float32)\n",
            "batch 194 accuracy: tf.Tensor(0.14564876, shape=(), dtype=float32)\n",
            "batch 195 accuracy: tf.Tensor(0.14560811, shape=(), dtype=float32)\n",
            "batch 196 accuracy: tf.Tensor(0.14575659, shape=(), dtype=float32)\n",
            "batch 197 accuracy: tf.Tensor(0.14588626, shape=(), dtype=float32)\n",
            "batch 198 accuracy: tf.Tensor(0.14602065, shape=(), dtype=float32)\n",
            "batch 199 accuracy: tf.Tensor(0.14613907, shape=(), dtype=float32)\n",
            "batch 200 accuracy: tf.Tensor(0.14621064, shape=(), dtype=float32)\n",
            "batch 201 accuracy: tf.Tensor(0.14587073, shape=(), dtype=float32)\n",
            "batch 202 accuracy: tf.Tensor(0.14565054, shape=(), dtype=float32)\n",
            "batch 203 accuracy: tf.Tensor(0.14558041, shape=(), dtype=float32)\n",
            "batch 204 accuracy: tf.Tensor(0.1456804, shape=(), dtype=float32)\n",
            "batch 205 accuracy: tf.Tensor(0.14554308, shape=(), dtype=float32)\n",
            "batch 206 accuracy: tf.Tensor(0.14521219, shape=(), dtype=float32)\n",
            "batch 207 accuracy: tf.Tensor(0.14523634, shape=(), dtype=float32)\n",
            "batch 208 accuracy: tf.Tensor(0.1453469, shape=(), dtype=float32)\n",
            "batch 209 accuracy: tf.Tensor(0.1457586, shape=(), dtype=float32)\n",
            "batch 210 accuracy: tf.Tensor(0.14596252, shape=(), dtype=float32)\n",
            "batch 211 accuracy: tf.Tensor(0.14633028, shape=(), dtype=float32)\n",
            "batch 212 accuracy: tf.Tensor(0.14628458, shape=(), dtype=float32)\n",
            "batch 213 accuracy: tf.Tensor(0.1461496, shape=(), dtype=float32)\n",
            "batch 214 accuracy: tf.Tensor(0.14611082, shape=(), dtype=float32)\n",
            "batch 215 accuracy: tf.Tensor(0.14636423, shape=(), dtype=float32)\n",
            "batch 216 accuracy: tf.Tensor(0.14663616, shape=(), dtype=float32)\n",
            "batch 217 accuracy: tf.Tensor(0.14678971, shape=(), dtype=float32)\n",
            "batch 218 accuracy: tf.Tensor(0.1468027, shape=(), dtype=float32)\n",
            "batch 219 accuracy: tf.Tensor(0.14690933, shape=(), dtype=float32)\n",
            "batch 220 accuracy: tf.Tensor(0.1469312, shape=(), dtype=float32)\n",
            "batch 221 accuracy: tf.Tensor(0.14676297, shape=(), dtype=float32)\n",
            "batch 222 accuracy: tf.Tensor(0.1465953, shape=(), dtype=float32)\n",
            "batch 223 accuracy: tf.Tensor(0.14662834, shape=(), dtype=float32)\n",
            "batch 224 accuracy: tf.Tensor(0.14667657, shape=(), dtype=float32)\n",
            "batch 225 accuracy: tf.Tensor(0.14693984, shape=(), dtype=float32)\n",
            "batch 226 accuracy: tf.Tensor(0.14712131, shape=(), dtype=float32)\n",
            "batch 227 accuracy: tf.Tensor(0.14705612, shape=(), dtype=float32)\n",
            "batch 228 accuracy: tf.Tensor(0.14711374, shape=(), dtype=float32)\n",
            "batch 229 accuracy: tf.Tensor(0.1471018, shape=(), dtype=float32)\n",
            "batch 230 accuracy: tf.Tensor(0.14720236, shape=(), dtype=float32)\n",
            "batch 231 accuracy: tf.Tensor(0.14723028, shape=(), dtype=float32)\n",
            "batch 232 accuracy: tf.Tensor(0.14694485, shape=(), dtype=float32)\n",
            "batch 233 accuracy: tf.Tensor(0.14701654, shape=(), dtype=float32)\n",
            "batch 234 accuracy: tf.Tensor(0.14700873, shape=(), dtype=float32)\n",
            "batch 235 accuracy: tf.Tensor(0.1467178, shape=(), dtype=float32)\n",
            "batch 236 accuracy: tf.Tensor(0.14607918, shape=(), dtype=float32)\n",
            "batch 237 accuracy: tf.Tensor(0.14623389, shape=(), dtype=float32)\n",
            "batch 238 accuracy: tf.Tensor(0.14637677, shape=(), dtype=float32)\n",
            "batch 239 accuracy: tf.Tensor(0.14630201, shape=(), dtype=float32)\n",
            "batch 240 accuracy: tf.Tensor(0.14610389, shape=(), dtype=float32)\n",
            "batch 241 accuracy: tf.Tensor(0.14634076, shape=(), dtype=float32)\n",
            "batch 242 accuracy: tf.Tensor(0.14635657, shape=(), dtype=float32)\n",
            "batch 243 accuracy: tf.Tensor(0.14641708, shape=(), dtype=float32)\n",
            "batch 244 accuracy: tf.Tensor(0.14604482, shape=(), dtype=float32)\n",
            "batch 245 accuracy: tf.Tensor(0.1460741, shape=(), dtype=float32)\n",
            "batch 246 accuracy: tf.Tensor(0.14616492, shape=(), dtype=float32)\n",
            "batch 247 accuracy: tf.Tensor(0.14609313, shape=(), dtype=float32)\n",
            "batch 248 accuracy: tf.Tensor(0.14614567, shape=(), dtype=float32)\n",
            "batch 249 accuracy: tf.Tensor(0.14602621, shape=(), dtype=float32)\n",
            "batch 250 accuracy: tf.Tensor(0.1461928, shape=(), dtype=float32)\n",
            "batch 251 accuracy: tf.Tensor(0.14614959, shape=(), dtype=float32)\n",
            "batch 252 accuracy: tf.Tensor(0.1465422, shape=(), dtype=float32)\n",
            "batch 253 accuracy: tf.Tensor(0.14626168, shape=(), dtype=float32)\n",
            "batch 254 accuracy: tf.Tensor(0.1463722, shape=(), dtype=float32)\n",
            "batch 255 accuracy: tf.Tensor(0.14626352, shape=(), dtype=float32)\n",
            "batch 256 accuracy: tf.Tensor(0.14650011, shape=(), dtype=float32)\n",
            "batch 257 accuracy: tf.Tensor(0.14638957, shape=(), dtype=float32)\n",
            "batch 258 accuracy: tf.Tensor(0.14646316, shape=(), dtype=float32)\n",
            "batch 259 accuracy: tf.Tensor(0.14644463, shape=(), dtype=float32)\n",
            "batch 260 accuracy: tf.Tensor(0.14636946, shape=(), dtype=float32)\n",
            "batch 261 accuracy: tf.Tensor(0.14671949, shape=(), dtype=float32)\n",
            "batch 262 accuracy: tf.Tensor(0.14683528, shape=(), dtype=float32)\n",
            "batch 263 accuracy: tf.Tensor(0.14692381, shape=(), dtype=float32)\n",
            "batch 264 accuracy: tf.Tensor(0.146919, shape=(), dtype=float32)\n",
            "batch 265 accuracy: tf.Tensor(0.1468655, shape=(), dtype=float32)\n",
            "batch 266 accuracy: tf.Tensor(0.14670682, shape=(), dtype=float32)\n",
            "batch 267 accuracy: tf.Tensor(0.14684, shape=(), dtype=float32)\n",
            "batch 268 accuracy: tf.Tensor(0.14679195, shape=(), dtype=float32)\n",
            "batch 269 accuracy: tf.Tensor(0.14672625, shape=(), dtype=float32)\n",
            "batch 270 accuracy: tf.Tensor(0.14702637, shape=(), dtype=float32)\n",
            "batch 271 accuracy: tf.Tensor(0.14702192, shape=(), dtype=float32)\n",
            "batch 272 accuracy: tf.Tensor(0.14714673, shape=(), dtype=float32)\n",
            "batch 273 accuracy: tf.Tensor(0.14713594, shape=(), dtype=float32)\n",
            "batch 274 accuracy: tf.Tensor(0.14718334, shape=(), dtype=float32)\n",
            "batch 275 accuracy: tf.Tensor(0.14721522, shape=(), dtype=float32)\n",
            "batch 276 accuracy: tf.Tensor(0.14700201, shape=(), dtype=float32)\n",
            "batch 277 accuracy: tf.Tensor(0.14709413, shape=(), dtype=float32)\n",
            "batch 278 accuracy: tf.Tensor(0.14713217, shape=(), dtype=float32)\n",
            "batch 279 accuracy: tf.Tensor(0.1467542, shape=(), dtype=float32)\n",
            "batch 280 accuracy: tf.Tensor(0.14676759, shape=(), dtype=float32)\n",
            "batch 281 accuracy: tf.Tensor(0.14678831, shape=(), dtype=float32)\n",
            "batch 282 accuracy: tf.Tensor(0.14679876, shape=(), dtype=float32)\n",
            "batch 283 accuracy: tf.Tensor(0.1467386, shape=(), dtype=float32)\n",
            "batch 284 accuracy: tf.Tensor(0.1467312, shape=(), dtype=float32)\n",
            "batch 285 accuracy: tf.Tensor(0.14684561, shape=(), dtype=float32)\n",
            "batch 286 accuracy: tf.Tensor(0.14678222, shape=(), dtype=float32)\n",
            "batch 287 accuracy: tf.Tensor(0.1468367, shape=(), dtype=float32)\n",
            "batch 288 accuracy: tf.Tensor(0.1467773, shape=(), dtype=float32)\n",
            "batch 289 accuracy: tf.Tensor(0.14696075, shape=(), dtype=float32)\n",
            "batch 290 accuracy: tf.Tensor(0.14702785, shape=(), dtype=float32)\n",
            "batch 291 accuracy: tf.Tensor(0.14700897, shape=(), dtype=float32)\n",
            "batch 292 accuracy: tf.Tensor(0.14694566, shape=(), dtype=float32)\n",
            "batch 293 accuracy: tf.Tensor(0.146716, shape=(), dtype=float32)\n",
            "batch 294 accuracy: tf.Tensor(0.14665708, shape=(), dtype=float32)\n",
            "batch 295 accuracy: tf.Tensor(0.1466, shape=(), dtype=float32)\n",
            "batch 296 accuracy: tf.Tensor(0.1466601, shape=(), dtype=float32)\n",
            "batch 297 accuracy: tf.Tensor(0.14671472, shape=(), dtype=float32)\n",
            "batch 298 accuracy: tf.Tensor(0.14647874, shape=(), dtype=float32)\n",
            "batch 299 accuracy: tf.Tensor(0.14644249, shape=(), dtype=float32)\n",
            "batch 300 accuracy: tf.Tensor(0.14628987, shape=(), dtype=float32)\n",
            "batch 301 accuracy: tf.Tensor(0.14614852, shape=(), dtype=float32)\n",
            "batch 302 accuracy: tf.Tensor(0.1461588, shape=(), dtype=float32)\n",
            "batch 303 accuracy: tf.Tensor(0.14633922, shape=(), dtype=float32)\n",
            "batch 304 accuracy: tf.Tensor(0.14622448, shape=(), dtype=float32)\n",
            "batch 305 accuracy: tf.Tensor(0.14658698, shape=(), dtype=float32)\n",
            "batch 306 accuracy: tf.Tensor(0.14644541, shape=(), dtype=float32)\n",
            "batch 307 accuracy: tf.Tensor(0.14638723, shape=(), dtype=float32)\n",
            "batch 308 accuracy: tf.Tensor(0.1463145, shape=(), dtype=float32)\n",
            "batch 309 accuracy: tf.Tensor(0.14635079, shape=(), dtype=float32)\n",
            "batch 310 accuracy: tf.Tensor(0.1461485, shape=(), dtype=float32)\n",
            "batch 311 accuracy: tf.Tensor(0.14616792, shape=(), dtype=float32)\n",
            "batch 312 accuracy: tf.Tensor(0.1463545, shape=(), dtype=float32)\n",
            "batch 313 accuracy: tf.Tensor(0.1464816, shape=(), dtype=float32)\n",
            "batch 314 accuracy: tf.Tensor(0.14647762, shape=(), dtype=float32)\n",
            "batch 315 accuracy: tf.Tensor(0.14653078, shape=(), dtype=float32)\n",
            "batch 316 accuracy: tf.Tensor(0.14664435, shape=(), dtype=float32)\n",
            "batch 317 accuracy: tf.Tensor(0.14663905, shape=(), dtype=float32)\n",
            "batch 318 accuracy: tf.Tensor(0.14670207, shape=(), dtype=float32)\n",
            "batch 319 accuracy: tf.Tensor(0.14678459, shape=(), dtype=float32)\n",
            "batch 320 accuracy: tf.Tensor(0.14682281, shape=(), dtype=float32)\n",
            "batch 321 accuracy: tf.Tensor(0.14679766, shape=(), dtype=float32)\n",
            "batch 322 accuracy: tf.Tensor(0.14677252, shape=(), dtype=float32)\n",
            "batch 323 accuracy: tf.Tensor(0.14663523, shape=(), dtype=float32)\n",
            "batch 324 accuracy: tf.Tensor(0.14672652, shape=(), dtype=float32)\n",
            "batch 325 accuracy: tf.Tensor(0.1467191, shape=(), dtype=float32)\n",
            "batch 326 accuracy: tf.Tensor(0.14676654, shape=(), dtype=float32)\n",
            "batch 327 accuracy: tf.Tensor(0.14680444, shape=(), dtype=float32)\n",
            "batch 328 accuracy: tf.Tensor(0.14679639, shape=(), dtype=float32)\n",
            "batch 329 accuracy: tf.Tensor(0.1466035, shape=(), dtype=float32)\n",
            "batch 330 accuracy: tf.Tensor(0.1466121, shape=(), dtype=float32)\n",
            "batch 331 accuracy: tf.Tensor(0.14688814, shape=(), dtype=float32)\n",
            "batch 332 accuracy: tf.Tensor(0.14704897, shape=(), dtype=float32)\n",
            "batch 333 accuracy: tf.Tensor(0.14710927, shape=(), dtype=float32)\n",
            "batch 334 accuracy: tf.Tensor(0.1470957, shape=(), dtype=float32)\n",
            "batch 335 accuracy: tf.Tensor(0.14723241, shape=(), dtype=float32)\n",
            "batch 336 accuracy: tf.Tensor(0.14711578, shape=(), dtype=float32)\n",
            "batch 337 accuracy: tf.Tensor(0.14713585, shape=(), dtype=float32)\n",
            "batch 338 accuracy: tf.Tensor(0.14720382, shape=(), dtype=float32)\n",
            "batch 339 accuracy: tf.Tensor(0.14735168, shape=(), dtype=float32)\n",
            "batch 340 accuracy: tf.Tensor(0.1470884, shape=(), dtype=float32)\n",
            "batch 341 accuracy: tf.Tensor(0.14697342, shape=(), dtype=float32)\n",
            "batch 342 accuracy: tf.Tensor(0.14691553, shape=(), dtype=float32)\n",
            "batch 343 accuracy: tf.Tensor(0.14682475, shape=(), dtype=float32)\n",
            "batch 344 accuracy: tf.Tensor(0.14700761, shape=(), dtype=float32)\n",
            "batch 345 accuracy: tf.Tensor(0.14710514, shape=(), dtype=float32)\n",
            "batch 346 accuracy: tf.Tensor(0.14707659, shape=(), dtype=float32)\n",
            "batch 347 accuracy: tf.Tensor(0.14698033, shape=(), dtype=float32)\n",
            "batch 348 accuracy: tf.Tensor(0.14704706, shape=(), dtype=float32)\n",
            "batch 349 accuracy: tf.Tensor(0.1468735, shape=(), dtype=float32)\n",
            "batch 350 accuracy: tf.Tensor(0.14700389, shape=(), dtype=float32)\n",
            "batch 351 accuracy: tf.Tensor(0.14691243, shape=(), dtype=float32)\n",
            "batch 352 accuracy: tf.Tensor(0.14694354, shape=(), dtype=float32)\n",
            "batch 353 accuracy: tf.Tensor(0.14685948, shape=(), dtype=float32)\n",
            "batch 354 accuracy: tf.Tensor(0.14688654, shape=(), dtype=float32)\n",
            "batch 355 accuracy: tf.Tensor(0.14706978, shape=(), dtype=float32)\n",
            "batch 356 accuracy: tf.Tensor(0.14718704, shape=(), dtype=float32)\n",
            "batch 357 accuracy: tf.Tensor(0.14719644, shape=(), dtype=float32)\n",
            "batch 358 accuracy: tf.Tensor(0.14711538, shape=(), dtype=float32)\n",
            "batch 359 accuracy: tf.Tensor(0.1471968, shape=(), dtype=float32)\n",
            "batch 360 accuracy: tf.Tensor(0.14700596, shape=(), dtype=float32)\n",
            "batch 361 accuracy: tf.Tensor(0.14701064, shape=(), dtype=float32)\n",
            "batch 362 accuracy: tf.Tensor(0.14713693, shape=(), dtype=float32)\n",
            "batch 363 accuracy: tf.Tensor(0.14706843, shape=(), dtype=float32)\n",
            "batch 364 accuracy: tf.Tensor(0.14715068, shape=(), dtype=float32)\n",
            "batch 365 accuracy: tf.Tensor(0.14725962, shape=(), dtype=float32)\n",
            "batch 366 accuracy: tf.Tensor(0.14738962, shape=(), dtype=float32)\n",
            "batch 367 accuracy: tf.Tensor(0.14742148, shape=(), dtype=float32)\n",
            "batch 368 accuracy: tf.Tensor(0.14743711, shape=(), dtype=float32)\n",
            "batch 369 accuracy: tf.Tensor(0.14729811, shape=(), dtype=float32)\n",
            "batch 370 accuracy: tf.Tensor(0.14718762, shape=(), dtype=float32)\n",
            "batch 371 accuracy: tf.Tensor(0.14692916, shape=(), dtype=float32)\n",
            "batch 372 accuracy: tf.Tensor(0.14691193, shape=(), dtype=float32)\n",
            "batch 373 accuracy: tf.Tensor(0.14686964, shape=(), dtype=float32)\n",
            "batch 374 accuracy: tf.Tensor(0.14663015, shape=(), dtype=float32)\n",
            "batch 375 accuracy: tf.Tensor(0.14677617, shape=(), dtype=float32)\n",
            "batch 376 accuracy: tf.Tensor(0.14695609, shape=(), dtype=float32)\n",
            "batch 377 accuracy: tf.Tensor(0.14700353, shape=(), dtype=float32)\n",
            "batch 378 accuracy: tf.Tensor(0.14700854, shape=(), dtype=float32)\n",
            "batch 379 accuracy: tf.Tensor(0.14707826, shape=(), dtype=float32)\n",
            "batch 380 accuracy: tf.Tensor(0.14713094, shape=(), dtype=float32)\n",
            "batch 381 accuracy: tf.Tensor(0.14695305, shape=(), dtype=float32)\n",
            "batch 382 accuracy: tf.Tensor(0.14684404, shape=(), dtype=float32)\n",
            "batch 383 accuracy: tf.Tensor(0.14693603, shape=(), dtype=float32)\n",
            "batch 384 accuracy: tf.Tensor(0.14694014, shape=(), dtype=float32)\n",
            "batch 385 accuracy: tf.Tensor(0.14695898, shape=(), dtype=float32)\n",
            "batch 386 accuracy: tf.Tensor(0.14696068, shape=(), dtype=float32)\n",
            "batch 387 accuracy: tf.Tensor(0.14711705, shape=(), dtype=float32)\n",
            "batch 388 accuracy: tf.Tensor(0.14717133, shape=(), dtype=float32)\n",
            "batch 389 accuracy: tf.Tensor(0.14727217, shape=(), dtype=float32)\n",
            "batch 390 accuracy: tf.Tensor(0.14720535, shape=(), dtype=float32)\n",
            "batch 391 accuracy: tf.Tensor(0.14711066, shape=(), dtype=float32)\n",
            "batch 392 accuracy: tf.Tensor(0.14715922, shape=(), dtype=float32)\n",
            "batch 393 accuracy: tf.Tensor(0.14725967, shape=(), dtype=float32)\n",
            "batch 394 accuracy: tf.Tensor(0.1473306, shape=(), dtype=float32)\n",
            "batch 395 accuracy: tf.Tensor(0.14720987, shape=(), dtype=float32)\n",
            "batch 396 accuracy: tf.Tensor(0.14713964, shape=(), dtype=float32)\n",
            "batch 397 accuracy: tf.Tensor(0.14727592, shape=(), dtype=float32)\n",
            "batch 398 accuracy: tf.Tensor(0.14716585, shape=(), dtype=float32)\n",
            "batch 399 accuracy: tf.Tensor(0.14708394, shape=(), dtype=float32)\n",
            "batch 400 accuracy: tf.Tensor(0.1471212, shape=(), dtype=float32)\n",
            "batch 401 accuracy: tf.Tensor(0.14686418, shape=(), dtype=float32)\n",
            "batch 402 accuracy: tf.Tensor(0.14701204, shape=(), dtype=float32)\n",
            "batch 403 accuracy: tf.Tensor(0.14699034, shape=(), dtype=float32)\n",
            "batch 404 accuracy: tf.Tensor(0.14692514, shape=(), dtype=float32)\n",
            "batch 405 accuracy: tf.Tensor(0.147127, shape=(), dtype=float32)\n",
            "batch 406 accuracy: tf.Tensor(0.14720908, shape=(), dtype=float32)\n",
            "batch 407 accuracy: tf.Tensor(0.14724961, shape=(), dtype=float32)\n",
            "batch 408 accuracy: tf.Tensor(0.14734703, shape=(), dtype=float32)\n",
            "batch 409 accuracy: tf.Tensor(0.14746626, shape=(), dtype=float32)\n",
            "batch 410 accuracy: tf.Tensor(0.14750238, shape=(), dtype=float32)\n",
            "batch 411 accuracy: tf.Tensor(0.1474703, shape=(), dtype=float32)\n",
            "batch 412 accuracy: tf.Tensor(0.14768876, shape=(), dtype=float32)\n",
            "batch 413 accuracy: tf.Tensor(0.14786708, shape=(), dtype=float32)\n",
            "batch 414 accuracy: tf.Tensor(0.1478162, shape=(), dtype=float32)\n",
            "batch 415 accuracy: tf.Tensor(0.14805311, shape=(), dtype=float32)\n",
            "batch 416 accuracy: tf.Tensor(0.14794463, shape=(), dtype=float32)\n",
            "batch 417 accuracy: tf.Tensor(0.14801686, shape=(), dtype=float32)\n",
            "batch 418 accuracy: tf.Tensor(0.14779608, shape=(), dtype=float32)\n",
            "batch 419 accuracy: tf.Tensor(0.14781477, shape=(), dtype=float32)\n",
            "batch 420 accuracy: tf.Tensor(0.14793365, shape=(), dtype=float32)\n",
            "batch 421 accuracy: tf.Tensor(0.14794299, shape=(), dtype=float32)\n",
            "batch 422 accuracy: tf.Tensor(0.1479703, shape=(), dtype=float32)\n",
            "batch 423 accuracy: tf.Tensor(0.14786565, shape=(), dtype=float32)\n",
            "batch 424 accuracy: tf.Tensor(0.1478288, shape=(), dtype=float32)\n",
            "batch 425 accuracy: tf.Tensor(0.14785916, shape=(), dtype=float32)\n",
            "batch 426 accuracy: tf.Tensor(0.14784384, shape=(), dtype=float32)\n",
            "batch 427 accuracy: tf.Tensor(0.14783011, shape=(), dtype=float32)\n",
            "batch 428 accuracy: tf.Tensor(0.14781727, shape=(), dtype=float32)\n",
            "batch 429 accuracy: tf.Tensor(0.14774565, shape=(), dtype=float32)\n",
            "batch 430 accuracy: tf.Tensor(0.14785336, shape=(), dtype=float32)\n",
            "batch 431 accuracy: tf.Tensor(0.14787203, shape=(), dtype=float32)\n",
            "batch 432 accuracy: tf.Tensor(0.14795476, shape=(), dtype=float32)\n",
            "batch 433 accuracy: tf.Tensor(0.1480459, shape=(), dtype=float32)\n",
            "batch 434 accuracy: tf.Tensor(0.14809783, shape=(), dtype=float32)\n",
            "batch 435 accuracy: tf.Tensor(0.14815317, shape=(), dtype=float32)\n",
            "batch 436 accuracy: tf.Tensor(0.14818497, shape=(), dtype=float32)\n",
            "batch 437 accuracy: tf.Tensor(0.14825286, shape=(), dtype=float32)\n",
            "batch 438 accuracy: tf.Tensor(0.14823185, shape=(), dtype=float32)\n",
            "batch 439 accuracy: tf.Tensor(0.148106, shape=(), dtype=float32)\n",
            "batch 440 accuracy: tf.Tensor(0.14801344, shape=(), dtype=float32)\n",
            "batch 441 accuracy: tf.Tensor(0.14806712, shape=(), dtype=float32)\n",
            "batch 442 accuracy: tf.Tensor(0.14812806, shape=(), dtype=float32)\n",
            "batch 443 accuracy: tf.Tensor(0.14810252, shape=(), dtype=float32)\n",
            "batch 444 accuracy: tf.Tensor(0.14812759, shape=(), dtype=float32)\n",
            "batch 445 accuracy: tf.Tensor(0.14826235, shape=(), dtype=float32)\n",
            "batch 446 accuracy: tf.Tensor(0.14819434, shape=(), dtype=float32)\n",
            "batch 447 accuracy: tf.Tensor(0.14823663, shape=(), dtype=float32)\n",
            "batch 448 accuracy: tf.Tensor(0.14814067, shape=(), dtype=float32)\n",
            "batch 449 accuracy: tf.Tensor(0.14813553, shape=(), dtype=float32)\n",
            "batch 450 accuracy: tf.Tensor(0.14814958, shape=(), dtype=float32)\n",
            "batch 451 accuracy: tf.Tensor(0.14814216, shape=(), dtype=float32)\n",
            "batch 452 accuracy: tf.Tensor(0.14819342, shape=(), dtype=float32)\n",
            "batch 453 accuracy: tf.Tensor(0.1482995, shape=(), dtype=float32)\n",
            "batch 454 accuracy: tf.Tensor(0.1483667, shape=(), dtype=float32)\n",
            "batch 455 accuracy: tf.Tensor(0.14862679, shape=(), dtype=float32)\n",
            "batch 456 accuracy: tf.Tensor(0.14854355, shape=(), dtype=float32)\n",
            "batch 457 accuracy: tf.Tensor(0.14849824, shape=(), dtype=float32)\n",
            "batch 458 accuracy: tf.Tensor(0.14853467, shape=(), dtype=float32)\n",
            "batch 459 accuracy: tf.Tensor(0.14857505, shape=(), dtype=float32)\n",
            "batch 460 accuracy: tf.Tensor(0.14862621, shape=(), dtype=float32)\n",
            "batch 461 accuracy: tf.Tensor(0.14851984, shape=(), dtype=float32)\n",
            "batch 462 accuracy: tf.Tensor(0.14856237, shape=(), dtype=float32)\n",
            "batch 463 accuracy: tf.Tensor(0.1486136, shape=(), dtype=float32)\n",
            "batch 464 accuracy: tf.Tensor(0.14860171, shape=(), dtype=float32)\n",
            "batch 465 accuracy: tf.Tensor(0.14852713, shape=(), dtype=float32)\n",
            "batch 466 accuracy: tf.Tensor(0.14847799, shape=(), dtype=float32)\n",
            "batch 467 accuracy: tf.Tensor(0.1485295, shape=(), dtype=float32)\n",
            "batch 468 accuracy: tf.Tensor(0.14858952, shape=(), dtype=float32)\n",
            "batch 469 accuracy: tf.Tensor(0.14869426, shape=(), dtype=float32)\n",
            "batch 470 accuracy: tf.Tensor(0.14898363, shape=(), dtype=float32)\n",
            "batch 471 accuracy: tf.Tensor(0.14892331, shape=(), dtype=float32)\n",
            "batch 472 accuracy: tf.Tensor(0.14886805, shape=(), dtype=float32)\n",
            "batch 473 accuracy: tf.Tensor(0.14886798, shape=(), dtype=float32)\n",
            "batch 474 accuracy: tf.Tensor(0.14874911, shape=(), dtype=float32)\n",
            "batch 475 accuracy: tf.Tensor(0.14842519, shape=(), dtype=float32)\n",
            "batch 476 accuracy: tf.Tensor(0.14839883, shape=(), dtype=float32)\n",
            "batch 477 accuracy: tf.Tensor(0.1483562, shape=(), dtype=float32)\n",
            "batch 478 accuracy: tf.Tensor(0.14826222, shape=(), dtype=float32)\n",
            "batch 479 accuracy: tf.Tensor(0.14825363, shape=(), dtype=float32)\n",
            "batch 480 accuracy: tf.Tensor(0.14814441, shape=(), dtype=float32)\n",
            "batch 481 accuracy: tf.Tensor(0.14815935, shape=(), dtype=float32)\n",
            "batch 482 accuracy: tf.Tensor(0.14812712, shape=(), dtype=float32)\n",
            "batch 483 accuracy: tf.Tensor(0.14819226, shape=(), dtype=float32)\n",
            "batch 484 accuracy: tf.Tensor(0.1482237, shape=(), dtype=float32)\n",
            "batch 485 accuracy: tf.Tensor(0.14805818, shape=(), dtype=float32)\n",
            "batch 486 accuracy: tf.Tensor(0.1481716, shape=(), dtype=float32)\n",
            "batch 487 accuracy: tf.Tensor(0.14817025, shape=(), dtype=float32)\n",
            "batch 488 accuracy: tf.Tensor(0.14814684, shape=(), dtype=float32)\n",
            "batch 489 accuracy: tf.Tensor(0.14807639, shape=(), dtype=float32)\n",
            "batch 490 accuracy: tf.Tensor(0.14797099, shape=(), dtype=float32)\n",
            "batch 491 accuracy: tf.Tensor(0.14800446, shape=(), dtype=float32)\n",
            "batch 492 accuracy: tf.Tensor(0.14799763, shape=(), dtype=float32)\n",
            "batch 493 accuracy: tf.Tensor(0.14810187, shape=(), dtype=float32)\n",
            "batch 494 accuracy: tf.Tensor(0.14817281, shape=(), dtype=float32)\n",
            "batch 495 accuracy: tf.Tensor(0.14824297, shape=(), dtype=float32)\n",
            "batch 496 accuracy: tf.Tensor(0.148262, shape=(), dtype=float32)\n",
            "batch 497 accuracy: tf.Tensor(0.1482727, shape=(), dtype=float32)\n",
            "batch 498 accuracy: tf.Tensor(0.14825113, shape=(), dtype=float32)\n",
            "batch 499 accuracy: tf.Tensor(0.1482011, shape=(), dtype=float32)\n",
            "batch 500 accuracy: tf.Tensor(0.14828384, shape=(), dtype=float32)\n",
            "batch 501 accuracy: tf.Tensor(0.14830649, shape=(), dtype=float32)\n",
            "batch 502 accuracy: tf.Tensor(0.14824794, shape=(), dtype=float32)\n",
            "batch 503 accuracy: tf.Tensor(0.14830041, shape=(), dtype=float32)\n",
            "batch 504 accuracy: tf.Tensor(0.14825854, shape=(), dtype=float32)\n",
            "batch 505 accuracy: tf.Tensor(0.14823982, shape=(), dtype=float32)\n",
            "batch 506 accuracy: tf.Tensor(0.14836936, shape=(), dtype=float32)\n",
            "batch 507 accuracy: tf.Tensor(0.14847045, shape=(), dtype=float32)\n",
            "batch 508 accuracy: tf.Tensor(0.14830172, shape=(), dtype=float32)\n",
            "batch 509 accuracy: tf.Tensor(0.14833261, shape=(), dtype=float32)\n",
            "batch 510 accuracy: tf.Tensor(0.14829908, shape=(), dtype=float32)\n",
            "batch 511 accuracy: tf.Tensor(0.14833415, shape=(), dtype=float32)\n",
            "batch 512 accuracy: tf.Tensor(0.14832799, shape=(), dtype=float32)\n",
            "batch 513 accuracy: tf.Tensor(0.14851546, shape=(), dtype=float32)\n",
            "batch 514 accuracy: tf.Tensor(0.1484143, shape=(), dtype=float32)\n",
            "batch 515 accuracy: tf.Tensor(0.14838237, shape=(), dtype=float32)\n",
            "batch 516 accuracy: tf.Tensor(0.14842951, shape=(), dtype=float32)\n",
            "batch 517 accuracy: tf.Tensor(0.14830953, shape=(), dtype=float32)\n",
            "batch 518 accuracy: tf.Tensor(0.14828339, shape=(), dtype=float32)\n",
            "batch 519 accuracy: tf.Tensor(0.14830543, shape=(), dtype=float32)\n",
            "batch 520 accuracy: tf.Tensor(0.14816321, shape=(), dtype=float32)\n",
            "batch 521 accuracy: tf.Tensor(0.14817749, shape=(), dtype=float32)\n",
            "batch 522 accuracy: tf.Tensor(0.14791246, shape=(), dtype=float32)\n",
            "batch 523 accuracy: tf.Tensor(0.1477808, shape=(), dtype=float32)\n",
            "batch 524 accuracy: tf.Tensor(0.1478521, shape=(), dtype=float32)\n",
            "batch 525 accuracy: tf.Tensor(0.14784592, shape=(), dtype=float32)\n",
            "batch 526 accuracy: tf.Tensor(0.14783014, shape=(), dtype=float32)\n",
            "batch 527 accuracy: tf.Tensor(0.14781563, shape=(), dtype=float32)\n",
            "batch 528 accuracy: tf.Tensor(0.14785658, shape=(), dtype=float32)\n",
            "batch 529 accuracy: tf.Tensor(0.14789093, shape=(), dtype=float32)\n",
            "batch 530 accuracy: tf.Tensor(0.14784068, shape=(), dtype=float32)\n",
            "batch 531 accuracy: tf.Tensor(0.14785948, shape=(), dtype=float32)\n",
            "batch 532 accuracy: tf.Tensor(0.14787522, shape=(), dtype=float32)\n",
            "batch 533 accuracy: tf.Tensor(0.14784478, shape=(), dtype=float32)\n",
            "batch 534 accuracy: tf.Tensor(0.14795838, shape=(), dtype=float32)\n",
            "batch 535 accuracy: tf.Tensor(0.14781782, shape=(), dtype=float32)\n",
            "batch 536 accuracy: tf.Tensor(0.14782822, shape=(), dtype=float32)\n",
            "batch 537 accuracy: tf.Tensor(0.14794932, shape=(), dtype=float32)\n",
            "batch 538 accuracy: tf.Tensor(0.14799176, shape=(), dtype=float32)\n",
            "batch 539 accuracy: tf.Tensor(0.14802411, shape=(), dtype=float32)\n",
            "batch 540 accuracy: tf.Tensor(0.14794125, shape=(), dtype=float32)\n",
            "batch 541 accuracy: tf.Tensor(0.14800979, shape=(), dtype=float32)\n",
            "batch 542 accuracy: tf.Tensor(0.14801234, shape=(), dtype=float32)\n",
            "batch 543 accuracy: tf.Tensor(0.14799453, shape=(), dtype=float32)\n",
            "batch 544 accuracy: tf.Tensor(0.14797662, shape=(), dtype=float32)\n",
            "batch 545 accuracy: tf.Tensor(0.14800417, shape=(), dtype=float32)\n",
            "batch 546 accuracy: tf.Tensor(0.14815263, shape=(), dtype=float32)\n",
            "batch 547 accuracy: tf.Tensor(0.14825359, shape=(), dtype=float32)\n",
            "batch 548 accuracy: tf.Tensor(0.14823677, shape=(), dtype=float32)\n",
            "batch 549 accuracy: tf.Tensor(0.14821519, shape=(), dtype=float32)\n",
            "batch 550 accuracy: tf.Tensor(0.14793012, shape=(), dtype=float32)\n",
            "batch 551 accuracy: tf.Tensor(0.14787836, shape=(), dtype=float32)\n",
            "batch 552 accuracy: tf.Tensor(0.14787766, shape=(), dtype=float32)\n",
            "batch 553 accuracy: tf.Tensor(0.14784035, shape=(), dtype=float32)\n",
            "batch 554 accuracy: tf.Tensor(0.14791101, shape=(), dtype=float32)\n",
            "batch 555 accuracy: tf.Tensor(0.14790383, shape=(), dtype=float32)\n",
            "batch 556 accuracy: tf.Tensor(0.14780228, shape=(), dtype=float32)\n",
            "batch 557 accuracy: tf.Tensor(0.14776075, shape=(), dtype=float32)\n",
            "batch 558 accuracy: tf.Tensor(0.14782983, shape=(), dtype=float32)\n",
            "batch 559 accuracy: tf.Tensor(0.14782344, shape=(), dtype=float32)\n",
            "batch 560 accuracy: tf.Tensor(0.14794485, shape=(), dtype=float32)\n",
            "batch 561 accuracy: tf.Tensor(0.14785473, shape=(), dtype=float32)\n",
            "batch 562 accuracy: tf.Tensor(0.14784327, shape=(), dtype=float32)\n",
            "batch 563 accuracy: tf.Tensor(0.14775987, shape=(), dtype=float32)\n",
            "batch 564 accuracy: tf.Tensor(0.14778058, shape=(), dtype=float32)\n",
            "batch 565 accuracy: tf.Tensor(0.14764333, shape=(), dtype=float32)\n",
            "batch 566 accuracy: tf.Tensor(0.14767307, shape=(), dtype=float32)\n",
            "batch 567 accuracy: tf.Tensor(0.14763243, shape=(), dtype=float32)\n",
            "batch 568 accuracy: tf.Tensor(0.1476225, shape=(), dtype=float32)\n",
            "batch 569 accuracy: tf.Tensor(0.14764328, shape=(), dtype=float32)\n",
            "batch 570 accuracy: tf.Tensor(0.14776666, shape=(), dtype=float32)\n",
            "batch 571 accuracy: tf.Tensor(0.14773558, shape=(), dtype=float32)\n",
            "batch 572 accuracy: tf.Tensor(0.14763397, shape=(), dtype=float32)\n",
            "batch 573 accuracy: tf.Tensor(0.14760277, shape=(), dtype=float32)\n",
            "batch 574 accuracy: tf.Tensor(0.14762989, shape=(), dtype=float32)\n",
            "batch 575 accuracy: tf.Tensor(0.14765753, shape=(), dtype=float32)\n",
            "batch 576 accuracy: tf.Tensor(0.14775853, shape=(), dtype=float32)\n",
            "batch 577 accuracy: tf.Tensor(0.1476293, shape=(), dtype=float32)\n",
            "batch 578 accuracy: tf.Tensor(0.14763217, shape=(), dtype=float32)\n",
            "batch 579 accuracy: tf.Tensor(0.14738421, shape=(), dtype=float32)\n",
            "batch 580 accuracy: tf.Tensor(0.14746861, shape=(), dtype=float32)\n",
            "batch 581 accuracy: tf.Tensor(0.14760822, shape=(), dtype=float32)\n",
            "batch 582 accuracy: tf.Tensor(0.14756836, shape=(), dtype=float32)\n",
            "batch 583 accuracy: tf.Tensor(0.14768289, shape=(), dtype=float32)\n",
            "batch 584 accuracy: tf.Tensor(0.14767757, shape=(), dtype=float32)\n",
            "batch 585 accuracy: tf.Tensor(0.14764695, shape=(), dtype=float32)\n",
            "batch 586 accuracy: tf.Tensor(0.14763953, shape=(), dtype=float32)\n",
            "batch 587 accuracy: tf.Tensor(0.14746343, shape=(), dtype=float32)\n",
            "batch 588 accuracy: tf.Tensor(0.14740027, shape=(), dtype=float32)\n",
            "batch 589 accuracy: tf.Tensor(0.14740288, shape=(), dtype=float32)\n",
            "batch 590 accuracy: tf.Tensor(0.14741662, shape=(), dtype=float32)\n",
            "batch 591 accuracy: tf.Tensor(0.14738236, shape=(), dtype=float32)\n",
            "batch 592 accuracy: tf.Tensor(0.14739925, shape=(), dtype=float32)\n",
            "batch 593 accuracy: tf.Tensor(0.14741266, shape=(), dtype=float32)\n",
            "batch 594 accuracy: tf.Tensor(0.14749801, shape=(), dtype=float32)\n",
            "batch 595 accuracy: tf.Tensor(0.147467, shape=(), dtype=float32)\n",
            "batch 596 accuracy: tf.Tensor(0.14761202, shape=(), dtype=float32)\n",
            "batch 597 accuracy: tf.Tensor(0.14751092, shape=(), dtype=float32)\n",
            "batch 598 accuracy: tf.Tensor(0.14759141, shape=(), dtype=float32)\n",
            "batch 599 accuracy: tf.Tensor(0.14751549, shape=(), dtype=float32)\n",
            "batch 600 accuracy: tf.Tensor(0.14743634, shape=(), dtype=float32)\n",
            "batch 601 accuracy: tf.Tensor(0.14751786, shape=(), dtype=float32)\n",
            "batch 602 accuracy: tf.Tensor(0.14756465, shape=(), dtype=float32)\n",
            "batch 603 accuracy: tf.Tensor(0.14751995, shape=(), dtype=float32)\n",
            "batch 604 accuracy: tf.Tensor(0.1475438, shape=(), dtype=float32)\n",
            "batch 605 accuracy: tf.Tensor(0.14752227, shape=(), dtype=float32)\n",
            "batch 606 accuracy: tf.Tensor(0.14755669, shape=(), dtype=float32)\n",
            "batch 607 accuracy: tf.Tensor(0.14756478, shape=(), dtype=float32)\n",
            "batch 608 accuracy: tf.Tensor(0.14748704, shape=(), dtype=float32)\n",
            "batch 609 accuracy: tf.Tensor(0.1475236, shape=(), dtype=float32)\n",
            "batch 610 accuracy: tf.Tensor(0.14757746, shape=(), dtype=float32)\n",
            "batch 611 accuracy: tf.Tensor(0.14758444, shape=(), dtype=float32)\n",
            "batch 612 accuracy: tf.Tensor(0.14748883, shape=(), dtype=float32)\n",
            "batch 613 accuracy: tf.Tensor(0.14749831, shape=(), dtype=float32)\n",
            "batch 614 accuracy: tf.Tensor(0.14760087, shape=(), dtype=float32)\n",
            "batch 615 accuracy: tf.Tensor(0.1476276, shape=(), dtype=float32)\n",
            "batch 616 accuracy: tf.Tensor(0.14755985, shape=(), dtype=float32)\n",
            "batch 617 accuracy: tf.Tensor(0.14754374, shape=(), dtype=float32)\n",
            "batch 618 accuracy: tf.Tensor(0.14752474, shape=(), dtype=float32)\n",
            "batch 619 accuracy: tf.Tensor(0.14752036, shape=(), dtype=float32)\n",
            "batch 620 accuracy: tf.Tensor(0.14752132, shape=(), dtype=float32)\n",
            "batch 621 accuracy: tf.Tensor(0.14754793, shape=(), dtype=float32)\n",
            "batch 622 accuracy: tf.Tensor(0.14760035, shape=(), dtype=float32)\n",
            "batch 623 accuracy: tf.Tensor(0.14768031, shape=(), dtype=float32)\n",
            "batch 624 accuracy: tf.Tensor(0.14759564, shape=(), dtype=float32)\n",
            "batch 625 accuracy: tf.Tensor(0.14752237, shape=(), dtype=float32)\n",
            "batch 626 accuracy: tf.Tensor(0.14751704, shape=(), dtype=float32)\n",
            "batch 627 accuracy: tf.Tensor(0.14757866, shape=(), dtype=float32)\n",
            "batch 628 accuracy: tf.Tensor(0.14758737, shape=(), dtype=float32)\n",
            "batch 629 accuracy: tf.Tensor(0.14755344, shape=(), dtype=float32)\n",
            "batch 630 accuracy: tf.Tensor(0.14759314, shape=(), dtype=float32)\n",
            "batch 631 accuracy: tf.Tensor(0.14756432, shape=(), dtype=float32)\n",
            "batch 632 accuracy: tf.Tensor(0.14765938, shape=(), dtype=float32)\n",
            "batch 633 accuracy: tf.Tensor(0.14772229, shape=(), dtype=float32)\n",
            "batch 634 accuracy: tf.Tensor(0.1477452, shape=(), dtype=float32)\n",
            "batch 635 accuracy: tf.Tensor(0.14778051, shape=(), dtype=float32)\n",
            "batch 636 accuracy: tf.Tensor(0.14776598, shape=(), dtype=float32)\n",
            "batch 637 accuracy: tf.Tensor(0.14775355, shape=(), dtype=float32)\n",
            "batch 638 accuracy: tf.Tensor(0.1478337, shape=(), dtype=float32)\n",
            "batch 639 accuracy: tf.Tensor(0.14781772, shape=(), dtype=float32)\n",
            "batch 640 accuracy: tf.Tensor(0.14786598, shape=(), dtype=float32)\n",
            "batch 641 accuracy: tf.Tensor(0.14795354, shape=(), dtype=float32)\n",
            "batch 642 accuracy: tf.Tensor(0.1479783, shape=(), dtype=float32)\n",
            "batch 643 accuracy: tf.Tensor(0.14798191, shape=(), dtype=float32)\n",
            "batch 644 accuracy: tf.Tensor(0.14800431, shape=(), dtype=float32)\n",
            "batch 645 accuracy: tf.Tensor(0.14787321, shape=(), dtype=float32)\n",
            "batch 646 accuracy: tf.Tensor(0.14783871, shape=(), dtype=float32)\n",
            "batch 647 accuracy: tf.Tensor(0.1478244, shape=(), dtype=float32)\n",
            "batch 648 accuracy: tf.Tensor(0.14779018, shape=(), dtype=float32)\n",
            "batch 649 accuracy: tf.Tensor(0.14772192, shape=(), dtype=float32)\n",
            "batch 650 accuracy: tf.Tensor(0.1477122, shape=(), dtype=float32)\n",
            "batch 651 accuracy: tf.Tensor(0.14760655, shape=(), dtype=float32)\n",
            "batch 652 accuracy: tf.Tensor(0.14752832, shape=(), dtype=float32)\n",
            "batch 653 accuracy: tf.Tensor(0.14744706, shape=(), dtype=float32)\n",
            "batch 654 accuracy: tf.Tensor(0.14743249, shape=(), dtype=float32)\n",
            "batch 655 accuracy: tf.Tensor(0.14722258, shape=(), dtype=float32)\n",
            "batch 656 accuracy: tf.Tensor(0.14723067, shape=(), dtype=float32)\n",
            "batch 657 accuracy: tf.Tensor(0.14726526, shape=(), dtype=float32)\n",
            "batch 658 accuracy: tf.Tensor(0.14727964, shape=(), dtype=float32)\n",
            "batch 659 accuracy: tf.Tensor(0.147385, shape=(), dtype=float32)\n",
            "batch 660 accuracy: tf.Tensor(0.14737251, shape=(), dtype=float32)\n",
            "batch 661 accuracy: tf.Tensor(0.14737411, shape=(), dtype=float32)\n",
            "batch 662 accuracy: tf.Tensor(0.14744477, shape=(), dtype=float32)\n",
            "batch 663 accuracy: tf.Tensor(0.14736776, shape=(), dtype=float32)\n",
            "batch 664 accuracy: tf.Tensor(0.14736061, shape=(), dtype=float32)\n",
            "batch 665 accuracy: tf.Tensor(0.1474616, shape=(), dtype=float32)\n",
            "batch 666 accuracy: tf.Tensor(0.14741358, shape=(), dtype=float32)\n",
            "batch 667 accuracy: tf.Tensor(0.14743483, shape=(), dtype=float32)\n",
            "batch 668 accuracy: tf.Tensor(0.1474403, shape=(), dtype=float32)\n",
            "batch 669 accuracy: tf.Tensor(0.14743124, shape=(), dtype=float32)\n",
            "batch 670 accuracy: tf.Tensor(0.14736122, shape=(), dtype=float32)\n",
            "batch 671 accuracy: tf.Tensor(0.14739424, shape=(), dtype=float32)\n",
            "batch 672 accuracy: tf.Tensor(0.14738806, shape=(), dtype=float32)\n",
            "batch 673 accuracy: tf.Tensor(0.14748885, shape=(), dtype=float32)\n",
            "batch 674 accuracy: tf.Tensor(0.14755146, shape=(), dtype=float32)\n",
            "batch 675 accuracy: tf.Tensor(0.14757088, shape=(), dtype=float32)\n",
            "batch 676 accuracy: tf.Tensor(0.14757666, shape=(), dtype=float32)\n",
            "batch 677 accuracy: tf.Tensor(0.14757451, shape=(), dtype=float32)\n",
            "batch 678 accuracy: tf.Tensor(0.14746022, shape=(), dtype=float32)\n",
            "batch 679 accuracy: tf.Tensor(0.14747255, shape=(), dtype=float32)\n",
            "batch 680 accuracy: tf.Tensor(0.14754628, shape=(), dtype=float32)\n",
            "batch 681 accuracy: tf.Tensor(0.14748877, shape=(), dtype=float32)\n",
            "batch 682 accuracy: tf.Tensor(0.14749011, shape=(), dtype=float32)\n",
            "batch 683 accuracy: tf.Tensor(0.14753155, shape=(), dtype=float32)\n",
            "batch 684 accuracy: tf.Tensor(0.14757156, shape=(), dtype=float32)\n",
            "batch 685 accuracy: tf.Tensor(0.14758694, shape=(), dtype=float32)\n",
            "batch 686 accuracy: tf.Tensor(0.14753316, shape=(), dtype=float32)\n",
            "batch 687 accuracy: tf.Tensor(0.1474176, shape=(), dtype=float32)\n",
            "batch 688 accuracy: tf.Tensor(0.14749242, shape=(), dtype=float32)\n",
            "batch 689 accuracy: tf.Tensor(0.14755738, shape=(), dtype=float32)\n",
            "batch 690 accuracy: tf.Tensor(0.14755397, shape=(), dtype=float32)\n",
            "batch 691 accuracy: tf.Tensor(0.14755015, shape=(), dtype=float32)\n",
            "batch 692 accuracy: tf.Tensor(0.14756043, shape=(), dtype=float32)\n",
            "batch 693 accuracy: tf.Tensor(0.14747581, shape=(), dtype=float32)\n",
            "batch 694 accuracy: tf.Tensor(0.14743616, shape=(), dtype=float32)\n",
            "batch 695 accuracy: tf.Tensor(0.14740254, shape=(), dtype=float32)\n",
            "batch 696 accuracy: tf.Tensor(0.14730161, shape=(), dtype=float32)\n",
            "batch 697 accuracy: tf.Tensor(0.14732482, shape=(), dtype=float32)\n",
            "batch 698 accuracy: tf.Tensor(0.14732963, shape=(), dtype=float32)\n",
            "batch 699 accuracy: tf.Tensor(0.14734793, shape=(), dtype=float32)\n",
            "batch 700 accuracy: tf.Tensor(0.14733404, shape=(), dtype=float32)\n",
            "batch 701 accuracy: tf.Tensor(0.14723226, shape=(), dtype=float32)\n",
            "batch 702 accuracy: tf.Tensor(0.14726156, shape=(), dtype=float32)\n",
            "batch 703 accuracy: tf.Tensor(0.14724685, shape=(), dtype=float32)\n",
            "batch 704 accuracy: tf.Tensor(0.14719534, shape=(), dtype=float32)\n",
            "batch 705 accuracy: tf.Tensor(0.1472152, shape=(), dtype=float32)\n",
            "batch 706 accuracy: tf.Tensor(0.14716281, shape=(), dtype=float32)\n",
            "batch 707 accuracy: tf.Tensor(0.14717488, shape=(), dtype=float32)\n",
            "batch 708 accuracy: tf.Tensor(0.1472054, shape=(), dtype=float32)\n",
            "batch 709 accuracy: tf.Tensor(0.14717306, shape=(), dtype=float32)\n",
            "batch 710 accuracy: tf.Tensor(0.14717671, shape=(), dtype=float32)\n",
            "batch 711 accuracy: tf.Tensor(0.14718287, shape=(), dtype=float32)\n",
            "batch 712 accuracy: tf.Tensor(0.14705825, shape=(), dtype=float32)\n",
            "batch 713 accuracy: tf.Tensor(0.14712015, shape=(), dtype=float32)\n",
            "batch 714 accuracy: tf.Tensor(0.14716643, shape=(), dtype=float32)\n",
            "batch 715 accuracy: tf.Tensor(0.14726327, shape=(), dtype=float32)\n",
            "batch 716 accuracy: tf.Tensor(0.14726193, shape=(), dtype=float32)\n",
            "batch 717 accuracy: tf.Tensor(0.1472608, shape=(), dtype=float32)\n",
            "batch 718 accuracy: tf.Tensor(0.14727435, shape=(), dtype=float32)\n",
            "batch 719 accuracy: tf.Tensor(0.1473057, shape=(), dtype=float32)\n",
            "batch 720 accuracy: tf.Tensor(0.14726497, shape=(), dtype=float32)\n",
            "batch 721 accuracy: tf.Tensor(0.1472337, shape=(), dtype=float32)\n",
            "batch 722 accuracy: tf.Tensor(0.14724311, shape=(), dtype=float32)\n",
            "batch 723 accuracy: tf.Tensor(0.14715762, shape=(), dtype=float32)\n",
            "batch 724 accuracy: tf.Tensor(0.1471173, shape=(), dtype=float32)\n",
            "batch 725 accuracy: tf.Tensor(0.14709577, shape=(), dtype=float32)\n",
            "batch 726 accuracy: tf.Tensor(0.14714584, shape=(), dtype=float32)\n",
            "batch 727 accuracy: tf.Tensor(0.14719993, shape=(), dtype=float32)\n",
            "batch 728 accuracy: tf.Tensor(0.14724968, shape=(), dtype=float32)\n",
            "batch 729 accuracy: tf.Tensor(0.14724638, shape=(), dtype=float32)\n",
            "batch 730 accuracy: tf.Tensor(0.14718656, shape=(), dtype=float32)\n",
            "batch 731 accuracy: tf.Tensor(0.1471548, shape=(), dtype=float32)\n",
            "batch 732 accuracy: tf.Tensor(0.14715743, shape=(), dtype=float32)\n",
            "batch 733 accuracy: tf.Tensor(0.14709842, shape=(), dtype=float32)\n",
            "batch 734 accuracy: tf.Tensor(0.14712678, shape=(), dtype=float32)\n",
            "batch 735 accuracy: tf.Tensor(0.14721434, shape=(), dtype=float32)\n",
            "batch 736 accuracy: tf.Tensor(0.14724112, shape=(), dtype=float32)\n",
            "batch 737 accuracy: tf.Tensor(0.14727055, shape=(), dtype=float32)\n",
            "batch 738 accuracy: tf.Tensor(0.14717765, shape=(), dtype=float32)\n",
            "batch 739 accuracy: tf.Tensor(0.14722472, shape=(), dtype=float32)\n",
            "batch 740 accuracy: tf.Tensor(0.147195, shape=(), dtype=float32)\n",
            "batch 741 accuracy: tf.Tensor(0.14729013, shape=(), dtype=float32)\n",
            "batch 742 accuracy: tf.Tensor(0.14727445, shape=(), dtype=float32)\n",
            "batch 743 accuracy: tf.Tensor(0.14732777, shape=(), dtype=float32)\n",
            "batch 744 accuracy: tf.Tensor(0.14729775, shape=(), dtype=float32)\n",
            "batch 745 accuracy: tf.Tensor(0.14731094, shape=(), dtype=float32)\n",
            "batch 746 accuracy: tf.Tensor(0.14736317, shape=(), dtype=float32)\n",
            "batch 747 accuracy: tf.Tensor(0.14742123, shape=(), dtype=float32)\n",
            "batch 748 accuracy: tf.Tensor(0.14742458, shape=(), dtype=float32)\n",
            "batch 749 accuracy: tf.Tensor(0.14744899, shape=(), dtype=float32)\n",
            "batch 750 accuracy: tf.Tensor(0.14738543, shape=(), dtype=float32)\n",
            "batch 751 accuracy: tf.Tensor(0.14743993, shape=(), dtype=float32)\n",
            "batch 752 accuracy: tf.Tensor(0.14740892, shape=(), dtype=float32)\n",
            "batch 753 accuracy: tf.Tensor(0.14737312, shape=(), dtype=float32)\n",
            "batch 754 accuracy: tf.Tensor(0.14731485, shape=(), dtype=float32)\n",
            "batch 755 accuracy: tf.Tensor(0.14720352, shape=(), dtype=float32)\n",
            "batch 756 accuracy: tf.Tensor(0.14723498, shape=(), dtype=float32)\n",
            "batch 757 accuracy: tf.Tensor(0.14719836, shape=(), dtype=float32)\n",
            "batch 758 accuracy: tf.Tensor(0.14731292, shape=(), dtype=float32)\n",
            "batch 759 accuracy: tf.Tensor(0.14731848, shape=(), dtype=float32)\n",
            "batch 760 accuracy: tf.Tensor(0.1472888, shape=(), dtype=float32)\n",
            "batch 761 accuracy: tf.Tensor(0.14731768, shape=(), dtype=float32)\n",
            "batch 762 accuracy: tf.Tensor(0.14732566, shape=(), dtype=float32)\n",
            "batch 763 accuracy: tf.Tensor(0.14737311, shape=(), dtype=float32)\n",
            "batch 764 accuracy: tf.Tensor(0.14747538, shape=(), dtype=float32)\n",
            "batch 765 accuracy: tf.Tensor(0.1474794, shape=(), dtype=float32)\n",
            "batch 766 accuracy: tf.Tensor(0.14749955, shape=(), dtype=float32)\n",
            "batch 767 accuracy: tf.Tensor(0.14756806, shape=(), dtype=float32)\n",
            "batch 768 accuracy: tf.Tensor(0.14754498, shape=(), dtype=float32)\n",
            "batch 769 accuracy: tf.Tensor(0.14752752, shape=(), dtype=float32)\n",
            "batch 770 accuracy: tf.Tensor(0.14756751, shape=(), dtype=float32)\n",
            "batch 771 accuracy: tf.Tensor(0.14756356, shape=(), dtype=float32)\n",
            "batch 772 accuracy: tf.Tensor(0.14745677, shape=(), dtype=float32)\n",
            "batch 773 accuracy: tf.Tensor(0.14747863, shape=(), dtype=float32)\n",
            "batch 774 accuracy: tf.Tensor(0.14747337, shape=(), dtype=float32)\n",
            "batch 775 accuracy: tf.Tensor(0.14757827, shape=(), dtype=float32)\n",
            "batch 776 accuracy: tf.Tensor(0.14758417, shape=(), dtype=float32)\n",
            "batch 777 accuracy: tf.Tensor(0.14762045, shape=(), dtype=float32)\n",
            "batch 778 accuracy: tf.Tensor(0.14769806, shape=(), dtype=float32)\n",
            "batch 779 accuracy: tf.Tensor(0.14770213, shape=(), dtype=float32)\n",
            "batch 780 accuracy: tf.Tensor(0.14776088, shape=(), dtype=float32)\n",
            "batch 781 accuracy: tf.Tensor(0.14772606, shape=(), dtype=float32)\n",
            "batch 782 accuracy: tf.Tensor(0.147741, shape=(), dtype=float32)\n",
            "batch 783 accuracy: tf.Tensor(0.1477789, shape=(), dtype=float32)\n",
            "batch 784 accuracy: tf.Tensor(0.14778288, shape=(), dtype=float32)\n",
            "batch 785 accuracy: tf.Tensor(0.1478331, shape=(), dtype=float32)\n",
            "batch 786 accuracy: tf.Tensor(0.14785379, shape=(), dtype=float32)\n",
            "batch 787 accuracy: tf.Tensor(0.1480161, shape=(), dtype=float32)\n",
            "batch 788 accuracy: tf.Tensor(0.14807828, shape=(), dtype=float32)\n",
            "batch 789 accuracy: tf.Tensor(0.14819705, shape=(), dtype=float32)\n",
            "batch 790 accuracy: tf.Tensor(0.14818218, shape=(), dtype=float32)\n",
            "batch 791 accuracy: tf.Tensor(0.14814359, shape=(), dtype=float32)\n",
            "batch 792 accuracy: tf.Tensor(0.14813906, shape=(), dtype=float32)\n",
            "batch 793 accuracy: tf.Tensor(0.14812675, shape=(), dtype=float32)\n",
            "batch 794 accuracy: tf.Tensor(0.14822428, shape=(), dtype=float32)\n",
            "batch 795 accuracy: tf.Tensor(0.1482488, shape=(), dtype=float32)\n",
            "batch 796 accuracy: tf.Tensor(0.14837122, shape=(), dtype=float32)\n",
            "batch 797 accuracy: tf.Tensor(0.148362, shape=(), dtype=float32)\n",
            "batch 798 accuracy: tf.Tensor(0.14831196, shape=(), dtype=float32)\n",
            "batch 799 accuracy: tf.Tensor(0.1483907, shape=(), dtype=float32)\n",
            "batch 800 accuracy: tf.Tensor(0.1483516, shape=(), dtype=float32)\n",
            "batch 801 accuracy: tf.Tensor(0.14847635, shape=(), dtype=float32)\n",
            "batch 802 accuracy: tf.Tensor(0.14849043, shape=(), dtype=float32)\n",
            "batch 803 accuracy: tf.Tensor(0.14853324, shape=(), dtype=float32)\n",
            "batch 804 accuracy: tf.Tensor(0.14861563, shape=(), dtype=float32)\n",
            "batch 805 accuracy: tf.Tensor(0.14859626, shape=(), dtype=float32)\n",
            "batch 806 accuracy: tf.Tensor(0.14864631, shape=(), dtype=float32)\n",
            "batch 807 accuracy: tf.Tensor(0.14859475, shape=(), dtype=float32)\n",
            "batch 808 accuracy: tf.Tensor(0.14859028, shape=(), dtype=float32)\n",
            "batch 809 accuracy: tf.Tensor(0.14858174, shape=(), dtype=float32)\n",
            "batch 810 accuracy: tf.Tensor(0.14857322, shape=(), dtype=float32)\n",
            "batch 811 accuracy: tf.Tensor(0.14879766, shape=(), dtype=float32)\n",
            "batch 812 accuracy: tf.Tensor(0.14882772, shape=(), dtype=float32)\n",
            "batch 813 accuracy: tf.Tensor(0.14879851, shape=(), dtype=float32)\n",
            "batch 814 accuracy: tf.Tensor(0.14877264, shape=(), dtype=float32)\n",
            "batch 815 accuracy: tf.Tensor(0.14879732, shape=(), dtype=float32)\n",
            "batch 816 accuracy: tf.Tensor(0.1488622, shape=(), dtype=float32)\n",
            "batch 817 accuracy: tf.Tensor(0.14888225, shape=(), dtype=float32)\n",
            "batch 818 accuracy: tf.Tensor(0.148899, shape=(), dtype=float32)\n",
            "batch 819 accuracy: tf.Tensor(0.14890738, shape=(), dtype=float32)\n",
            "batch 820 accuracy: tf.Tensor(0.14895572, shape=(), dtype=float32)\n",
            "batch 821 accuracy: tf.Tensor(0.14885217, shape=(), dtype=float32)\n",
            "batch 822 accuracy: tf.Tensor(0.1488804, shape=(), dtype=float32)\n",
            "batch 823 accuracy: tf.Tensor(0.14891706, shape=(), dtype=float32)\n",
            "batch 824 accuracy: tf.Tensor(0.14891031, shape=(), dtype=float32)\n",
            "batch 825 accuracy: tf.Tensor(0.14891198, shape=(), dtype=float32)\n",
            "batch 826 accuracy: tf.Tensor(0.1489368, shape=(), dtype=float32)\n",
            "batch 827 accuracy: tf.Tensor(0.14894192, shape=(), dtype=float32)\n",
            "batch 828 accuracy: tf.Tensor(0.1489689, shape=(), dtype=float32)\n",
            "batch 829 accuracy: tf.Tensor(0.14894682, shape=(), dtype=float32)\n",
            "batch 830 accuracy: tf.Tensor(0.1489961, shape=(), dtype=float32)\n",
            "batch 831 accuracy: tf.Tensor(0.14898112, shape=(), dtype=float32)\n",
            "batch 832 accuracy: tf.Tensor(0.14901668, shape=(), dtype=float32)\n",
            "batch 833 accuracy: tf.Tensor(0.14905892, shape=(), dtype=float32)\n",
            "batch 834 accuracy: tf.Tensor(0.14905842, shape=(), dtype=float32)\n",
            "batch 835 accuracy: tf.Tensor(0.14907351, shape=(), dtype=float32)\n",
            "batch 836 accuracy: tf.Tensor(0.14902578, shape=(), dtype=float32)\n",
            "batch 837 accuracy: tf.Tensor(0.14903718, shape=(), dtype=float32)\n",
            "batch 838 accuracy: tf.Tensor(0.14893343, shape=(), dtype=float32)\n",
            "batch 839 accuracy: tf.Tensor(0.14881842, shape=(), dtype=float32)\n",
            "batch 840 accuracy: tf.Tensor(0.14877144, shape=(), dtype=float32)\n",
            "batch 841 accuracy: tf.Tensor(0.14875709, shape=(), dtype=float32)\n",
            "batch 842 accuracy: tf.Tensor(0.14874789, shape=(), dtype=float32)\n",
            "batch 843 accuracy: tf.Tensor(0.14874616, shape=(), dtype=float32)\n",
            "batch 844 accuracy: tf.Tensor(0.1487244, shape=(), dtype=float32)\n",
            "batch 845 accuracy: tf.Tensor(0.14870036, shape=(), dtype=float32)\n",
            "batch 846 accuracy: tf.Tensor(0.14868851, shape=(), dtype=float32)\n",
            "batch 847 accuracy: tf.Tensor(0.14872663, shape=(), dtype=float32)\n",
            "batch 848 accuracy: tf.Tensor(0.14872377, shape=(), dtype=float32)\n",
            "batch 849 accuracy: tf.Tensor(0.14878353, shape=(), dtype=float32)\n",
            "batch 850 accuracy: tf.Tensor(0.1488269, shape=(), dtype=float32)\n",
            "batch 851 accuracy: tf.Tensor(0.14878185, shape=(), dtype=float32)\n",
            "batch 852 accuracy: tf.Tensor(0.14877604, shape=(), dtype=float32)\n",
            "batch 853 accuracy: tf.Tensor(0.14873697, shape=(), dtype=float32)\n",
            "batch 854 accuracy: tf.Tensor(0.14870451, shape=(), dtype=float32)\n",
            "batch 855 accuracy: tf.Tensor(0.14868562, shape=(), dtype=float32)\n",
            "batch 856 accuracy: tf.Tensor(0.14860469, shape=(), dtype=float32)\n",
            "batch 857 accuracy: tf.Tensor(0.1486033, shape=(), dtype=float32)\n",
            "batch 858 accuracy: tf.Tensor(0.14868374, shape=(), dtype=float32)\n",
            "batch 859 accuracy: tf.Tensor(0.14873038, shape=(), dtype=float32)\n",
            "batch 860 accuracy: tf.Tensor(0.14865991, shape=(), dtype=float32)\n",
            "batch 861 accuracy: tf.Tensor(0.1485383, shape=(), dtype=float32)\n",
            "batch 862 accuracy: tf.Tensor(0.1485919, shape=(), dtype=float32)\n",
            "batch 863 accuracy: tf.Tensor(0.14863917, shape=(), dtype=float32)\n",
            "batch 864 accuracy: tf.Tensor(0.1486628, shape=(), dtype=float32)\n",
            "batch 865 accuracy: tf.Tensor(0.14866833, shape=(), dtype=float32)\n",
            "batch 866 accuracy: tf.Tensor(0.14867266, shape=(), dtype=float32)\n",
            "batch 867 accuracy: tf.Tensor(0.14872864, shape=(), dtype=float32)\n",
            "batch 868 accuracy: tf.Tensor(0.14869472, shape=(), dtype=float32)\n",
            "batch 869 accuracy: tf.Tensor(0.14870648, shape=(), dtype=float32)\n",
            "batch 870 accuracy: tf.Tensor(0.14862041, shape=(), dtype=float32)\n",
            "batch 871 accuracy: tf.Tensor(0.14859992, shape=(), dtype=float32)\n",
            "batch 872 accuracy: tf.Tensor(0.14861152, shape=(), dtype=float32)\n",
            "batch 873 accuracy: tf.Tensor(0.14864929, shape=(), dtype=float32)\n",
            "batch 874 accuracy: tf.Tensor(0.14863357, shape=(), dtype=float32)\n",
            "batch 875 accuracy: tf.Tensor(0.1486451, shape=(), dtype=float32)\n",
            "batch 876 accuracy: tf.Tensor(0.14864962, shape=(), dtype=float32)\n",
            "batch 877 accuracy: tf.Tensor(0.1486827, shape=(), dtype=float32)\n",
            "batch 878 accuracy: tf.Tensor(0.14865884, shape=(), dtype=float32)\n",
            "batch 879 accuracy: tf.Tensor(0.14874493, shape=(), dtype=float32)\n",
            "batch 880 accuracy: tf.Tensor(0.14867745, shape=(), dtype=float32)\n",
            "batch 881 accuracy: tf.Tensor(0.14871359, shape=(), dtype=float32)\n",
            "batch 882 accuracy: tf.Tensor(0.14877997, shape=(), dtype=float32)\n",
            "batch 883 accuracy: tf.Tensor(0.14880237, shape=(), dtype=float32)\n",
            "batch 884 accuracy: tf.Tensor(0.14872743, shape=(), dtype=float32)\n",
            "batch 885 accuracy: tf.Tensor(0.14866696, shape=(), dtype=float32)\n",
            "batch 886 accuracy: tf.Tensor(0.14866482, shape=(), dtype=float32)\n",
            "batch 887 accuracy: tf.Tensor(0.14866894, shape=(), dtype=float32)\n",
            "batch 888 accuracy: tf.Tensor(0.1486719, shape=(), dtype=float32)\n",
            "batch 889 accuracy: tf.Tensor(0.14863095, shape=(), dtype=float32)\n",
            "batch 890 accuracy: tf.Tensor(0.14871697, shape=(), dtype=float32)\n",
            "batch 891 accuracy: tf.Tensor(0.14877522, shape=(), dtype=float32)\n",
            "batch 892 accuracy: tf.Tensor(0.14875793, shape=(), dtype=float32)\n",
            "batch 893 accuracy: tf.Tensor(0.14876859, shape=(), dtype=float32)\n",
            "batch 894 accuracy: tf.Tensor(0.1487456, shape=(), dtype=float32)\n",
            "batch 895 accuracy: tf.Tensor(0.14872874, shape=(), dtype=float32)\n",
            "batch 896 accuracy: tf.Tensor(0.14870824, shape=(), dtype=float32)\n",
            "batch 897 accuracy: tf.Tensor(0.14876859, shape=(), dtype=float32)\n",
            "batch 898 accuracy: tf.Tensor(0.14878547, shape=(), dtype=float32)\n",
            "batch 899 accuracy: tf.Tensor(0.14868711, shape=(), dtype=float32)\n",
            "batch 900 accuracy: tf.Tensor(0.14865535, shape=(), dtype=float32)\n",
            "batch 901 accuracy: tf.Tensor(0.14865607, shape=(), dtype=float32)\n",
            "batch 902 accuracy: tf.Tensor(0.14863987, shape=(), dtype=float32)\n",
            "batch 903 accuracy: tf.Tensor(0.14858134, shape=(), dtype=float32)\n",
            "batch 904 accuracy: tf.Tensor(0.14861184, shape=(), dtype=float32)\n",
            "batch 905 accuracy: tf.Tensor(0.14856128, shape=(), dtype=float32)\n",
            "batch 906 accuracy: tf.Tensor(0.14856936, shape=(), dtype=float32)\n",
            "batch 907 accuracy: tf.Tensor(0.14861923, shape=(), dtype=float32)\n",
            "batch 908 accuracy: tf.Tensor(0.14858419, shape=(), dtype=float32)\n",
            "batch 909 accuracy: tf.Tensor(0.1484965, shape=(), dtype=float32)\n",
            "batch 910 accuracy: tf.Tensor(0.14838505, shape=(), dtype=float32)\n",
            "batch 911 accuracy: tf.Tensor(0.14841165, shape=(), dtype=float32)\n",
            "batch 912 accuracy: tf.Tensor(0.14842746, shape=(), dtype=float32)\n",
            "batch 913 accuracy: tf.Tensor(0.14847547, shape=(), dtype=float32)\n",
            "batch 914 accuracy: tf.Tensor(0.14850502, shape=(), dtype=float32)\n",
            "batch 915 accuracy: tf.Tensor(0.14852501, shape=(), dtype=float32)\n",
            "batch 916 accuracy: tf.Tensor(0.1485247, shape=(), dtype=float32)\n",
            "batch 917 accuracy: tf.Tensor(0.14850987, shape=(), dtype=float32)\n",
            "batch 918 accuracy: tf.Tensor(0.14855728, shape=(), dtype=float32)\n",
            "batch 919 accuracy: tf.Tensor(0.14859709, shape=(), dtype=float32)\n",
            "batch 920 accuracy: tf.Tensor(0.14859429, shape=(), dtype=float32)\n",
            "batch 921 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7f5eed5f9b90>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-95170fbd3f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m '''encoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{0}.h5\".format(0))\n\u001b[1;32m      3\u001b[0m decoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec\\epoch{0}.h5\".format(0))'''\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-d552c57e264f>\u001b[0m in \u001b[0;36mtrainData\u001b[0;34m(dataset, EPOCHS)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# obteniendo los erroes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m#encoder.load_weights(\"/content/drive/My Drive/Colab Notebooks/train/enc/epoch{0}.h5\".format(4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m#decoder.load_weights(\"/content/drive/My Drive/Colab Notebooks/train/dec/epoch{0}.h5\".format(4))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-7c703e88a934>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(image, groundTruth)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# si existe por lo menos un label por predecir entonces se llama al decoder envindole\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# su respectivo input, las salidas del encoder y el hidden state anterior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_decoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m#encoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{0}.h5\".format(2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m#decoder.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec\\epoch{0}.h5\".format(2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-6fc4bc8f7b74>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, x, a, h)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# se alimenta al gru con dicha informacion y se obtiene una salida y su ultimo estado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0;32m--> 444\u001b[0;31m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[0;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;31m# Under eager context, check the device placement and prefer the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m           \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m           last_output, outputs, new_h, runtime = standard_gru(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mgpu_gru\u001b[0;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001b[0m\n\u001b[1;32m    643\u001b[0m       \u001b[0mbiases\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m       \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m       transpose_weights=True)\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m_canonical_to_params\u001b[0;34m(weights, biases, shape, transpose_weights)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose_weights\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m   \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose_weights\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m   \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m   1300\u001b[0m   \"\"\"\n\u001b[1;32m   1301\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtranspose_weights\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m   \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose_v2\u001b[0;34m(a, perm, conjugate, name)\u001b[0m\n\u001b[1;32m   2226\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2227\u001b[0m   \"\"\"\n\u001b[0;32m-> 2228\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjugate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m       \u001b[0mperm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2316\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  11644\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11645\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m> 11646\u001b[0;31m         _ctx, \"Transpose\", name, x, perm)\n\u001b[0m\u001b[1;32m  11647\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11648\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXO8FV4Km07D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "4f410186-f0c2-4cec-a3fd-d4ddf75a6433"
      },
      "source": [
        "encoder.save_weights(\"/content/drive/My Drive/Colab Notebooks/train//enc/epoch{0}.h5\".format(3),\n",
        "                    save_format='h5')\n",
        "decoder.save_weights(\"/content/drive/My Drive/Colab Notebooks/train/dec/epoch{0}.h5\".format(3),\n",
        "                    save_format='h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d96ef8fbddd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m encoder.save_weights(\"/content/drive/My Drive/Colab Notebooks/train//enc/epoch{0}.h5\".format(3),\n\u001b[0m\u001b[1;32m      2\u001b[0m                     save_format='h5')\n\u001b[1;32m      3\u001b[0m decoder.save_weights(\"/content/drive/My Drive/Colab Notebooks/train/dec/epoch{0}.h5\".format(3),\n\u001b[1;32m      4\u001b[0m                     save_format='h5')\n",
            "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8t83To6m07E",
        "outputId": "c383d80f-ce29-4809-c89d-7f2488277874"
      },
      "source": [
        "'''encoder.save(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\enc\\epoch{}\".format(EPOCH))\n",
        "decoder.save_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec1.h5\",\n",
        "                    save_format='h5')'''\n",
        "a = tf.constant([[0.2, 0.4, 0.3, 0.1], [0.4, 0.4, 0.65, 0.1], [0.2, 0.58, 0.14, 0.1],\n",
        "                 [0.5, 0.14, 0.85, 0.3], [0.024, 0.39, 0.47, 0.4], [0.6, 0.004, 0.05, 0.7]])\n",
        "print(a.shape)\n",
        "samples = tf.argmax(a, 1)\n",
        "print(samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 4)\n",
            "tf.Tensor([1 2 1 2 2 3], shape=(6,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkWwM2kJm07F",
        "outputId": "aad06843-9658-4f3e-d10c-ce9e8e205cff"
      },
      "source": [
        "def evaluation(image):\n",
        "    hidden = decoder.reset(groundTruth.shape[0])\n",
        "hidden = decoder.reset(1)\n",
        "image = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\\HAMEX\\formulaire033-equation052.jpg\"\n",
        "img_val = tf.expand_dims(getProcessedImages(image)[0],0)\n",
        "feature_map = encoder(img_val)\n",
        "input_decoder = tf.constant([word_index['<start>']] * 1)\n",
        "#print(input_decoder.shape)\n",
        "print(getProcessedImages(image)[1])\n",
        "for i in range(len(getProcessedImages(image)[1])):\n",
        "    pred, hidden, alphas = decoder(input_decoder, feature_map, hidden)\n",
        "    predicted_ = tf.argmax(pred, 1)\n",
        "    input_decoder = predicted_\n",
        "    print(predicted_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[  4  16   2   6   3   2   6   3   9  16   2   6   3   2   7   3   9  16\n",
            "   2   6   3   2  18   3   9 100   9 127   5   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "tf.Tensor([16], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n",
            "tf.Tensor([57], shape=(1,), dtype=int64)\n",
            "tf.Tensor([28], shape=(1,), dtype=int64)\n",
            "tf.Tensor([10], shape=(1,), dtype=int64)\n",
            "tf.Tensor([2], shape=(1,), dtype=int64)\n",
            "tf.Tensor([35], shape=(1,), dtype=int64)\n",
            "tf.Tensor([118], shape=(1,), dtype=int64)\n",
            "tf.Tensor([18], shape=(1,), dtype=int64)\n",
            "tf.Tensor([106], shape=(1,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA7sCIYUm07F",
        "outputId": "2e5d46b0-ed16-4b1a-ec2b-cf99121320c8"
      },
      "source": [
        "decoder2 = GRU_decoder(128,128,len(list(word_index.keys())))\n",
        "decoder2.load_weights(r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec1.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11220/3096518049.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdecoder2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGRU_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdecoder2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\train\\dec1.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mF:\\anaconda\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2312\u001b[0m           '`load_weights` requires h5py when loading weights from HDF5.')\n\u001b[0;32m   2313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2314\u001b[1;33m       raise ValueError(\n\u001b[0m\u001b[0;32m   2315\u001b[0m           \u001b[1;34m'Unable to load weights saved in HDF5 format into a subclassed '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m           \u001b[1;34m'Model which has not created its variables yet. Call the Model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Unable to load weights saved in HDF5 format into a subclassed Model which has not created its variables yet. Call the Model first, then load the weights."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Iof8FAjm07G",
        "outputId": "5f7b942f-7e19-442b-df01-6ab25801e716"
      },
      "source": [
        "print(tf.config.list_physical_devices())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:XLA_CPU:0', device_type='XLA_CPU'), PhysicalDevice(name='/physical_device:XLA_GPU:0', device_type='XLA_GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhl3X0H_m07H"
      },
      "source": [
        "# ignorar todo a partir de aqui, es para hacer pruebas jeje :)\n",
        "\n",
        "'''\n",
        "def preTraining(dataSet, cache=True, shuffle_buffer_size=1000):\n",
        "    dataSet = dataSet.shuffle( buffer_size=shuffle_buffer_size )\n",
        "    #dataSet = dataSet.repeat()\n",
        "    dataSet = dataSet.batch(16) #batch size =32\n",
        "    #dataSet = dataSet.prefetch(buffer_size = tf.data.AUTOTUNE)\n",
        "    return dataSet\n",
        "trainDS = preTraining(labeledDataset)\n",
        "#image_batch, label_batch = next(iter(trainDS))\n",
        "#show_batch(image_batch.numpy(), label_batch.numpy())'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKpTO0yXm07H",
        "outputId": "3266873e-4b17-40f4-8b93-f85ce880f352"
      },
      "source": [
        "# convert to grayscale\n",
        "PATH = r\"G:\\\\Documents\\\\CROHME\\\\CROHME\\\\CROHME2013_data\\\\TrainINKML\\\\images\\\\expressmatch\\\\101_alfonso.jpg\"\n",
        "image = cv.imread(PATH)\n",
        "resized = cv.resize(image, (1024,512), interpolation = cv.INTER_AREA)\n",
        " \n",
        "print('Resized Dimensions : ',resized.shape)\n",
        " \n",
        "cv.imshow(\"Resized image\", resized)\n",
        "cv.waitKey(0)\n",
        "cv.destroyAllWindows()\n",
        "#grayImage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resized Dimensions :  (512, 1024, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3vhb7U2m07H"
      },
      "source": [
        "path = r\"G:\\Documents\\CROHME\\CROHME\\CROHME2013_data\\TrainINKML\\images\\expressmatch\\65_alfonso.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxEbzgnmm07I"
      },
      "source": [
        "# Variables necesarias, ignorar por ahora\n",
        "# M = embdedding dimmensionality\n",
        "# N = GRU dimensionality\n",
        "# L = number of annotation vectors\n",
        "# D = dimensionality of annotation vectors\n",
        "# K = number of words in vocabulary\n",
        "# N_prime = attention dimentionality\n",
        "\n",
        "L = 3\n",
        "D = 128\n",
        "K = 127\n",
        "N_prime = 128\n",
        "N = 64\n",
        "M = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6giaavRBm07I",
        "outputId": "72793737-01ec-4829-fa82-9169e7b7e111"
      },
      "source": [
        "a = tf.zeros((16,1,3, 128))\n",
        "print(a.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16, 1, 3, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUWIeV5Um07I",
        "outputId": "6b1e9bce-2ec5-4375-a4d5-e3747e7dfdde"
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Activation, Dense \n",
        "model = Sequential() \n",
        "layer_1 = Dense(128, input_shape = (56,)) \n",
        "\n",
        "model.add(layer_1) \n",
        "print(layer_1.input_shape) \n",
        "print(layer_1.output_shape )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(None, 56)\n",
            "(None, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF0J59mKm07J",
        "outputId": "3cf447e6-150f-4451-a583-f86286e03eb0"
      },
      "source": [
        "t = decoder.g\n",
        "\n",
        "class test(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(test, self).__init__()\n",
        "        self.fc1 = tf.keras.layers.Dense(128)\n",
        "        self.fc2 = tf.keras.layers.Dense(128)#,activation='softmax')\n",
        "        self.fc3 = tf.keras.layers.Dense(128)\n",
        "        self.fc4 = tf.keras.layers.Dense(127, activation='softmax')\n",
        "    \n",
        "    def call(self, a, b, c):\n",
        "        a = self.fc1(a)\n",
        "        b = self.fc2(b)\n",
        "        c = self.fc3(c)\n",
        "        res = a+b+c\n",
        "        res = self.fc4(res)\n",
        "        return res\n",
        "tst = test()\n",
        "res = tst(t[:,0], t[:,1], t[:,2])\n",
        "print(res[1], max(res[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.0077122  0.00798441 0.0082583  0.00813114 0.00758686 0.00765422\n",
            " 0.00819508 0.00801731 0.00778867 0.00793868 0.00817909 0.0077188\n",
            " 0.00780235 0.00792794 0.00782531 0.00801626 0.00759206 0.00791037\n",
            " 0.00784708 0.00803427 0.00783526 0.00810021 0.00777087 0.00752414\n",
            " 0.00764606 0.00757418 0.007841   0.00777249 0.00772197 0.00759741\n",
            " 0.0077856  0.0078179  0.00805625 0.00800839 0.00779082 0.00805504\n",
            " 0.00801177 0.00805107 0.00823483 0.0081527  0.00743428 0.00756936\n",
            " 0.00782649 0.00787631 0.00812574 0.00805205 0.00788147 0.00777273\n",
            " 0.00788906 0.00815082 0.00745555 0.00793089 0.00765897 0.00804335\n",
            " 0.00789843 0.0077011  0.00802226 0.00792664 0.0081496  0.00784043\n",
            " 0.00800649 0.0077229  0.00779958 0.00769156 0.00797984 0.0078022\n",
            " 0.00766275 0.00797059 0.00790793 0.0080414  0.00796528 0.0081026\n",
            " 0.00842888 0.00783339 0.00775519 0.00776263 0.0078705  0.0076692\n",
            " 0.00840811 0.00759783 0.00786747 0.00764156 0.00765676 0.00792471\n",
            " 0.00792545 0.00794002 0.00792474 0.00750257 0.00773712 0.00808666\n",
            " 0.00778254 0.00804139 0.00782606 0.00767495 0.00779922 0.00801521\n",
            " 0.00814676 0.00785039 0.00806912 0.00779993 0.0079702  0.00775691\n",
            " 0.00774464 0.00762086 0.00766431 0.00750018 0.00788963 0.0078758\n",
            " 0.00800091 0.00793499 0.00777898 0.00768511 0.00793518 0.00793537\n",
            " 0.00771615 0.00773617 0.00767745 0.00790054 0.00780226 0.00813506\n",
            " 0.00783516 0.00799613 0.00790621 0.00805534 0.00827717 0.00782513\n",
            " 0.00797879], shape=(127,), dtype=float32) tf.Tensor(0.008428884, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYg78kwIm07J",
        "outputId": "7a862d24-374e-4667-dd44-f391851c94e8"
      },
      "source": [
        "'''import tensorflow_probability as tfp\n",
        "resp = tfp.distributions.Multinomial(probs=[.2,.5,.6], num_samples=1)\n",
        "print(resp)'''\n",
        "'''import tensorflow as tf\n",
        "samples = tf.constant([[.25,.26,.6], [.85, .9, 0.25], [.3, .8, .4]])\n",
        "shape = samples.shape\n",
        "for i in range(shape[1]):\n",
        "print(samples)\n",
        "print(tf.reduce_max(tf.compat.v1.multinomial(samples, 1), axis=1))'''\n",
        "res_words = tf.reduce_max(res, axis=1)\n",
        "\n",
        "\n",
        "print(tf.reduce_max(res, axis=1))\n",
        "#print(tf.compat.v1.multinomial(logits=samples, num_samples=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.00836815 0.00836697 0.00836866 0.00836738 0.00836732 0.0083674\n",
            " 0.00836789 0.0083669 ], shape=(8,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5BSOxU_m07K",
        "outputId": "b8b2cc56-a934-493d-d781-917e27dd6a50"
      },
      "source": [
        "B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
        "                 [14, 45, 23, 5, 27]])\n",
        "print(tf.argmax(res, 1), tf.transpose(tf.argmax(res, 1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([72 72 72 72 72 72 72 72], shape=(8,), dtype=int64) tf.Tensor([72 72 72 72 72 72 72 72], shape=(8,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxFSz2Dgm07K",
        "outputId": "f6028b69-b5ed-4913-ecb0-ec61c08675e1"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.9.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCKwsXjcm07K"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQSDwRv1m07L",
        "outputId": "a4672235-dd63-4a36-8ae1-32a3877214d7"
      },
      "source": [
        "gpus = tf.config.experimental.list_physical_devices()\n",
        "print(\"Num GPUs Available\", gpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zGTCXm4m07L",
        "outputId": "761ef4e9-0980-4b67-8afd-86cc67f0265c"
      },
      "source": [
        "print(tf.test.is_gpu_available())\n",
        "print(tf.test.is_built_with_cuda())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Yo\\AppData\\Local\\Temp/ipykernel_19424/3597539986.py:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "False\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NObUN8B_m07L",
        "outputId": "b7197999-6634-4227-fad7-4354637879f3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRui7Qcom07L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}